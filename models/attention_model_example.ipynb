{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd063f661667cfff4a21b9f1172704ab3c7d831d3612a4dc528cd9d3281904853c9",
   "display_name": "Python 3.8.5 64-bit ('nlpai': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import seaborn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on class GRU in module torch.nn.modules.rnn:\n\nclass GRU(RNNBase)\n |  GRU(*args, **kwargs)\n |  \n |  Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\n |  \n |  \n |  For each element in the input sequence, each layer computes the following\n |  function:\n |  \n |  .. math::\n |      \\begin{array}{ll}\n |          r_t = \\sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\\\\n |          z_t = \\sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\\\\n |          n_t = \\tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\\\\n |          h_t = (1 - z_t) * n_t + z_t * h_{(t-1)}\n |      \\end{array}\n |  \n |  where :math:`h_t` is the hidden state at time `t`, :math:`x_t` is the input\n |  at time `t`, :math:`h_{(t-1)}` is the hidden state of the layer\n |  at time `t-1` or the initial hidden state at time `0`, and :math:`r_t`,\n |  :math:`z_t`, :math:`n_t` are the reset, update, and new gates, respectively.\n |  :math:`\\sigma` is the sigmoid function, and :math:`*` is the Hadamard product.\n |  \n |  In a multilayer GRU, the input :math:`x^{(l)}_t` of the :math:`l` -th layer\n |  (:math:`l >= 2`) is the hidden state :math:`h^{(l-1)}_t` of the previous layer multiplied by\n |  dropout :math:`\\delta^{(l-1)}_t` where each :math:`\\delta^{(l-1)}_t` is a Bernoulli random\n |  variable which is :math:`0` with probability :attr:`dropout`.\n |  \n |  Args:\n |      input_size: The number of expected features in the input `x`\n |      hidden_size: The number of features in the hidden state `h`\n |      num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n |          would mean stacking two GRUs together to form a `stacked GRU`,\n |          with the second GRU taking in outputs of the first GRU and\n |          computing the final results. Default: 1\n |      bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n |          Default: ``True``\n |      batch_first: If ``True``, then the input and output tensors are provided\n |          as (batch, seq, feature). Default: ``False``\n |      dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n |          GRU layer except the last layer, with dropout probability equal to\n |          :attr:`dropout`. Default: 0\n |      bidirectional: If ``True``, becomes a bidirectional GRU. Default: ``False``\n |  \n |  Inputs: input, h_0\n |      - **input** of shape `(seq_len, batch, input_size)`: tensor containing the features\n |        of the input sequence. The input can also be a packed variable length\n |        sequence. See :func:`torch.nn.utils.rnn.pack_padded_sequence`\n |        for details.\n |      - **h_0** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n |        containing the initial hidden state for each element in the batch.\n |        Defaults to zero if not provided. If the RNN is bidirectional,\n |        num_directions should be 2, else it should be 1.\n |  \n |  Outputs: output, h_n\n |      - **output** of shape `(seq_len, batch, num_directions * hidden_size)`: tensor\n |        containing the output features h_t from the last layer of the GRU,\n |        for each `t`. If a :class:`torch.nn.utils.rnn.PackedSequence` has been\n |        given as the input, the output will also be a packed sequence.\n |        For the unpacked case, the directions can be separated\n |        using ``output.view(seq_len, batch, num_directions, hidden_size)``,\n |        with forward and backward being direction `0` and `1` respectively.\n |  \n |        Similarly, the directions can be separated in the packed case.\n |      - **h_n** of shape `(num_layers * num_directions, batch, hidden_size)`: tensor\n |        containing the hidden state for `t = seq_len`\n |  \n |        Like *output*, the layers can be separated using\n |        ``h_n.view(num_layers, num_directions, batch, hidden_size)``.\n |  \n |  Shape:\n |      - Input1: :math:`(L, N, H_{in})` tensor containing input features where\n |        :math:`H_{in}=\\text{input\\_size}` and `L` represents a sequence length.\n |      - Input2: :math:`(S, N, H_{out})` tensor\n |        containing the initial hidden state for each element in the batch.\n |        :math:`H_{out}=\\text{hidden\\_size}`\n |        Defaults to zero if not provided. where :math:`S=\\text{num\\_layers} * \\text{num\\_directions}`\n |        If the RNN is bidirectional, num_directions should be 2, else it should be 1.\n |      - Output1: :math:`(L, N, H_{all})` where :math:`H_{all}=\\text{num\\_directions} * \\text{hidden\\_size}`\n |      - Output2: :math:`(S, N, H_{out})` tensor containing the next hidden state\n |        for each element in the batch\n |  \n |  Attributes:\n |      weight_ih_l[k] : the learnable input-hidden weights of the :math:`\\text{k}^{th}` layer\n |          (W_ir|W_iz|W_in), of shape `(3*hidden_size, input_size)` for `k = 0`.\n |          Otherwise, the shape is `(3*hidden_size, num_directions * hidden_size)`\n |      weight_hh_l[k] : the learnable hidden-hidden weights of the :math:`\\text{k}^{th}` layer\n |          (W_hr|W_hz|W_hn), of shape `(3*hidden_size, hidden_size)`\n |      bias_ih_l[k] : the learnable input-hidden bias of the :math:`\\text{k}^{th}` layer\n |          (b_ir|b_iz|b_in), of shape `(3*hidden_size)`\n |      bias_hh_l[k] : the learnable hidden-hidden bias of the :math:`\\text{k}^{th}` layer\n |          (b_hr|b_hz|b_hn), of shape `(3*hidden_size)`\n |  \n |  .. note::\n |      All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n |      where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n |  \n |  .. include:: ../cudnn_persistent_rnn.rst\n |  \n |  Examples::\n |  \n |      >>> rnn = nn.GRU(10, 20, 2)\n |      >>> input = torch.randn(5, 3, 10)\n |      >>> h0 = torch.randn(2, 3, 20)\n |      >>> output, hn = rnn(input, h0)\n |  \n |  Method resolution order:\n |      GRU\n |      RNNBase\n |      torch.nn.modules.module.Module\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, *args, **kwargs)\n |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n |  \n |  forward(self, input, hx=None)\n |      Defines the computation performed at every call.\n |      \n |      Should be overridden by all subclasses.\n |      \n |      .. note::\n |          Although the recipe for forward pass needs to be defined within\n |          this function, one should call the :class:`Module` instance afterwards\n |          instead of this since the former takes care of running the\n |          registered hooks while the latter silently ignores them.\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from RNNBase:\n |  \n |  __setattr__(self, attr, value)\n |      Implement setattr(self, name, value).\n |  \n |  __setstate__(self, d)\n |  \n |  check_forward_args(self, input: torch.Tensor, hidden: torch.Tensor, batch_sizes: Union[torch.Tensor, NoneType])\n |  \n |  check_hidden_size(self, hx: torch.Tensor, expected_hidden_size: Tuple[int, int, int], msg: str = 'Expected hidden size {}, got {}') -> None\n |  \n |  check_input(self, input: torch.Tensor, batch_sizes: Union[torch.Tensor, NoneType]) -> None\n |  \n |  extra_repr(self) -> str\n |      Set the extra representation of the module\n |      \n |      To print customized extra information, you should re-implement\n |      this method in your own modules. Both single-line and multi-line\n |      strings are acceptable.\n |  \n |  flatten_parameters(self) -> None\n |      Resets parameter data pointer so that they can use faster code paths.\n |      \n |      Right now, this works only if the module is on the GPU and cuDNN is enabled.\n |      Otherwise, it's a no-op.\n |  \n |  get_expected_hidden_size(self, input: torch.Tensor, batch_sizes: Union[torch.Tensor, NoneType]) -> Tuple[int, int, int]\n |  \n |  permute_hidden(self, hx: torch.Tensor, permutation: Union[torch.Tensor, NoneType])\n |  \n |  reset_parameters(self) -> None\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties inherited from RNNBase:\n |  \n |  all_weights\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from RNNBase:\n |  \n |  __annotations__ = {'batch_first': <class 'bool'>, 'bias': <class 'bool...\n |  \n |  __constants__ = ['mode', 'input_size', 'hidden_size', 'num_layers', 'b...\n |  \n |  __jit_unused_properties__ = ['all_weights']\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from torch.nn.modules.module.Module:\n |  \n |  __call__ = _call_impl(self, *input, **kwargs)\n |  \n |  __delattr__(self, name)\n |      Implement delattr(self, name).\n |  \n |  __dir__(self)\n |      Default dir() implementation.\n |  \n |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n |  \n |  __repr__(self)\n |      Return repr(self).\n |  \n |  add_module(self, name: str, module: Union[ForwardRef('Module'), NoneType]) -> None\n |      Adds a child module to the current module.\n |      \n |      The module can be accessed as an attribute using the given name.\n |      \n |      Args:\n |          name (string): name of the child module. The child module can be\n |              accessed from this module using the given name\n |          module (Module): child module to be added to the module.\n |  \n |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n |      as well as self. Typical use includes initializing the parameters of a model\n |      (see also :ref:`nn-init-doc`).\n |      \n |      Args:\n |          fn (:class:`Module` -> None): function to be applied to each submodule\n |      \n |      Returns:\n |          Module: self\n |      \n |      Example::\n |      \n |          >>> @torch.no_grad()\n |          >>> def init_weights(m):\n |          >>>     print(m)\n |          >>>     if type(m) == nn.Linear:\n |          >>>         m.weight.fill_(1.0)\n |          >>>         print(m.weight)\n |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n |          >>> net.apply(init_weights)\n |          Linear(in_features=2, out_features=2, bias=True)\n |          Parameter containing:\n |          tensor([[ 1.,  1.],\n |                  [ 1.,  1.]])\n |          Linear(in_features=2, out_features=2, bias=True)\n |          Parameter containing:\n |          tensor([[ 1.,  1.],\n |                  [ 1.,  1.]])\n |          Sequential(\n |            (0): Linear(in_features=2, out_features=2, bias=True)\n |            (1): Linear(in_features=2, out_features=2, bias=True)\n |          )\n |          Sequential(\n |            (0): Linear(in_features=2, out_features=2, bias=True)\n |            (1): Linear(in_features=2, out_features=2, bias=True)\n |          )\n |  \n |  bfloat16(self: ~T) -> ~T\n |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n |      \n |      Returns:\n |          Module: self\n |  \n |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n |      Returns an iterator over module buffers.\n |      \n |      Args:\n |          recurse (bool): if True, then yields buffers of this module\n |              and all submodules. Otherwise, yields only buffers that\n |              are direct members of this module.\n |      \n |      Yields:\n |          torch.Tensor: module buffer\n |      \n |      Example::\n |      \n |          >>> for buf in model.buffers():\n |          >>>     print(type(buf), buf.size())\n |          <class 'torch.Tensor'> (20L,)\n |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n |  \n |  children(self) -> Iterator[ForwardRef('Module')]\n |      Returns an iterator over immediate children modules.\n |      \n |      Yields:\n |          Module: a child module\n |  \n |  cpu(self: ~T) -> ~T\n |      Moves all model parameters and buffers to the CPU.\n |      \n |      Returns:\n |          Module: self\n |  \n |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n |      Moves all model parameters and buffers to the GPU.\n |      \n |      This also makes associated parameters and buffers different objects. So\n |      it should be called before constructing optimizer if the module will\n |      live on GPU while being optimized.\n |      \n |      Arguments:\n |          device (int, optional): if specified, all parameters will be\n |              copied to that device\n |      \n |      Returns:\n |          Module: self\n |  \n |  double(self: ~T) -> ~T\n |      Casts all floating point parameters and buffers to ``double`` datatype.\n |      \n |      Returns:\n |          Module: self\n |  \n |  eval(self: ~T) -> ~T\n |      Sets the module in evaluation mode.\n |      \n |      This has any effect only on certain modules. See documentations of\n |      particular modules for details of their behaviors in training/evaluation\n |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n |      etc.\n |      \n |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n |      \n |      Returns:\n |          Module: self\n |  \n |  float(self: ~T) -> ~T\n |      Casts all floating point parameters and buffers to float datatype.\n |      \n |      Returns:\n |          Module: self\n |  \n |  half(self: ~T) -> ~T\n |      Casts all floating point parameters and buffers to ``half`` datatype.\n |      \n |      Returns:\n |          Module: self\n |  \n |  load_state_dict(self, state_dict: Dict[str, torch.Tensor], strict: bool = True)\n |      Copies parameters and buffers from :attr:`state_dict` into\n |      this module and its descendants. If :attr:`strict` is ``True``, then\n |      the keys of :attr:`state_dict` must exactly match the keys returned\n |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n |      \n |      Arguments:\n |          state_dict (dict): a dict containing parameters and\n |              persistent buffers.\n |          strict (bool, optional): whether to strictly enforce that the keys\n |              in :attr:`state_dict` match the keys returned by this module's\n |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n |      \n |      Returns:\n |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n |              * **missing_keys** is a list of str containing the missing keys\n |              * **unexpected_keys** is a list of str containing the unexpected keys\n |  \n |  modules(self) -> Iterator[ForwardRef('Module')]\n |      Returns an iterator over all modules in the network.\n |      \n |      Yields:\n |          Module: a module in the network\n |      \n |      Note:\n |          Duplicate modules are returned only once. In the following\n |          example, ``l`` will be returned only once.\n |      \n |      Example::\n |      \n |          >>> l = nn.Linear(2, 2)\n |          >>> net = nn.Sequential(l, l)\n |          >>> for idx, m in enumerate(net.modules()):\n |                  print(idx, '->', m)\n |      \n |          0 -> Sequential(\n |            (0): Linear(in_features=2, out_features=2, bias=True)\n |            (1): Linear(in_features=2, out_features=2, bias=True)\n |          )\n |          1 -> Linear(in_features=2, out_features=2, bias=True)\n |  \n |  named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n |      Returns an iterator over module buffers, yielding both the\n |      name of the buffer as well as the buffer itself.\n |      \n |      Args:\n |          prefix (str): prefix to prepend to all buffer names.\n |          recurse (bool): if True, then yields buffers of this module\n |              and all submodules. Otherwise, yields only buffers that\n |              are direct members of this module.\n |      \n |      Yields:\n |          (string, torch.Tensor): Tuple containing the name and buffer\n |      \n |      Example::\n |      \n |          >>> for name, buf in self.named_buffers():\n |          >>>    if name in ['running_var']:\n |          >>>        print(buf.size())\n |  \n |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n |      Returns an iterator over immediate children modules, yielding both\n |      the name of the module as well as the module itself.\n |      \n |      Yields:\n |          (string, Module): Tuple containing a name and child module\n |      \n |      Example::\n |      \n |          >>> for name, module in model.named_children():\n |          >>>     if name in ['conv4', 'conv5']:\n |          >>>         print(module)\n |  \n |  named_modules(self, memo: Union[Set[ForwardRef('Module')], NoneType] = None, prefix: str = '')\n |      Returns an iterator over all modules in the network, yielding\n |      both the name of the module as well as the module itself.\n |      \n |      Yields:\n |          (string, Module): Tuple of name and module\n |      \n |      Note:\n |          Duplicate modules are returned only once. In the following\n |          example, ``l`` will be returned only once.\n |      \n |      Example::\n |      \n |          >>> l = nn.Linear(2, 2)\n |          >>> net = nn.Sequential(l, l)\n |          >>> for idx, m in enumerate(net.named_modules()):\n |                  print(idx, '->', m)\n |      \n |          0 -> ('', Sequential(\n |            (0): Linear(in_features=2, out_features=2, bias=True)\n |            (1): Linear(in_features=2, out_features=2, bias=True)\n |          ))\n |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n |  \n |  named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n |      Returns an iterator over module parameters, yielding both the\n |      name of the parameter as well as the parameter itself.\n |      \n |      Args:\n |          prefix (str): prefix to prepend to all parameter names.\n |          recurse (bool): if True, then yields parameters of this module\n |              and all submodules. Otherwise, yields only parameters that\n |              are direct members of this module.\n |      \n |      Yields:\n |          (string, Parameter): Tuple containing the name and parameter\n |      \n |      Example::\n |      \n |          >>> for name, param in self.named_parameters():\n |          >>>    if name in ['bias']:\n |          >>>        print(param.size())\n |  \n |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n |      Returns an iterator over module parameters.\n |      \n |      This is typically passed to an optimizer.\n |      \n |      Args:\n |          recurse (bool): if True, then yields parameters of this module\n |              and all submodules. Otherwise, yields only parameters that\n |              are direct members of this module.\n |      \n |      Yields:\n |          Parameter: module parameter\n |      \n |      Example::\n |      \n |          >>> for param in model.parameters():\n |          >>>     print(type(param), param.size())\n |          <class 'torch.Tensor'> (20L,)\n |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n |  \n |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n |      Registers a backward hook on the module.\n |      \n |      .. warning ::\n |      \n |          The current implementation will not have the presented behavior\n |          for complex :class:`Module` that perform many operations.\n |          In some failure cases, :attr:`grad_input` and :attr:`grad_output` will only\n |          contain the gradients for a subset of the inputs and outputs.\n |          For such :class:`Module`, you should use :func:`torch.Tensor.register_hook`\n |          directly on a specific input or output to get the required gradients.\n |      \n |      The hook will be called every time the gradients with respect to module\n |      inputs are computed. The hook should have the following signature::\n |      \n |          hook(module, grad_input, grad_output) -> Tensor or None\n |      \n |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n |      module has multiple inputs or outputs. The hook should not modify its\n |      arguments, but it can optionally return a new gradient with respect to\n |      input that will be used in place of :attr:`grad_input` in subsequent\n |      computations. :attr:`grad_input` will only correspond to the inputs given\n |      as positional arguments.\n |      \n |      Returns:\n |          :class:`torch.utils.hooks.RemovableHandle`:\n |              a handle that can be used to remove the added hook by calling\n |              ``handle.remove()``\n |  \n |  register_buffer(self, name: str, tensor: Union[torch.Tensor, NoneType], persistent: bool = True) -> None\n |      Adds a buffer to the module.\n |      \n |      This is typically used to register a buffer that should not to be\n |      considered a model parameter. For example, BatchNorm's ``running_mean``\n |      is not a parameter, but is part of the module's state. Buffers, by\n |      default, are persistent and will be saved alongside parameters. This\n |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n |      only difference between a persistent buffer and a non-persistent buffer\n |      is that the latter will not be a part of this module's\n |      :attr:`state_dict`.\n |      \n |      Buffers can be accessed as attributes using given names.\n |      \n |      Args:\n |          name (string): name of the buffer. The buffer can be accessed\n |              from this module using the given name\n |          tensor (Tensor): buffer to be registered.\n |          persistent (bool): whether the buffer is part of this module's\n |              :attr:`state_dict`.\n |      \n |      Example::\n |      \n |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n |  \n |  register_forward_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n |      Registers a forward hook on the module.\n |      \n |      The hook will be called every time after :func:`forward` has computed an output.\n |      It should have the following signature::\n |      \n |          hook(module, input, output) -> None or modified output\n |      \n |      The input contains only the positional arguments given to the module.\n |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n |      The hook can modify the output. It can modify the input inplace but\n |      it will not have effect on forward since this is called after\n |      :func:`forward` is called.\n |      \n |      Returns:\n |          :class:`torch.utils.hooks.RemovableHandle`:\n |              a handle that can be used to remove the added hook by calling\n |              ``handle.remove()``\n |  \n |  register_forward_pre_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n |      Registers a forward pre-hook on the module.\n |      \n |      The hook will be called every time before :func:`forward` is invoked.\n |      It should have the following signature::\n |      \n |          hook(module, input) -> None or modified input\n |      \n |      The input contains only the positional arguments given to the module.\n |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n |      The hook can modify the input. User can either return a tuple or a\n |      single modified value in the hook. We will wrap the value into a tuple\n |      if a single value is returned(unless that value is already a tuple).\n |      \n |      Returns:\n |          :class:`torch.utils.hooks.RemovableHandle`:\n |              a handle that can be used to remove the added hook by calling\n |              ``handle.remove()``\n |  \n |  register_parameter(self, name: str, param: Union[torch.nn.parameter.Parameter, NoneType]) -> None\n |      Adds a parameter to the module.\n |      \n |      The parameter can be accessed as an attribute using given name.\n |      \n |      Args:\n |          name (string): name of the parameter. The parameter can be accessed\n |              from this module using the given name\n |          param (Parameter): parameter to be added to the module.\n |  \n |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n |      Change if autograd should record operations on parameters in this\n |      module.\n |      \n |      This method sets the parameters' :attr:`requires_grad` attributes\n |      in-place.\n |      \n |      This method is helpful for freezing part of the module for finetuning\n |      or training parts of a model individually (e.g., GAN training).\n |      \n |      Args:\n |          requires_grad (bool): whether autograd should record operations on\n |                                parameters in this module. Default: ``True``.\n |      \n |      Returns:\n |          Module: self\n |  \n |  share_memory(self: ~T) -> ~T\n |  \n |  state_dict(self, destination=None, prefix='', keep_vars=False)\n |      Returns a dictionary containing a whole state of the module.\n |      \n |      Both parameters and persistent buffers (e.g. running averages) are\n |      included. Keys are corresponding parameter and buffer names.\n |      \n |      Returns:\n |          dict:\n |              a dictionary containing a whole state of the module\n |      \n |      Example::\n |      \n |          >>> module.state_dict().keys()\n |          ['bias', 'weight']\n |  \n |  to(self, *args, **kwargs)\n |      Moves and/or casts the parameters and buffers.\n |      \n |      This can be called as\n |      \n |      .. function:: to(device=None, dtype=None, non_blocking=False)\n |      \n |      .. function:: to(dtype, non_blocking=False)\n |      \n |      .. function:: to(tensor, non_blocking=False)\n |      \n |      .. function:: to(memory_format=torch.channels_last)\n |      \n |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n |      floating point desired :attr:`dtype` s. In addition, this method will\n |      only cast the floating point parameters and buffers to :attr:`dtype`\n |      (if given). The integral parameters and buffers will be moved\n |      :attr:`device`, if that is given, but with dtypes unchanged. When\n |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n |      with respect to the host if possible, e.g., moving CPU Tensors with\n |      pinned memory to CUDA devices.\n |      \n |      See below for examples.\n |      \n |      .. note::\n |          This method modifies the module in-place.\n |      \n |      Args:\n |          device (:class:`torch.device`): the desired device of the parameters\n |              and buffers in this module\n |          dtype (:class:`torch.dtype`): the desired floating point type of\n |              the floating point parameters and buffers in this module\n |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n |              dtype and device for all parameters and buffers in this module\n |          memory_format (:class:`torch.memory_format`): the desired memory\n |              format for 4D parameters and buffers in this module (keyword\n |              only argument)\n |      \n |      Returns:\n |          Module: self\n |      \n |      Example::\n |      \n |          >>> linear = nn.Linear(2, 2)\n |          >>> linear.weight\n |          Parameter containing:\n |          tensor([[ 0.1913, -0.3420],\n |                  [-0.5113, -0.2325]])\n |          >>> linear.to(torch.double)\n |          Linear(in_features=2, out_features=2, bias=True)\n |          >>> linear.weight\n |          Parameter containing:\n |          tensor([[ 0.1913, -0.3420],\n |                  [-0.5113, -0.2325]], dtype=torch.float64)\n |          >>> gpu1 = torch.device(\"cuda:1\")\n |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n |          Linear(in_features=2, out_features=2, bias=True)\n |          >>> linear.weight\n |          Parameter containing:\n |          tensor([[ 0.1914, -0.3420],\n |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n |          >>> cpu = torch.device(\"cpu\")\n |          >>> linear.to(cpu)\n |          Linear(in_features=2, out_features=2, bias=True)\n |          >>> linear.weight\n |          Parameter containing:\n |          tensor([[ 0.1914, -0.3420],\n |                  [-0.5112, -0.2324]], dtype=torch.float16)\n |  \n |  train(self: ~T, mode: bool = True) -> ~T\n |      Sets the module in training mode.\n |      \n |      This has any effect only on certain modules. See documentations of\n |      particular modules for details of their behaviors in training/evaluation\n |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n |      etc.\n |      \n |      Args:\n |          mode (bool): whether to set training mode (``True``) or evaluation\n |                       mode (``False``). Default: ``True``.\n |      \n |      Returns:\n |          Module: self\n |  \n |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n |      Casts all parameters and buffers to :attr:`dst_type`.\n |      \n |      Arguments:\n |          dst_type (type or string): the desired type\n |      \n |      Returns:\n |          Module: self\n |  \n |  zero_grad(self, set_to_none: bool = False) -> None\n |      Sets gradients of all model parameters to zero. See similar function\n |      under :class:`torch.optim.Optimizer` for more context.\n |      \n |      Arguments:\n |          set_to_none (bool): instead of setting to zero, set the grads to None.\n |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from torch.nn.modules.module.Module:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from torch.nn.modules.module.Module:\n |  \n |  T_destination = ~T_destination\n |  \n |  dump_patches = False\n\n"
     ]
    }
   ],
   "source": [
    "help(nn.GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[ 2.3055e-01,  2.5716e-02,  4.5740e-01,  3.7781e-01,  7.8190e-02,\n",
       "            1.8347e-01,  7.6843e-01, -2.5473e-01, -5.7000e-02, -2.6446e-02,\n",
       "           -8.3580e-02,  1.2621e-01,  3.4657e-02, -4.9156e-01,  4.4637e-01,\n",
       "            2.7897e-01, -5.4851e-02,  5.2738e-02, -4.7107e-01, -9.1475e-02],\n",
       "          [-2.7087e-01,  7.4617e-01,  8.9711e-02,  2.8086e-01, -2.7391e-01,\n",
       "           -2.5305e-01,  1.2640e+00, -7.5073e-02,  1.0244e+00, -2.2982e-01,\n",
       "            1.4906e-01, -3.9038e-01,  8.8065e-01,  5.4107e-01, -4.1802e-02,\n",
       "            4.5941e-01,  5.0731e-01, -8.6635e-02,  3.8593e-01, -6.1066e-01],\n",
       "          [-2.1145e-01,  2.0153e-01, -1.7278e-01, -2.3729e-01,  1.0064e+00,\n",
       "           -1.1166e-01,  6.5414e-01, -4.3845e-01,  1.5096e-01, -1.7989e-01,\n",
       "            3.8273e-01,  2.4047e-02, -3.5726e-01, -1.8464e-01, -2.2593e+00,\n",
       "           -5.6330e-01, -1.4881e+00,  8.3509e-01,  2.3473e-01, -4.8383e-01]],\n",
       " \n",
       "         [[ 1.1466e-01,  3.7165e-03,  1.6816e-01,  7.6023e-02, -1.0573e-01,\n",
       "            2.0894e-01,  2.7225e-01, -1.3051e-01, -2.5710e-02,  2.3979e-01,\n",
       "           -1.3551e-01, -3.2005e-02,  9.0259e-02, -3.5185e-01,  2.9148e-01,\n",
       "            9.7445e-02, -1.4297e-01, -1.7246e-01, -1.6917e-01, -2.7897e-01],\n",
       "          [-3.6757e-01,  4.0240e-01, -2.3671e-02,  1.6025e-01, -7.7304e-02,\n",
       "           -1.8224e-03,  8.4927e-01, -2.0699e-01,  6.5495e-01, -2.1774e-01,\n",
       "           -2.9949e-01, -1.5037e-01,  4.9375e-01,  2.6991e-01, -8.8561e-02,\n",
       "            1.7390e-01,  3.1011e-01, -1.8893e-01,  3.7842e-01, -3.7559e-01],\n",
       "          [-1.5121e-01,  9.2983e-02, -3.7742e-01, -1.8515e-01,  4.7643e-01,\n",
       "            6.7769e-02,  4.3344e-01, -5.8184e-02, -5.6994e-02,  2.0346e-01,\n",
       "            3.3583e-02, -6.1730e-02, -6.3201e-02, -3.4204e-01, -1.5479e+00,\n",
       "           -3.4943e-01, -7.4510e-01,  4.9036e-01, -1.8855e-02, -2.3442e-01]],\n",
       " \n",
       "         [[ 8.1826e-03, -2.1648e-02,  5.1203e-03, -1.4027e-01, -7.3935e-02,\n",
       "            2.1005e-01,  1.5979e-02, -5.8191e-02, -3.1012e-02,  2.7800e-01,\n",
       "           -1.9183e-01, -9.0557e-02,  2.6765e-02, -3.0957e-01,  2.1740e-01,\n",
       "           -4.3258e-02, -6.6129e-02, -2.4770e-01, -1.0869e-02, -2.1270e-01],\n",
       "          [-4.3311e-01,  2.6684e-01, -1.0873e-01, -8.8864e-02,  8.5994e-02,\n",
       "            3.8474e-02,  5.0831e-01, -2.1640e-01,  2.9670e-01, -7.1868e-02,\n",
       "           -4.4881e-01, -5.7986e-02,  1.9507e-01,  7.3372e-02,  3.8755e-03,\n",
       "           -7.1118e-02,  2.8188e-01, -3.2374e-01,  3.7504e-01, -1.2506e-01],\n",
       "          [-1.0066e-01,  1.1235e-01, -3.6014e-01, -1.5951e-01,  2.2797e-01,\n",
       "            7.1657e-02,  1.8538e-01,  1.2138e-01, -1.8088e-01,  3.8666e-01,\n",
       "           -1.6590e-01, -2.7152e-02,  1.2676e-01, -3.9999e-01, -9.4399e-01,\n",
       "           -2.9691e-01, -3.7347e-01,  1.5338e-01, -5.3517e-02, -8.6978e-02]],\n",
       " \n",
       "         [[-4.6443e-02,  9.5747e-02, -5.6948e-02, -1.8737e-01, -4.0952e-02,\n",
       "            1.2862e-01, -1.3485e-01, -6.5302e-02, -2.5682e-02,  2.8112e-01,\n",
       "           -2.8074e-01, -6.9497e-02,  1.1212e-01, -1.5737e-01,  6.5112e-02,\n",
       "           -1.9096e-01,  4.4789e-02, -2.5217e-01,  1.6250e-01, -6.3941e-02],\n",
       "          [-3.9687e-01,  1.7916e-01, -1.5797e-01, -2.4522e-01,  1.4122e-01,\n",
       "            4.4929e-02,  2.7809e-01, -1.8468e-01,  1.8643e-01,  1.4748e-02,\n",
       "           -4.7663e-01, -6.7615e-02,  4.9388e-02, -9.3883e-02,  4.4479e-02,\n",
       "           -1.7674e-01,  3.5398e-01, -3.4348e-01,  3.5868e-01,  4.4281e-02],\n",
       "          [-1.0732e-01,  7.8540e-02, -3.2681e-01, -1.6353e-01,  2.4337e-01,\n",
       "            6.0551e-02,  6.8117e-02,  1.3877e-01, -1.8771e-01,  3.7878e-01,\n",
       "           -3.2693e-01, -2.2036e-02,  9.5319e-02, -3.6138e-01, -4.6876e-01,\n",
       "           -2.7316e-01, -9.8084e-02, -2.3628e-02,  6.2946e-02,  1.4981e-02]],\n",
       " \n",
       "         [[-1.1980e-01,  1.6613e-01, -9.8589e-02, -2.4509e-01,  3.5718e-02,\n",
       "            8.3445e-02, -2.0901e-01, -7.2255e-02, -5.8295e-02,  2.6559e-01,\n",
       "           -3.4936e-01, -4.7557e-02,  8.2076e-02, -5.0021e-02, -1.6149e-02,\n",
       "           -3.1250e-01,  1.2984e-01, -2.5588e-01,  2.6303e-01,  4.0699e-02],\n",
       "          [-3.3074e-01,  4.5700e-02, -2.2918e-01, -2.9375e-01,  2.1314e-01,\n",
       "            5.7093e-02,  8.0135e-02, -1.2773e-01, -6.1014e-03,  3.1384e-02,\n",
       "           -4.7539e-01, -1.0439e-01,  3.3814e-02, -1.8570e-01,  6.1244e-02,\n",
       "           -2.7426e-01,  2.8559e-01, -3.5217e-01,  3.4884e-01,  8.0583e-02],\n",
       "          [-1.0204e-01,  5.1591e-02, -2.9493e-01, -1.8069e-01,  2.8122e-01,\n",
       "            1.3952e-01,  8.8718e-03,  1.5019e-01, -2.3403e-01,  2.8604e-01,\n",
       "           -3.6833e-01, -7.0061e-02,  2.9631e-03, -3.6131e-01, -1.3120e-01,\n",
       "           -2.1520e-01, -2.3147e-02, -1.1258e-01,  7.8409e-02,  3.0424e-02]]],\n",
       "        grad_fn=<StackBackward>),\n",
       " tensor([[[ 0.0942, -0.1563,  0.2826, -0.3494,  0.3965,  0.1896,  0.1607,\n",
       "           -0.1202, -0.3976, -0.4125, -0.6675, -0.0610,  0.1148,  0.3394,\n",
       "            0.1889, -0.2460, -0.0829,  0.0156, -0.5917,  0.3899],\n",
       "          [ 0.0559,  0.1528,  0.3999,  0.0224,  0.2356,  0.1937,  0.4042,\n",
       "            0.0410, -0.1147, -0.0838, -0.4968,  0.0867,  0.1476,  0.0958,\n",
       "           -0.0084,  0.0691, -0.2390,  0.0245, -0.3038,  0.1421],\n",
       "          [ 0.2709,  0.0168, -0.1869,  0.1389,  0.3549,  0.2470,  0.1531,\n",
       "            0.1930,  0.1695, -0.0960,  0.1218,  0.2383, -0.5001, -0.3344,\n",
       "           -0.1612,  0.1206, -0.1667,  0.2804, -0.0507, -0.0745]],\n",
       " \n",
       "         [[-0.1198,  0.1661, -0.0986, -0.2451,  0.0357,  0.0834, -0.2090,\n",
       "           -0.0723, -0.0583,  0.2656, -0.3494, -0.0476,  0.0821, -0.0500,\n",
       "           -0.0161, -0.3125,  0.1298, -0.2559,  0.2630,  0.0407],\n",
       "          [-0.3307,  0.0457, -0.2292, -0.2937,  0.2131,  0.0571,  0.0801,\n",
       "           -0.1277, -0.0061,  0.0314, -0.4754, -0.1044,  0.0338, -0.1857,\n",
       "            0.0612, -0.2743,  0.2856, -0.3522,  0.3488,  0.0806],\n",
       "          [-0.1020,  0.0516, -0.2949, -0.1807,  0.2812,  0.1395,  0.0089,\n",
       "            0.1502, -0.2340,  0.2860, -0.3683, -0.0701,  0.0030, -0.3613,\n",
       "           -0.1312, -0.2152, -0.0231, -0.1126,  0.0784,  0.0304]]],\n",
       "        grad_fn=<StackBackward>))"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "rnn = nn.GRU(10, 20, 2)\n",
    "inputs = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "outputs, hn = rnn(inputs, h0)\n",
    "outputs, hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here _get_weights corresponds to fatt, query is a decoder hidden state hi and values is a matrix of encoder hidden states s.\n",
    "class Attention(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, encoder_dim: int, decoder_dim: int):\n",
    "        super().__init__()\n",
    "        self.encoder_dim = encoder_dim\n",
    "        self.decoder_dim = decoder_dim\n",
    "    \n",
    "    def forward(self, \n",
    "        query: torch.Tensor,  # [decoder_dim]\n",
    "        values: torch.Tensor, # [seq_length, encoder_dim]\n",
    "        ):\n",
    "        weights = self._get_weights(query, values) # [seq_length] | not implemented\n",
    "        weights = torch.nn.functional.softmax(weights, dim=0)\n",
    "        return weights @ values  # [encoder_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additive attention uses a single-layer feedforward neural network with hyperbolic tangent nonlinearity to compute the weights aij:\n",
    "class AdditiveAttention(Attention):\n",
    "\n",
    "    def __init__(self, encoder_dim, decoder_dim):\n",
    "        super().__init__(encoder_dim, decoder_dim)\n",
    "        self.v = torch.nn.Parameter(\n",
    "            torch.FloatTensor(self.decoder_dim).uniform_(-0.1, 0.1))\n",
    "        self.W_1 = torch.nn.Linear(self.decoder_dim, self.decoder_dim)\n",
    "        self.W_2 = torch.nn.Linear(self.encoder_dim, self.decoder_dim)\n",
    "\n",
    "    def _get_weights(self,        \n",
    "        query: torch.Tensor,  # [decoder_dim]\n",
    "        values: torch.Tensor,  # [seq_length, encoder_dim]\n",
    "    ):\n",
    "        query = query.repeat(values.size(0), 1)  # [seq_length, decoder_dim]\n",
    "        weights = self.W_1(query) + self.W_2(values)  # [seq_length, decoder_dim]\n",
    "        return torch.tanh(weights) @ self.v  # [seq_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = AdditiveAttention(encoder_dim=10, decoder_dim = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Linear(in_features=20, out_features=20, bias=True)"
      ]
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "# attn._get_weights(torch.randn(10), torch.randn(3, 20))\n",
    "attn.W_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AdditiveAttention(\n",
       "  (W_1): Linear(in_features=20, out_features=20, bias=True)\n",
       "  (W_2): Linear(in_features=10, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = torch.randn(20) # [decoder dim]\n",
    "values = torch.randn(10, 10) # [seq_length, encoder dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = query.repeat(values.size(0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([10, 20])"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "attn.W_1(query2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([10, 20])"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "attn.W_2(values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.nn.Parameter(\n",
    "            torch.FloatTensor(20).uniform_(-0.1, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([20])"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = attn.W_1(query2) + attn.W_2(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 0.0325, -0.0951,  0.0298, -0.2375,  0.1206,  0.1327, -0.0260, -0.0677,\n",
       "         0.0685, -0.1237], grad_fn=<MvBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "torch.tanh(weights) @ v # return seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiplicativeAttention(Attention):\n",
    "\n",
    "    def __init__(self, encoder_dim: int, decoder_dim: int):\n",
    "        super().__init__(encoder_dim, decoder_dim)\n",
    "        self.W = torch.nn.Parameter(torch.FloatTensor(\n",
    "            self.decoder_dim, self.encoder_dim).uniform_(-0.1, 0.1))\n",
    "\n",
    "    def _get_weights(self,\n",
    "        query: torch.Tensor,  # [decoder_dim]\n",
    "        values: torch.Tensor, # [seq_length, encoder_dim]\n",
    "    ):\n",
    "        weights = query @ self.W @ values.T  # [seq_length]\n",
    "        return weights/np.sqrt(self.decoder_dim)  # [seq_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "mattn = MultiplicativeAttention(encoder_dim=10, decoder_dim=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_weights = query @ mattn.W @ values.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-0.3170,  0.1239, -1.0604, -1.0130, -0.2769, -0.7936,  1.5426, -0.8648,\n",
       "        -0.7662,  0.2843], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "m_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-0.0709,  0.0277, -0.2371, -0.2265, -0.0619, -0.1775,  0.3449, -0.1934,\n",
       "        -0.1713,  0.0636], grad_fn=<DivBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "m_weights/np.sqrt(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In practice, the attention mechanism handles queries at each time step of text generation\n",
    "attention = MultiplicativeAttention(encoder_dim=100, decoder_dim=50)\n",
    "decoder = torch.nn.LSTMCell(100, 50)\n",
    "encoder_hidden_states = torch.rand(10, 100)\n",
    "h, c = torch.rand(1, 50), torch.rand(1, 50)\n",
    "for step in range(13):\n",
    "    context_vector = attention(h.squeeze(0), encoder_hidden_states)\n",
    "    (h, c) = decoder(context_vector.unsqueeze(0), (h, c))\n",
    "    # Generating the next work based on h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "metadata": {},
     "execution_count": 116
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 355.79575 248.518125\" width=\"355.79575pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-04-16T11:46:42.173312</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M -0 248.518125 \r\nL 355.79575 248.518125 \r\nL 355.79575 0 \r\nL -0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 23.878125 224.64 \r\nL 291.718125 224.64 \r\nL 291.718125 7.2 \r\nL 23.878125 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"QuadMesh_1\">\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 23.878125 7.2 \r\nL 50.662125 7.2 \r\nL 50.662125 23.926154 \r\nL 23.878125 23.926154 \r\nL 23.878125 7.2 \r\n\" style=\"fill:#4c1d4b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 50.662125 7.2 \r\nL 77.446125 7.2 \r\nL 77.446125 23.926154 \r\nL 50.662125 23.926154 \r\nL 50.662125 7.2 \r\n\" style=\"fill:#511e4d;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 77.446125 7.2 \r\nL 104.230125 7.2 \r\nL 104.230125 23.926154 \r\nL 77.446125 23.926154 \r\nL 77.446125 7.2 \r\n\" style=\"fill:#871e5b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 104.230125 7.2 \r\nL 131.014125 7.2 \r\nL 131.014125 23.926154 \r\nL 104.230125 23.926154 \r\nL 104.230125 7.2 \r\n\" style=\"fill:#0d0a21;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 131.014125 7.2 \r\nL 157.798125 7.2 \r\nL 157.798125 23.926154 \r\nL 131.014125 23.926154 \r\nL 131.014125 7.2 \r\n\" style=\"fill:#35193e;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 157.798125 7.2 \r\nL 184.582125 7.2 \r\nL 184.582125 23.926154 \r\nL 157.798125 23.926154 \r\nL 157.798125 7.2 \r\n\" style=\"fill:#751f58;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 184.582125 7.2 \r\nL 211.366125 7.2 \r\nL 211.366125 23.926154 \r\nL 184.582125 23.926154 \r\nL 184.582125 7.2 \r\n\" style=\"fill:#931c5b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 211.366125 7.2 \r\nL 238.150125 7.2 \r\nL 238.150125 23.926154 \r\nL 211.366125 23.926154 \r\nL 211.366125 7.2 \r\n\" style=\"fill:#1b112b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 238.150125 7.2 \r\nL 264.934125 7.2 \r\nL 264.934125 23.926154 \r\nL 238.150125 23.926154 \r\nL 238.150125 7.2 \r\n\" style=\"fill:#9e1a5b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 264.934125 7.2 \r\nL 291.718125 7.2 \r\nL 291.718125 23.926154 \r\nL 264.934125 23.926154 \r\nL 264.934125 7.2 \r\n\" style=\"fill:#871e5b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 23.878125 23.926154 \r\nL 50.662125 23.926154 \r\nL 50.662125 40.652308 \r\nL 23.878125 40.652308 \r\nL 23.878125 23.926154 \r\n\" style=\"fill:#b51657;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 50.662125 23.926154 \r\nL 77.446125 23.926154 \r\nL 77.446125 40.652308 \r\nL 50.662125 40.652308 \r\nL 50.662125 23.926154 \r\n\" style=\"fill:#c21753;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 77.446125 23.926154 \r\nL 104.230125 23.926154 \r\nL 104.230125 40.652308 \r\nL 77.446125 40.652308 \r\nL 77.446125 23.926154 \r\n\" style=\"fill:#df2f44;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 104.230125 23.926154 \r\nL 131.014125 23.926154 \r\nL 131.014125 40.652308 \r\nL 104.230125 40.652308 \r\nL 104.230125 23.926154 \r\n\" style=\"fill:#681f55;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 131.014125 23.926154 \r\nL 157.798125 23.926154 \r\nL 157.798125 40.652308 \r\nL 131.014125 40.652308 \r\nL 131.014125 23.926154 \r\n\" style=\"fill:#971c5b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 157.798125 23.926154 \r\nL 184.582125 23.926154 \r\nL 184.582125 40.652308 \r\nL 157.798125 40.652308 \r\nL 157.798125 23.926154 \r\n\" style=\"fill:#cb1b4f;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 184.582125 23.926154 \r\nL 211.366125 23.926154 \r\nL 211.366125 40.652308 \r\nL 184.582125 40.652308 \r\nL 184.582125 23.926154 \r\n\" style=\"fill:#ee543f;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 211.366125 23.926154 \r\nL 238.150125 23.926154 \r\nL 238.150125 40.652308 \r\nL 211.366125 40.652308 \r\nL 211.366125 23.926154 \r\n\" style=\"fill:#701f57;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 238.150125 23.926154 \r\nL 264.934125 23.926154 \r\nL 264.934125 40.652308 \r\nL 238.150125 40.652308 \r\nL 238.150125 23.926154 \r\n\" style=\"fill:#ef5a41;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 264.934125 23.926154 \r\nL 291.718125 23.926154 \r\nL 291.718125 40.652308 \r\nL 264.934125 40.652308 \r\nL 264.934125 23.926154 \r\n\" style=\"fill:#e03143;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 23.878125 40.652308 \r\nL 50.662125 40.652308 \r\nL 50.662125 57.378462 \r\nL 23.878125 57.378462 \r\nL 23.878125 40.652308 \r\n\" style=\"fill:#a3195b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 50.662125 40.652308 \r\nL 77.446125 40.652308 \r\nL 77.446125 57.378462 \r\nL 50.662125 57.378462 \r\nL 50.662125 40.652308 \r\n\" style=\"fill:#b21758;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 77.446125 40.652308 \r\nL 104.230125 40.652308 \r\nL 104.230125 57.378462 \r\nL 77.446125 57.378462 \r\nL 77.446125 40.652308 \r\n\" style=\"fill:#d62449;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 104.230125 40.652308 \r\nL 131.014125 40.652308 \r\nL 131.014125 57.378462 \r\nL 104.230125 57.378462 \r\nL 104.230125 40.652308 \r\n\" style=\"fill:#591e50;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 131.014125 40.652308 \r\nL 157.798125 40.652308 \r\nL 157.798125 57.378462 \r\nL 131.014125 57.378462 \r\nL 131.014125 40.652308 \r\n\" style=\"fill:#7f1e5a;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 157.798125 40.652308 \r\nL 184.582125 40.652308 \r\nL 184.582125 57.378462 \r\nL 157.798125 57.378462 \r\nL 157.798125 40.652308 \r\n\" style=\"fill:#bf1654;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 184.582125 40.652308 \r\nL 211.366125 40.652308 \r\nL 211.366125 57.378462 \r\nL 184.582125 57.378462 \r\nL 184.582125 40.652308 \r\n\" style=\"fill:#e63b40;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 211.366125 40.652308 \r\nL 238.150125 40.652308 \r\nL 238.150125 57.378462 \r\nL 211.366125 57.378462 \r\nL 211.366125 40.652308 \r\n\" style=\"fill:#5c1e51;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 238.150125 40.652308 \r\nL 264.934125 40.652308 \r\nL 264.934125 57.378462 \r\nL 238.150125 57.378462 \r\nL 238.150125 40.652308 \r\n\" style=\"fill:#ea443e;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 264.934125 40.652308 \r\nL 291.718125 40.652308 \r\nL 291.718125 57.378462 \r\nL 264.934125 57.378462 \r\nL 264.934125 40.652308 \r\n\" style=\"fill:#de2e44;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 23.878125 57.378462 \r\nL 50.662125 57.378462 \r\nL 50.662125 74.104615 \r\nL 23.878125 74.104615 \r\nL 23.878125 57.378462 \r\n\" style=\"fill:#451c47;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 50.662125 57.378462 \r\nL 77.446125 57.378462 \r\nL 77.446125 74.104615 \r\nL 50.662125 74.104615 \r\nL 50.662125 57.378462 \r\n\" style=\"fill:#511e4d;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 77.446125 57.378462 \r\nL 104.230125 57.378462 \r\nL 104.230125 74.104615 \r\nL 77.446125 74.104615 \r\nL 77.446125 57.378462 \r\n\" style=\"fill:#821e5a;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 104.230125 57.378462 \r\nL 131.014125 57.378462 \r\nL 131.014125 74.104615 \r\nL 104.230125 74.104615 \r\nL 104.230125 57.378462 \r\n\" style=\"fill:#03051a;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 131.014125 57.378462 \r\nL 157.798125 57.378462 \r\nL 157.798125 74.104615 \r\nL 131.014125 74.104615 \r\nL 131.014125 57.378462 \r\n\" style=\"fill:#2b1637;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 157.798125 57.378462 \r\nL 184.582125 57.378462 \r\nL 184.582125 74.104615 \r\nL 157.798125 74.104615 \r\nL 157.798125 57.378462 \r\n\" style=\"fill:#6b1f56;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 184.582125 57.378462 \r\nL 211.366125 57.378462 \r\nL 211.366125 74.104615 \r\nL 184.582125 74.104615 \r\nL 184.582125 57.378462 \r\n\" style=\"fill:#921c5b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 211.366125 57.378462 \r\nL 238.150125 57.378462 \r\nL 238.150125 74.104615 \r\nL 211.366125 74.104615 \r\nL 211.366125 57.378462 \r\n\" style=\"fill:#160e27;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 238.150125 57.378462 \r\nL 264.934125 57.378462 \r\nL 264.934125 74.104615 \r\nL 238.150125 74.104615 \r\nL 238.150125 57.378462 \r\n\" style=\"fill:#9a1b5b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 264.934125 57.378462 \r\nL 291.718125 57.378462 \r\nL 291.718125 74.104615 \r\nL 264.934125 74.104615 \r\nL 264.934125 57.378462 \r\n\" style=\"fill:#751f58;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 23.878125 74.104615 \r\nL 50.662125 74.104615 \r\nL 50.662125 90.830769 \r\nL 23.878125 90.830769 \r\nL 23.878125 74.104615 \r\n\" style=\"fill:#bf1654;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 50.662125 74.104615 \r\nL 77.446125 74.104615 \r\nL 77.446125 90.830769 \r\nL 50.662125 90.830769 \r\nL 50.662125 74.104615 \r\n\" style=\"fill:#c21753;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 77.446125 74.104615 \r\nL 104.230125 74.104615 \r\nL 104.230125 90.830769 \r\nL 77.446125 90.830769 \r\nL 77.446125 74.104615 \r\n\" style=\"fill:#eb463e;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 104.230125 74.104615 \r\nL 131.014125 74.104615 \r\nL 131.014125 90.830769 \r\nL 104.230125 90.830769 \r\nL 104.230125 74.104615 \r\n\" style=\"fill:#731f58;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 131.014125 74.104615 \r\nL 157.798125 74.104615 \r\nL 157.798125 90.830769 \r\nL 131.014125 90.830769 \r\nL 131.014125 74.104615 \r\n\" style=\"fill:#9e1a5b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 157.798125 74.104615 \r\nL 184.582125 74.104615 \r\nL 184.582125 90.830769 \r\nL 157.798125 90.830769 \r\nL 157.798125 74.104615 \r\n\" style=\"fill:#dd2c45;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 184.582125 74.104615 \r\nL 211.366125 74.104615 \r\nL 211.366125 90.830769 \r\nL 184.582125 90.830769 \r\nL 184.582125 74.104615 \r\n\" style=\"fill:#ee543f;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 211.366125 74.104615 \r\nL 238.150125 74.104615 \r\nL 238.150125 90.830769 \r\nL 211.366125 90.830769 \r\nL 211.366125 74.104615 \r\n\" style=\"fill:#761f58;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 238.150125 74.104615 \r\nL 264.934125 74.104615 \r\nL 264.934125 90.830769 \r\nL 238.150125 90.830769 \r\nL 238.150125 74.104615 \r\n\" style=\"fill:#f16646;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 264.934125 74.104615 \r\nL 291.718125 74.104615 \r\nL 291.718125 90.830769 \r\nL 264.934125 90.830769 \r\nL 264.934125 74.104615 \r\n\" style=\"fill:#e8403e;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 23.878125 90.830769 \r\nL 50.662125 90.830769 \r\nL 50.662125 107.556923 \r\nL 23.878125 107.556923 \r\nL 23.878125 90.830769 \r\n\" style=\"fill:#f6b089;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 50.662125 90.830769 \r\nL 77.446125 90.830769 \r\nL 77.446125 107.556923 \r\nL 50.662125 107.556923 \r\nL 50.662125 90.830769 \r\n\" style=\"fill:#f6b38d;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 77.446125 90.830769 \r\nL 104.230125 90.830769 \r\nL 104.230125 107.556923 \r\nL 77.446125 107.556923 \r\nL 77.446125 90.830769 \r\n\" style=\"fill:#f8d1b8;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 104.230125 90.830769 \r\nL 131.014125 90.830769 \r\nL 131.014125 107.556923 \r\nL 104.230125 107.556923 \r\nL 104.230125 90.830769 \r\n\" style=\"fill:#ea443e;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 131.014125 90.830769 \r\nL 157.798125 90.830769 \r\nL 157.798125 107.556923 \r\nL 131.014125 107.556923 \r\nL 131.014125 90.830769 \r\n\" style=\"fill:#f58a61;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 157.798125 90.830769 \r\nL 184.582125 90.830769 \r\nL 184.582125 107.556923 \r\nL 157.798125 107.556923 \r\nL 157.798125 90.830769 \r\n\" style=\"fill:#f6b18b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 184.582125 90.830769 \r\nL 211.366125 90.830769 \r\nL 211.366125 107.556923 \r\nL 184.582125 107.556923 \r\nL 184.582125 90.830769 \r\n\" style=\"fill:#fae6d6;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 211.366125 90.830769 \r\nL 238.150125 90.830769 \r\nL 238.150125 107.556923 \r\nL 211.366125 107.556923 \r\nL 211.366125 90.830769 \r\n\" style=\"fill:#ed4e3e;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 238.150125 90.830769 \r\nL 264.934125 90.830769 \r\nL 264.934125 107.556923 \r\nL 238.150125 107.556923 \r\nL 238.150125 90.830769 \r\n\" style=\"fill:#faebdd;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 264.934125 90.830769 \r\nL 291.718125 90.830769 \r\nL 291.718125 107.556923 \r\nL 264.934125 107.556923 \r\nL 264.934125 90.830769 \r\n\" style=\"fill:#f7d0b5;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 23.878125 107.556923 \r\nL 50.662125 107.556923 \r\nL 50.662125 124.283077 \r\nL 23.878125 124.283077 \r\nL 23.878125 107.556923 \r\n\" style=\"fill:#701f57;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 50.662125 107.556923 \r\nL 77.446125 107.556923 \r\nL 77.446125 124.283077 \r\nL 50.662125 124.283077 \r\nL 50.662125 107.556923 \r\n\" style=\"fill:#761f58;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 77.446125 107.556923 \r\nL 104.230125 107.556923 \r\nL 104.230125 124.283077 \r\nL 77.446125 124.283077 \r\nL 77.446125 107.556923 \r\n\" style=\"fill:#951c5b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 104.230125 107.556923 \r\nL 131.014125 107.556923 \r\nL 131.014125 124.283077 \r\nL 104.230125 124.283077 \r\nL 104.230125 107.556923 \r\n\" style=\"fill:#130d25;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 131.014125 107.556923 \r\nL 157.798125 107.556923 \r\nL 157.798125 124.283077 \r\nL 131.014125 124.283077 \r\nL 131.014125 107.556923 \r\n\" style=\"fill:#461c48;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 157.798125 107.556923 \r\nL 184.582125 107.556923 \r\nL 184.582125 124.283077 \r\nL 157.798125 124.283077 \r\nL 157.798125 107.556923 \r\n\" style=\"fill:#871e5b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 184.582125 107.556923 \r\nL 211.366125 107.556923 \r\nL 211.366125 124.283077 \r\nL 184.582125 124.283077 \r\nL 184.582125 107.556923 \r\n\" style=\"fill:#ab185a;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 211.366125 107.556923 \r\nL 238.150125 107.556923 \r\nL 238.150125 124.283077 \r\nL 211.366125 124.283077 \r\nL 211.366125 107.556923 \r\n\" style=\"fill:#1a102a;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 238.150125 107.556923 \r\nL 264.934125 107.556923 \r\nL 264.934125 124.283077 \r\nL 238.150125 124.283077 \r\nL 238.150125 107.556923 \r\n\" style=\"fill:#b01759;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 264.934125 107.556923 \r\nL 291.718125 107.556923 \r\nL 291.718125 124.283077 \r\nL 264.934125 124.283077 \r\nL 264.934125 107.556923 \r\n\" style=\"fill:#821e5a;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 23.878125 124.283077 \r\nL 50.662125 124.283077 \r\nL 50.662125 141.009231 \r\nL 23.878125 141.009231 \r\nL 23.878125 124.283077 \r\n\" style=\"fill:#ef5a41;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 50.662125 124.283077 \r\nL 77.446125 124.283077 \r\nL 77.446125 141.009231 \r\nL 50.662125 141.009231 \r\nL 50.662125 124.283077 \r\n\" style=\"fill:#f16244;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 77.446125 124.283077 \r\nL 104.230125 124.283077 \r\nL 104.230125 141.009231 \r\nL 77.446125 141.009231 \r\nL 77.446125 124.283077 \r\n\" style=\"fill:#f4865e;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 104.230125 124.283077 \r\nL 131.014125 124.283077 \r\nL 131.014125 141.009231 \r\nL 104.230125 141.009231 \r\nL 104.230125 124.283077 \r\n\" style=\"fill:#bc1656;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 131.014125 124.283077 \r\nL 157.798125 124.283077 \r\nL 157.798125 141.009231 \r\nL 131.014125 141.009231 \r\nL 131.014125 124.283077 \r\n\" style=\"fill:#e53940;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 157.798125 124.283077 \r\nL 184.582125 124.283077 \r\nL 184.582125 141.009231 \r\nL 157.798125 141.009231 \r\nL 157.798125 124.283077 \r\n\" style=\"fill:#f47c55;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 184.582125 124.283077 \r\nL 211.366125 124.283077 \r\nL 211.366125 141.009231 \r\nL 184.582125 141.009231 \r\nL 184.582125 124.283077 \r\n\" style=\"fill:#f6a47c;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 211.366125 124.283077 \r\nL 238.150125 124.283077 \r\nL 238.150125 141.009231 \r\nL 211.366125 141.009231 \r\nL 211.366125 124.283077 \r\n\" style=\"fill:#bd1655;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 238.150125 124.283077 \r\nL 264.934125 124.283077 \r\nL 264.934125 141.009231 \r\nL 238.150125 141.009231 \r\nL 238.150125 124.283077 \r\n\" style=\"fill:#f6b089;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 264.934125 124.283077 \r\nL 291.718125 124.283077 \r\nL 291.718125 141.009231 \r\nL 264.934125 141.009231 \r\nL 264.934125 124.283077 \r\n\" style=\"fill:#f4835b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 23.878125 141.009231 \r\nL 50.662125 141.009231 \r\nL 50.662125 157.735385 \r\nL 23.878125 157.735385 \r\nL 23.878125 141.009231 \r\n\" style=\"fill:#9e1a5b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 50.662125 141.009231 \r\nL 77.446125 141.009231 \r\nL 77.446125 157.735385 \r\nL 50.662125 157.735385 \r\nL 50.662125 141.009231 \r\n\" style=\"fill:#981b5b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 77.446125 141.009231 \r\nL 104.230125 141.009231 \r\nL 104.230125 157.735385 \r\nL 77.446125 157.735385 \r\nL 77.446125 141.009231 \r\n\" style=\"fill:#c21753;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 104.230125 141.009231 \r\nL 131.014125 141.009231 \r\nL 131.014125 157.735385 \r\nL 104.230125 157.735385 \r\nL 104.230125 141.009231 \r\n\" style=\"fill:#451c47;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 131.014125 141.009231 \r\nL 157.798125 141.009231 \r\nL 157.798125 157.735385 \r\nL 131.014125 157.735385 \r\nL 131.014125 141.009231 \r\n\" style=\"fill:#751f58;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 157.798125 141.009231 \r\nL 184.582125 141.009231 \r\nL 184.582125 157.735385 \r\nL 157.798125 157.735385 \r\nL 157.798125 141.009231 \r\n\" style=\"fill:#af1759;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 184.582125 141.009231 \r\nL 211.366125 141.009231 \r\nL 211.366125 157.735385 \r\nL 184.582125 157.735385 \r\nL 184.582125 141.009231 \r\n\" style=\"fill:#dc2b46;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 211.366125 141.009231 \r\nL 238.150125 141.009231 \r\nL 238.150125 157.735385 \r\nL 211.366125 157.735385 \r\nL 211.366125 141.009231 \r\n\" style=\"fill:#461c48;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 238.150125 141.009231 \r\nL 264.934125 141.009231 \r\nL 264.934125 157.735385 \r\nL 238.150125 157.735385 \r\nL 238.150125 141.009231 \r\n\" style=\"fill:#dd2c45;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 264.934125 141.009231 \r\nL 291.718125 141.009231 \r\nL 291.718125 157.735385 \r\nL 264.934125 157.735385 \r\nL 264.934125 141.009231 \r\n\" style=\"fill:#c71951;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 23.878125 157.735385 \r\nL 50.662125 157.735385 \r\nL 50.662125 174.461538 \r\nL 23.878125 174.461538 \r\nL 23.878125 157.735385 \r\n\" style=\"fill:#f4845d;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 50.662125 157.735385 \r\nL 77.446125 157.735385 \r\nL 77.446125 174.461538 \r\nL 50.662125 174.461538 \r\nL 50.662125 157.735385 \r\n\" style=\"fill:#f47f58;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 77.446125 157.735385 \r\nL 104.230125 157.735385 \r\nL 104.230125 174.461538 \r\nL 77.446125 174.461538 \r\nL 77.446125 157.735385 \r\n\" style=\"fill:#f6ae87;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 104.230125 157.735385 \r\nL 131.014125 157.735385 \r\nL 131.014125 174.461538 \r\nL 104.230125 174.461538 \r\nL 104.230125 157.735385 \r\n\" style=\"fill:#db2946;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 131.014125 157.735385 \r\nL 157.798125 157.735385 \r\nL 157.798125 174.461538 \r\nL 131.014125 174.461538 \r\nL 131.014125 157.735385 \r\n\" style=\"fill:#ee543f;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 157.798125 157.735385 \r\nL 184.582125 157.735385 \r\nL 184.582125 174.461538 \r\nL 157.798125 174.461538 \r\nL 157.798125 157.735385 \r\n\" style=\"fill:#f6a178;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 184.582125 157.735385 \r\nL 211.366125 157.735385 \r\nL 211.366125 174.461538 \r\nL 184.582125 174.461538 \r\nL 184.582125 157.735385 \r\n\" style=\"fill:#f8d1b8;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 211.366125 157.735385 \r\nL 238.150125 157.735385 \r\nL 238.150125 174.461538 \r\nL 211.366125 174.461538 \r\nL 211.366125 157.735385 \r\n\" style=\"fill:#dc2b46;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 238.150125 157.735385 \r\nL 264.934125 157.735385 \r\nL 264.934125 174.461538 \r\nL 238.150125 174.461538 \r\nL 238.150125 157.735385 \r\n\" style=\"fill:#f7c9aa;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 264.934125 157.735385 \r\nL 291.718125 157.735385 \r\nL 291.718125 174.461538 \r\nL 264.934125 174.461538 \r\nL 264.934125 157.735385 \r\n\" style=\"fill:#f6ad85;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 23.878125 174.461538 \r\nL 50.662125 174.461538 \r\nL 50.662125 191.187692 \r\nL 23.878125 191.187692 \r\nL 23.878125 174.461538 \r\n\" style=\"fill:#ce1d4e;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 50.662125 174.461538 \r\nL 77.446125 174.461538 \r\nL 77.446125 191.187692 \r\nL 50.662125 191.187692 \r\nL 50.662125 174.461538 \r\n\" style=\"fill:#d3214b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 77.446125 174.461538 \r\nL 104.230125 174.461538 \r\nL 104.230125 191.187692 \r\nL 77.446125 191.187692 \r\nL 77.446125 174.461538 \r\n\" style=\"fill:#ec4a3e;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 104.230125 174.461538 \r\nL 131.014125 174.461538 \r\nL 131.014125 191.187692 \r\nL 104.230125 191.187692 \r\nL 104.230125 174.461538 \r\n\" style=\"fill:#7f1e5a;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 131.014125 174.461538 \r\nL 157.798125 174.461538 \r\nL 157.798125 191.187692 \r\nL 131.014125 191.187692 \r\nL 131.014125 174.461538 \r\n\" style=\"fill:#a4195b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 157.798125 174.461538 \r\nL 184.582125 174.461538 \r\nL 184.582125 191.187692 \r\nL 157.798125 191.187692 \r\nL 157.798125 174.461538 \r\n\" style=\"fill:#dc2b46;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 184.582125 174.461538 \r\nL 211.366125 174.461538 \r\nL 211.366125 191.187692 \r\nL 184.582125 191.187692 \r\nL 184.582125 174.461538 \r\n\" style=\"fill:#f05e42;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 211.366125 174.461538 \r\nL 238.150125 174.461538 \r\nL 238.150125 191.187692 \r\nL 211.366125 191.187692 \r\nL 211.366125 174.461538 \r\n\" style=\"fill:#731f58;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 238.150125 174.461538 \r\nL 264.934125 174.461538 \r\nL 264.934125 191.187692 \r\nL 238.150125 191.187692 \r\nL 238.150125 174.461538 \r\n\" style=\"fill:#f16445;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 264.934125 174.461538 \r\nL 291.718125 174.461538 \r\nL 291.718125 191.187692 \r\nL 264.934125 191.187692 \r\nL 264.934125 174.461538 \r\n\" style=\"fill:#ec4a3e;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 23.878125 191.187692 \r\nL 50.662125 191.187692 \r\nL 50.662125 207.913846 \r\nL 23.878125 207.913846 \r\nL 23.878125 191.187692 \r\n\" style=\"fill:#c41753;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 50.662125 191.187692 \r\nL 77.446125 191.187692 \r\nL 77.446125 207.913846 \r\nL 50.662125 207.913846 \r\nL 50.662125 191.187692 \r\n\" style=\"fill:#c71951;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 77.446125 191.187692 \r\nL 104.230125 191.187692 \r\nL 104.230125 207.913846 \r\nL 77.446125 207.913846 \r\nL 77.446125 191.187692 \r\n\" style=\"fill:#e43841;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 104.230125 191.187692 \r\nL 131.014125 191.187692 \r\nL 131.014125 207.913846 \r\nL 104.230125 207.913846 \r\nL 104.230125 191.187692 \r\n\" style=\"fill:#681f55;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 131.014125 191.187692 \r\nL 157.798125 191.187692 \r\nL 157.798125 207.913846 \r\nL 131.014125 207.913846 \r\nL 131.014125 191.187692 \r\n\" style=\"fill:#981b5b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 157.798125 191.187692 \r\nL 184.582125 191.187692 \r\nL 184.582125 207.913846 \r\nL 157.798125 207.913846 \r\nL 157.798125 191.187692 \r\n\" style=\"fill:#d82748;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 184.582125 191.187692 \r\nL 211.366125 191.187692 \r\nL 211.366125 207.913846 \r\nL 184.582125 207.913846 \r\nL 184.582125 191.187692 \r\n\" style=\"fill:#ec4a3e;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 211.366125 191.187692 \r\nL 238.150125 191.187692 \r\nL 238.150125 207.913846 \r\nL 211.366125 207.913846 \r\nL 211.366125 191.187692 \r\n\" style=\"fill:#691f55;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 238.150125 191.187692 \r\nL 264.934125 191.187692 \r\nL 264.934125 207.913846 \r\nL 238.150125 207.913846 \r\nL 238.150125 191.187692 \r\n\" style=\"fill:#ee543f;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 264.934125 191.187692 \r\nL 291.718125 191.187692 \r\nL 291.718125 207.913846 \r\nL 264.934125 207.913846 \r\nL 264.934125 191.187692 \r\n\" style=\"fill:#d62449;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 23.878125 207.913846 \r\nL 50.662125 207.913846 \r\nL 50.662125 224.64 \r\nL 23.878125 224.64 \r\nL 23.878125 207.913846 \r\n\" style=\"fill:#9e1a5b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 50.662125 207.913846 \r\nL 77.446125 207.913846 \r\nL 77.446125 224.64 \r\nL 50.662125 224.64 \r\nL 50.662125 207.913846 \r\n\" style=\"fill:#9c1b5b;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 77.446125 207.913846 \r\nL 104.230125 207.913846 \r\nL 104.230125 224.64 \r\nL 77.446125 224.64 \r\nL 77.446125 207.913846 \r\n\" style=\"fill:#c11754;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 104.230125 207.913846 \r\nL 131.014125 207.913846 \r\nL 131.014125 224.64 \r\nL 104.230125 224.64 \r\nL 104.230125 207.913846 \r\n\" style=\"fill:#421b45;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 131.014125 207.913846 \r\nL 157.798125 207.913846 \r\nL 157.798125 224.64 \r\nL 131.014125 224.64 \r\nL 131.014125 207.913846 \r\n\" style=\"fill:#6b1f56;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 157.798125 207.913846 \r\nL 184.582125 207.913846 \r\nL 184.582125 224.64 \r\nL 157.798125 224.64 \r\nL 157.798125 207.913846 \r\n\" style=\"fill:#b01759;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 184.582125 207.913846 \r\nL 211.366125 207.913846 \r\nL 211.366125 224.64 \r\nL 184.582125 224.64 \r\nL 184.582125 207.913846 \r\n\" style=\"fill:#dc2b46;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 211.366125 207.913846 \r\nL 238.150125 207.913846 \r\nL 238.150125 224.64 \r\nL 211.366125 224.64 \r\nL 211.366125 207.913846 \r\n\" style=\"fill:#3c1a42;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 238.150125 207.913846 \r\nL 264.934125 207.913846 \r\nL 264.934125 224.64 \r\nL 238.150125 224.64 \r\nL 238.150125 207.913846 \r\n\" style=\"fill:#e43841;\"/>\r\n    <path clip-path=\"url(#p008893592e)\" d=\"M 264.934125 207.913846 \r\nL 291.718125 207.913846 \r\nL 291.718125 224.64 \r\nL 264.934125 224.64 \r\nL 264.934125 207.913846 \r\n\" style=\"fill:#cf1e4d;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m963fca97d6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"37.270125\" xlink:href=\"#m963fca97d6\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(34.088875 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"64.054125\" xlink:href=\"#m963fca97d6\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 1 -->\r\n      <g transform=\"translate(60.872875 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"90.838125\" xlink:href=\"#m963fca97d6\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 2 -->\r\n      <g transform=\"translate(87.656875 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"117.622125\" xlink:href=\"#m963fca97d6\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 3 -->\r\n      <g transform=\"translate(114.440875 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"144.406125\" xlink:href=\"#m963fca97d6\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 4 -->\r\n      <g transform=\"translate(141.224875 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"171.190125\" xlink:href=\"#m963fca97d6\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(168.008875 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"197.974125\" xlink:href=\"#m963fca97d6\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 6 -->\r\n      <g transform=\"translate(194.792875 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.758125\" xlink:href=\"#m963fca97d6\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 7 -->\r\n      <g transform=\"translate(221.576875 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_9\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"251.542125\" xlink:href=\"#m963fca97d6\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 8 -->\r\n      <g transform=\"translate(248.360875 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_10\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"278.326125\" xlink:href=\"#m963fca97d6\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 9 -->\r\n      <g transform=\"translate(275.144875 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.984375 1.515625 \r\nL 10.984375 10.5 \r\nQ 14.703125 8.734375 18.5 7.8125 \r\nQ 22.3125 6.890625 25.984375 6.890625 \r\nQ 35.75 6.890625 40.890625 13.453125 \r\nQ 46.046875 20.015625 46.78125 33.40625 \r\nQ 43.953125 29.203125 39.59375 26.953125 \r\nQ 35.25 24.703125 29.984375 24.703125 \r\nQ 19.046875 24.703125 12.671875 31.3125 \r\nQ 6.296875 37.9375 6.296875 49.421875 \r\nQ 6.296875 60.640625 12.9375 67.421875 \r\nQ 19.578125 74.21875 30.609375 74.21875 \r\nQ 43.265625 74.21875 49.921875 64.515625 \r\nQ 56.59375 54.828125 56.59375 36.375 \r\nQ 56.59375 19.140625 48.40625 8.859375 \r\nQ 40.234375 -1.421875 26.421875 -1.421875 \r\nQ 22.703125 -1.421875 18.890625 -0.6875 \r\nQ 15.09375 0.046875 10.984375 1.515625 \r\nz\r\nM 30.609375 32.421875 \r\nQ 37.25 32.421875 41.125 36.953125 \r\nQ 45.015625 41.5 45.015625 49.421875 \r\nQ 45.015625 57.28125 41.125 61.84375 \r\nQ 37.25 66.40625 30.609375 66.40625 \r\nQ 23.96875 66.40625 20.09375 61.84375 \r\nQ 16.21875 57.28125 16.21875 49.421875 \r\nQ 16.21875 41.5 20.09375 36.953125 \r\nQ 23.96875 32.421875 30.609375 32.421875 \r\nz\r\n\" id=\"DejaVuSans-57\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-57\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_11\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"medf8047a55\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"23.878125\" xlink:href=\"#medf8047a55\" y=\"15.563077\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(14.798438 18.126358)rotate(-90)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"23.878125\" xlink:href=\"#medf8047a55\" y=\"32.289231\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 1 -->\r\n      <g transform=\"translate(14.798438 34.852512)rotate(-90)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"23.878125\" xlink:href=\"#medf8047a55\" y=\"49.015385\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 2 -->\r\n      <g transform=\"translate(14.798438 51.578666)rotate(-90)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"23.878125\" xlink:href=\"#medf8047a55\" y=\"65.741538\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 3 -->\r\n      <g transform=\"translate(14.798438 68.30482)rotate(-90)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"23.878125\" xlink:href=\"#medf8047a55\" y=\"82.467692\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 4 -->\r\n      <g transform=\"translate(14.798438 85.030974)rotate(-90)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_16\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"23.878125\" xlink:href=\"#medf8047a55\" y=\"99.193846\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_16\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(14.798438 101.757127)rotate(-90)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_17\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"23.878125\" xlink:href=\"#medf8047a55\" y=\"115.92\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_17\">\r\n      <!-- 6 -->\r\n      <g transform=\"translate(14.798438 118.483281)rotate(-90)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_18\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"23.878125\" xlink:href=\"#medf8047a55\" y=\"132.646154\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_18\">\r\n      <!-- 7 -->\r\n      <g transform=\"translate(14.798438 135.209435)rotate(-90)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_19\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"23.878125\" xlink:href=\"#medf8047a55\" y=\"149.372308\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_19\">\r\n      <!-- 8 -->\r\n      <g transform=\"translate(14.798438 151.935589)rotate(-90)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_10\">\r\n     <g id=\"line2d_20\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"23.878125\" xlink:href=\"#medf8047a55\" y=\"166.098462\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_20\">\r\n      <!-- 9 -->\r\n      <g transform=\"translate(14.798438 168.661743)rotate(-90)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-57\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_11\">\r\n     <g id=\"line2d_21\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"23.878125\" xlink:href=\"#medf8047a55\" y=\"182.824615\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_21\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(14.798438 191.750397)rotate(-90)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_12\">\r\n     <g id=\"line2d_22\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"23.878125\" xlink:href=\"#medf8047a55\" y=\"199.550769\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_22\">\r\n      <!-- 11 -->\r\n      <g transform=\"translate(14.798438 208.47655)rotate(-90)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_13\">\r\n     <g id=\"line2d_23\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"23.878125\" xlink:href=\"#medf8047a55\" y=\"216.276923\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_23\">\r\n      <!-- 12 -->\r\n      <g transform=\"translate(14.798438 225.202704)rotate(-90)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n  <g id=\"axes_2\">\r\n   <g id=\"patch_3\">\r\n    <path clip-path=\"url(#pfd66fdce92)\" d=\"M 308.458125 224.64 \r\nL 308.458125 223.790625 \r\nL 308.458125 8.049375 \r\nL 308.458125 7.2 \r\nL 319.330125 7.2 \r\nL 319.330125 8.049375 \r\nL 319.330125 223.790625 \r\nL 319.330125 224.64 \r\nz\r\n\" style=\"fill:#ffffff;stroke:#ffffff;stroke-linejoin:miter;stroke-width:0.01;\"/>\r\n   </g>\r\n   <image height=\"217\" id=\"imagedd5ec9bcfa\" transform=\"scale(1 -1)translate(0 -217)\" width=\"11\" x=\"308\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAAAsAAADZCAYAAAD2WsoCAAABX0lEQVR4nNWa2w0DMQjAeN0S3X/OXlfAH5ZovhEyhqS5qDnP543lmszcxtLgAMFdJWUurcAiGCgzsuFhHPHc6dk4MXWoQLEpNzKb7dZsaBgTaDb2y5wNrd0QY7/Mk58EjzZIzIbXbm9brUPp8HvqoA2AIarTmJGNI8wIg+1ukpkVuP48+FsbJJjY8DDmBgZrN2EehHHEhoYx7z61uAfrBgaykWExwwIBRjNmEgxEi+oSnAXTJLhIMMKAmdexMV1fKbNYIDjsGHM1sAGZAQZSJ9oYbTYQs6auwFWGYYQ3G14wuPeQxx6qjmUGN3OWGdwLJgiGx8wwwM8mzEyeLFBmGEze6zQbQZ4NPRtJbES3hIGa4nnO0QoU200yoz0IPnlVG6SDHgaywc461EFLHdzdGoZXIMrcaPhvMLN2o3nWNmzemDrRBinwxvBnP1Jmc/iJZ9Ju9C+LKwWydmtnnVXgD2R4KiPLLY7SAAAAAElFTkSuQmCC\" y=\"-7\"/>\r\n   <g id=\"matplotlib.axis_3\"/>\r\n   <g id=\"matplotlib.axis_4\">\r\n    <g id=\"ytick_14\">\r\n     <g id=\"line2d_24\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 3.5 0 \r\n\" id=\"me32e5ab81d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"319.330125\" xlink:href=\"#me32e5ab81d\" y=\"199.10314\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_24\">\r\n      <!-- 0.00 -->\r\n      <g transform=\"translate(326.330125 202.902359)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_15\">\r\n     <g id=\"line2d_25\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"319.330125\" xlink:href=\"#me32e5ab81d\" y=\"164.178941\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_25\">\r\n      <!-- 0.05 -->\r\n      <g transform=\"translate(326.330125 167.97816)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_16\">\r\n     <g id=\"line2d_26\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"319.330125\" xlink:href=\"#me32e5ab81d\" y=\"129.254742\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_26\">\r\n      <!-- 0.10 -->\r\n      <g transform=\"translate(326.330125 133.053961)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_17\">\r\n     <g id=\"line2d_27\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"319.330125\" xlink:href=\"#me32e5ab81d\" y=\"94.330543\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_27\">\r\n      <!-- 0.15 -->\r\n      <g transform=\"translate(326.330125 98.129762)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_18\">\r\n     <g id=\"line2d_28\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"319.330125\" xlink:href=\"#me32e5ab81d\" y=\"59.406344\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_28\">\r\n      <!-- 0.20 -->\r\n      <g transform=\"translate(326.330125 63.205563)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_19\">\r\n     <g id=\"line2d_29\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"319.330125\" xlink:href=\"#me32e5ab81d\" y=\"24.482145\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_29\">\r\n      <!-- 0.25 -->\r\n      <g transform=\"translate(326.330125 28.281364)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 308.458125 224.64 \r\nL 308.458125 223.790625 \r\nL 308.458125 8.049375 \r\nL 308.458125 7.2 \r\nL 319.330125 7.2 \r\nL 319.330125 8.049375 \r\nL 319.330125 223.790625 \r\nL 319.330125 224.64 \r\nz\r\n\" style=\"fill:none;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p008893592e\">\r\n   <rect height=\"217.44\" width=\"267.84\" x=\"23.878125\" y=\"7.2\"/>\r\n  </clipPath>\r\n  <clipPath id=\"pfd66fdce92\">\r\n   <rect height=\"217.44\" width=\"10.872\" x=\"308.458125\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "encoder_dim, decoder_dim, encoder_seq_length, decoder_seq_length = 100, 50, 10, 13\n",
    "attention = AdditiveAttention(encoder_dim, decoder_dim)\n",
    "encoder_hidden_states = torch.rand(encoder_seq_length, encoder_dim)\n",
    "decoder_hidden_states = torch.rand(decoder_seq_length, decoder_dim)\n",
    "weights = torch.FloatTensor(decoder_seq_length, encoder_seq_length)\n",
    "for step in range(decoder_seq_length):\n",
    "    context_vector = attention(decoder_hidden_states[step], encoder_hidden_states)\n",
    "    weights[step] = attention._get_weights(decoder_hidden_states[step], encoder_hidden_states)\n",
    "seaborn.heatmap(weights.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on class BCEWithLogitsLoss in module torch.nn.modules.loss:\n\nclass BCEWithLogitsLoss(_Loss)\n |  BCEWithLogitsLoss(weight: Union[torch.Tensor, NoneType] = None, size_average=None, reduce=None, reduction: str = 'mean', pos_weight: Union[torch.Tensor, NoneType] = None) -> None\n |  \n |  This loss combines a `Sigmoid` layer and the `BCELoss` in one single\n |  class. This version is more numerically stable than using a plain `Sigmoid`\n |  followed by a `BCELoss` as, by combining the operations into one layer,\n |  we take advantage of the log-sum-exp trick for numerical stability.\n |  \n |  The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n |  \n |  .. math::\n |      \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n |      l_n = - w_n \\left[ y_n \\cdot \\log \\sigma(x_n)\n |      + (1 - y_n) \\cdot \\log (1 - \\sigma(x_n)) \\right],\n |  \n |  where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n |  (default ``'mean'``), then\n |  \n |  .. math::\n |      \\ell(x, y) = \\begin{cases}\n |          \\operatorname{mean}(L), & \\text{if reduction} = \\text{'mean';}\\\\\n |          \\operatorname{sum}(L),  & \\text{if reduction} = \\text{'sum'.}\n |      \\end{cases}\n |  \n |  This is used for measuring the error of a reconstruction in for example\n |  an auto-encoder. Note that the targets `t[i]` should be numbers\n |  between 0 and 1.\n |  \n |  It's possible to trade off recall and precision by adding weights to positive examples.\n |  In the case of multi-label classification the loss can be described as:\n |  \n |  .. math::\n |      \\ell_c(x, y) = L_c = \\{l_{1,c},\\dots,l_{N,c}\\}^\\top, \\quad\n |      l_{n,c} = - w_{n,c} \\left[ p_c y_{n,c} \\cdot \\log \\sigma(x_{n,c})\n |      + (1 - y_{n,c}) \\cdot \\log (1 - \\sigma(x_{n,c})) \\right],\n |  \n |  where :math:`c` is the class number (:math:`c > 1` for multi-label binary classification,\n |  :math:`c = 1` for single-label binary classification),\n |  :math:`n` is the number of the sample in the batch and\n |  :math:`p_c` is the weight of the positive answer for the class :math:`c`.\n |  \n |  :math:`p_c > 1` increases the recall, :math:`p_c < 1` increases the precision.\n |  \n |  For example, if a dataset contains 100 positive and 300 negative examples of a single class,\n |  then `pos_weight` for the class should be equal to :math:`\\frac{300}{100}=3`.\n |  The loss would act as if the dataset contains :math:`3\\times 100=300` positive examples.\n |  \n |  Examples::\n |  \n |      >>> target = torch.ones([10, 64], dtype=torch.float32)  # 64 classes, batch size = 10\n |      >>> output = torch.full([10, 64], 1.5)  # A prediction (logit)\n |      >>> pos_weight = torch.ones([64])  # All weights are equal to 1\n |      >>> criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n |      >>> criterion(output, target)  # -log(sigmoid(1.5))\n |      tensor(0.2014)\n |  \n |  Args:\n |      weight (Tensor, optional): a manual rescaling weight given to the loss\n |          of each batch element. If given, has to be a Tensor of size `nbatch`.\n |      size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n |          the losses are averaged over each loss element in the batch. Note that for\n |          some losses, there are multiple elements per sample. If the field :attr:`size_average`\n |          is set to ``False``, the losses are instead summed for each minibatch. Ignored\n |          when reduce is ``False``. Default: ``True``\n |      reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n |          losses are averaged or summed over observations for each minibatch depending\n |          on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n |          batch element instead and ignores :attr:`size_average`. Default: ``True``\n |      reduction (string, optional): Specifies the reduction to apply to the output:\n |          ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n |          ``'mean'``: the sum of the output will be divided by the number of\n |          elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n |          and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n |          specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n |      pos_weight (Tensor, optional): a weight of positive examples.\n |              Must be a vector with length equal to the number of classes.\n |  \n |  Shape:\n |      - Input: :math:`(N, *)` where :math:`*` means, any number of additional dimensions\n |      - Target: :math:`(N, *)`, same shape as the input\n |      - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(N, *)`, same\n |        shape as input.\n |  \n |   Examples::\n |  \n |      >>> loss = nn.BCEWithLogitsLoss()\n |      >>> input = torch.randn(3, requires_grad=True)\n |      >>> target = torch.empty(3).random_(2)\n |      >>> output = loss(input, target)\n |      >>> output.backward()\n |  \n |  Method resolution order:\n |      BCEWithLogitsLoss\n |      _Loss\n |      torch.nn.modules.module.Module\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, weight: Union[torch.Tensor, NoneType] = None, size_average=None, reduce=None, reduction: str = 'mean', pos_weight: Union[torch.Tensor, NoneType] = None) -> None\n |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n |  \n |  forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor\n |      Defines the computation performed at every call.\n |      \n |      Should be overridden by all subclasses.\n |      \n |      .. note::\n |          Although the recipe for forward pass needs to be defined within\n |          this function, one should call the :class:`Module` instance afterwards\n |          instead of this since the former takes care of running the\n |          registered hooks while the latter silently ignores them.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from _Loss:\n |  \n |  __annotations__ = {'reduction': <class 'str'>}\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from torch.nn.modules.module.Module:\n |  \n |  __call__ = _call_impl(self, *input, **kwargs)\n |  \n |  __delattr__(self, name)\n |      Implement delattr(self, name).\n |  \n |  __dir__(self)\n |      Default dir() implementation.\n |  \n |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n |  \n |  __repr__(self)\n |      Return repr(self).\n |  \n |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n |      Implement setattr(self, name, value).\n |  \n |  __setstate__(self, state)\n |  \n |  add_module(self, name: str, module: Union[ForwardRef('Module'), NoneType]) -> None\n |      Adds a child module to the current module.\n |      \n |      The module can be accessed as an attribute using the given name.\n |      \n |      Args:\n |          name (string): name of the child module. The child module can be\n |              accessed from this module using the given name\n |          module (Module): child module to be added to the module.\n |  \n |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n |      as well as self. Typical use includes initializing the parameters of a model\n |      (see also :ref:`nn-init-doc`).\n |      \n |      Args:\n |          fn (:class:`Module` -> None): function to be applied to each submodule\n |      \n |      Returns:\n |          Module: self\n |      \n |      Example::\n |      \n |          >>> @torch.no_grad()\n |          >>> def init_weights(m):\n |          >>>     print(m)\n |          >>>     if type(m) == nn.Linear:\n |          >>>         m.weight.fill_(1.0)\n |          >>>         print(m.weight)\n |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n |          >>> net.apply(init_weights)\n |          Linear(in_features=2, out_features=2, bias=True)\n |          Parameter containing:\n |          tensor([[ 1.,  1.],\n |                  [ 1.,  1.]])\n |          Linear(in_features=2, out_features=2, bias=True)\n |          Parameter containing:\n |          tensor([[ 1.,  1.],\n |                  [ 1.,  1.]])\n |          Sequential(\n |            (0): Linear(in_features=2, out_features=2, bias=True)\n |            (1): Linear(in_features=2, out_features=2, bias=True)\n |          )\n |          Sequential(\n |            (0): Linear(in_features=2, out_features=2, bias=True)\n |            (1): Linear(in_features=2, out_features=2, bias=True)\n |          )\n |  \n |  bfloat16(self: ~T) -> ~T\n |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n |      \n |      Returns:\n |          Module: self\n |  \n |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n |      Returns an iterator over module buffers.\n |      \n |      Args:\n |          recurse (bool): if True, then yields buffers of this module\n |              and all submodules. Otherwise, yields only buffers that\n |              are direct members of this module.\n |      \n |      Yields:\n |          torch.Tensor: module buffer\n |      \n |      Example::\n |      \n |          >>> for buf in model.buffers():\n |          >>>     print(type(buf), buf.size())\n |          <class 'torch.Tensor'> (20L,)\n |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n |  \n |  children(self) -> Iterator[ForwardRef('Module')]\n |      Returns an iterator over immediate children modules.\n |      \n |      Yields:\n |          Module: a child module\n |  \n |  cpu(self: ~T) -> ~T\n |      Moves all model parameters and buffers to the CPU.\n |      \n |      Returns:\n |          Module: self\n |  \n |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n |      Moves all model parameters and buffers to the GPU.\n |      \n |      This also makes associated parameters and buffers different objects. So\n |      it should be called before constructing optimizer if the module will\n |      live on GPU while being optimized.\n |      \n |      Arguments:\n |          device (int, optional): if specified, all parameters will be\n |              copied to that device\n |      \n |      Returns:\n |          Module: self\n |  \n |  double(self: ~T) -> ~T\n |      Casts all floating point parameters and buffers to ``double`` datatype.\n |      \n |      Returns:\n |          Module: self\n |  \n |  eval(self: ~T) -> ~T\n |      Sets the module in evaluation mode.\n |      \n |      This has any effect only on certain modules. See documentations of\n |      particular modules for details of their behaviors in training/evaluation\n |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n |      etc.\n |      \n |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n |      \n |      Returns:\n |          Module: self\n |  \n |  extra_repr(self) -> str\n |      Set the extra representation of the module\n |      \n |      To print customized extra information, you should re-implement\n |      this method in your own modules. Both single-line and multi-line\n |      strings are acceptable.\n |  \n |  float(self: ~T) -> ~T\n |      Casts all floating point parameters and buffers to float datatype.\n |      \n |      Returns:\n |          Module: self\n |  \n |  half(self: ~T) -> ~T\n |      Casts all floating point parameters and buffers to ``half`` datatype.\n |      \n |      Returns:\n |          Module: self\n |  \n |  load_state_dict(self, state_dict: Dict[str, torch.Tensor], strict: bool = True)\n |      Copies parameters and buffers from :attr:`state_dict` into\n |      this module and its descendants. If :attr:`strict` is ``True``, then\n |      the keys of :attr:`state_dict` must exactly match the keys returned\n |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n |      \n |      Arguments:\n |          state_dict (dict): a dict containing parameters and\n |              persistent buffers.\n |          strict (bool, optional): whether to strictly enforce that the keys\n |              in :attr:`state_dict` match the keys returned by this module's\n |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n |      \n |      Returns:\n |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n |              * **missing_keys** is a list of str containing the missing keys\n |              * **unexpected_keys** is a list of str containing the unexpected keys\n |  \n |  modules(self) -> Iterator[ForwardRef('Module')]\n |      Returns an iterator over all modules in the network.\n |      \n |      Yields:\n |          Module: a module in the network\n |      \n |      Note:\n |          Duplicate modules are returned only once. In the following\n |          example, ``l`` will be returned only once.\n |      \n |      Example::\n |      \n |          >>> l = nn.Linear(2, 2)\n |          >>> net = nn.Sequential(l, l)\n |          >>> for idx, m in enumerate(net.modules()):\n |                  print(idx, '->', m)\n |      \n |          0 -> Sequential(\n |            (0): Linear(in_features=2, out_features=2, bias=True)\n |            (1): Linear(in_features=2, out_features=2, bias=True)\n |          )\n |          1 -> Linear(in_features=2, out_features=2, bias=True)\n |  \n |  named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n |      Returns an iterator over module buffers, yielding both the\n |      name of the buffer as well as the buffer itself.\n |      \n |      Args:\n |          prefix (str): prefix to prepend to all buffer names.\n |          recurse (bool): if True, then yields buffers of this module\n |              and all submodules. Otherwise, yields only buffers that\n |              are direct members of this module.\n |      \n |      Yields:\n |          (string, torch.Tensor): Tuple containing the name and buffer\n |      \n |      Example::\n |      \n |          >>> for name, buf in self.named_buffers():\n |          >>>    if name in ['running_var']:\n |          >>>        print(buf.size())\n |  \n |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n |      Returns an iterator over immediate children modules, yielding both\n |      the name of the module as well as the module itself.\n |      \n |      Yields:\n |          (string, Module): Tuple containing a name and child module\n |      \n |      Example::\n |      \n |          >>> for name, module in model.named_children():\n |          >>>     if name in ['conv4', 'conv5']:\n |          >>>         print(module)\n |  \n |  named_modules(self, memo: Union[Set[ForwardRef('Module')], NoneType] = None, prefix: str = '')\n |      Returns an iterator over all modules in the network, yielding\n |      both the name of the module as well as the module itself.\n |      \n |      Yields:\n |          (string, Module): Tuple of name and module\n |      \n |      Note:\n |          Duplicate modules are returned only once. In the following\n |          example, ``l`` will be returned only once.\n |      \n |      Example::\n |      \n |          >>> l = nn.Linear(2, 2)\n |          >>> net = nn.Sequential(l, l)\n |          >>> for idx, m in enumerate(net.named_modules()):\n |                  print(idx, '->', m)\n |      \n |          0 -> ('', Sequential(\n |            (0): Linear(in_features=2, out_features=2, bias=True)\n |            (1): Linear(in_features=2, out_features=2, bias=True)\n |          ))\n |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n |  \n |  named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n |      Returns an iterator over module parameters, yielding both the\n |      name of the parameter as well as the parameter itself.\n |      \n |      Args:\n |          prefix (str): prefix to prepend to all parameter names.\n |          recurse (bool): if True, then yields parameters of this module\n |              and all submodules. Otherwise, yields only parameters that\n |              are direct members of this module.\n |      \n |      Yields:\n |          (string, Parameter): Tuple containing the name and parameter\n |      \n |      Example::\n |      \n |          >>> for name, param in self.named_parameters():\n |          >>>    if name in ['bias']:\n |          >>>        print(param.size())\n |  \n |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n |      Returns an iterator over module parameters.\n |      \n |      This is typically passed to an optimizer.\n |      \n |      Args:\n |          recurse (bool): if True, then yields parameters of this module\n |              and all submodules. Otherwise, yields only parameters that\n |              are direct members of this module.\n |      \n |      Yields:\n |          Parameter: module parameter\n |      \n |      Example::\n |      \n |          >>> for param in model.parameters():\n |          >>>     print(type(param), param.size())\n |          <class 'torch.Tensor'> (20L,)\n |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n |  \n |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n |      Registers a backward hook on the module.\n |      \n |      .. warning ::\n |      \n |          The current implementation will not have the presented behavior\n |          for complex :class:`Module` that perform many operations.\n |          In some failure cases, :attr:`grad_input` and :attr:`grad_output` will only\n |          contain the gradients for a subset of the inputs and outputs.\n |          For such :class:`Module`, you should use :func:`torch.Tensor.register_hook`\n |          directly on a specific input or output to get the required gradients.\n |      \n |      The hook will be called every time the gradients with respect to module\n |      inputs are computed. The hook should have the following signature::\n |      \n |          hook(module, grad_input, grad_output) -> Tensor or None\n |      \n |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n |      module has multiple inputs or outputs. The hook should not modify its\n |      arguments, but it can optionally return a new gradient with respect to\n |      input that will be used in place of :attr:`grad_input` in subsequent\n |      computations. :attr:`grad_input` will only correspond to the inputs given\n |      as positional arguments.\n |      \n |      Returns:\n |          :class:`torch.utils.hooks.RemovableHandle`:\n |              a handle that can be used to remove the added hook by calling\n |              ``handle.remove()``\n |  \n |  register_buffer(self, name: str, tensor: Union[torch.Tensor, NoneType], persistent: bool = True) -> None\n |      Adds a buffer to the module.\n |      \n |      This is typically used to register a buffer that should not to be\n |      considered a model parameter. For example, BatchNorm's ``running_mean``\n |      is not a parameter, but is part of the module's state. Buffers, by\n |      default, are persistent and will be saved alongside parameters. This\n |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n |      only difference between a persistent buffer and a non-persistent buffer\n |      is that the latter will not be a part of this module's\n |      :attr:`state_dict`.\n |      \n |      Buffers can be accessed as attributes using given names.\n |      \n |      Args:\n |          name (string): name of the buffer. The buffer can be accessed\n |              from this module using the given name\n |          tensor (Tensor): buffer to be registered.\n |          persistent (bool): whether the buffer is part of this module's\n |              :attr:`state_dict`.\n |      \n |      Example::\n |      \n |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n |  \n |  register_forward_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n |      Registers a forward hook on the module.\n |      \n |      The hook will be called every time after :func:`forward` has computed an output.\n |      It should have the following signature::\n |      \n |          hook(module, input, output) -> None or modified output\n |      \n |      The input contains only the positional arguments given to the module.\n |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n |      The hook can modify the output. It can modify the input inplace but\n |      it will not have effect on forward since this is called after\n |      :func:`forward` is called.\n |      \n |      Returns:\n |          :class:`torch.utils.hooks.RemovableHandle`:\n |              a handle that can be used to remove the added hook by calling\n |              ``handle.remove()``\n |  \n |  register_forward_pre_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n |      Registers a forward pre-hook on the module.\n |      \n |      The hook will be called every time before :func:`forward` is invoked.\n |      It should have the following signature::\n |      \n |          hook(module, input) -> None or modified input\n |      \n |      The input contains only the positional arguments given to the module.\n |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n |      The hook can modify the input. User can either return a tuple or a\n |      single modified value in the hook. We will wrap the value into a tuple\n |      if a single value is returned(unless that value is already a tuple).\n |      \n |      Returns:\n |          :class:`torch.utils.hooks.RemovableHandle`:\n |              a handle that can be used to remove the added hook by calling\n |              ``handle.remove()``\n |  \n |  register_parameter(self, name: str, param: Union[torch.nn.parameter.Parameter, NoneType]) -> None\n |      Adds a parameter to the module.\n |      \n |      The parameter can be accessed as an attribute using given name.\n |      \n |      Args:\n |          name (string): name of the parameter. The parameter can be accessed\n |              from this module using the given name\n |          param (Parameter): parameter to be added to the module.\n |  \n |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n |      Change if autograd should record operations on parameters in this\n |      module.\n |      \n |      This method sets the parameters' :attr:`requires_grad` attributes\n |      in-place.\n |      \n |      This method is helpful for freezing part of the module for finetuning\n |      or training parts of a model individually (e.g., GAN training).\n |      \n |      Args:\n |          requires_grad (bool): whether autograd should record operations on\n |                                parameters in this module. Default: ``True``.\n |      \n |      Returns:\n |          Module: self\n |  \n |  share_memory(self: ~T) -> ~T\n |  \n |  state_dict(self, destination=None, prefix='', keep_vars=False)\n |      Returns a dictionary containing a whole state of the module.\n |      \n |      Both parameters and persistent buffers (e.g. running averages) are\n |      included. Keys are corresponding parameter and buffer names.\n |      \n |      Returns:\n |          dict:\n |              a dictionary containing a whole state of the module\n |      \n |      Example::\n |      \n |          >>> module.state_dict().keys()\n |          ['bias', 'weight']\n |  \n |  to(self, *args, **kwargs)\n |      Moves and/or casts the parameters and buffers.\n |      \n |      This can be called as\n |      \n |      .. function:: to(device=None, dtype=None, non_blocking=False)\n |      \n |      .. function:: to(dtype, non_blocking=False)\n |      \n |      .. function:: to(tensor, non_blocking=False)\n |      \n |      .. function:: to(memory_format=torch.channels_last)\n |      \n |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n |      floating point desired :attr:`dtype` s. In addition, this method will\n |      only cast the floating point parameters and buffers to :attr:`dtype`\n |      (if given). The integral parameters and buffers will be moved\n |      :attr:`device`, if that is given, but with dtypes unchanged. When\n |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n |      with respect to the host if possible, e.g., moving CPU Tensors with\n |      pinned memory to CUDA devices.\n |      \n |      See below for examples.\n |      \n |      .. note::\n |          This method modifies the module in-place.\n |      \n |      Args:\n |          device (:class:`torch.device`): the desired device of the parameters\n |              and buffers in this module\n |          dtype (:class:`torch.dtype`): the desired floating point type of\n |              the floating point parameters and buffers in this module\n |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n |              dtype and device for all parameters and buffers in this module\n |          memory_format (:class:`torch.memory_format`): the desired memory\n |              format for 4D parameters and buffers in this module (keyword\n |              only argument)\n |      \n |      Returns:\n |          Module: self\n |      \n |      Example::\n |      \n |          >>> linear = nn.Linear(2, 2)\n |          >>> linear.weight\n |          Parameter containing:\n |          tensor([[ 0.1913, -0.3420],\n |                  [-0.5113, -0.2325]])\n |          >>> linear.to(torch.double)\n |          Linear(in_features=2, out_features=2, bias=True)\n |          >>> linear.weight\n |          Parameter containing:\n |          tensor([[ 0.1913, -0.3420],\n |                  [-0.5113, -0.2325]], dtype=torch.float64)\n |          >>> gpu1 = torch.device(\"cuda:1\")\n |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n |          Linear(in_features=2, out_features=2, bias=True)\n |          >>> linear.weight\n |          Parameter containing:\n |          tensor([[ 0.1914, -0.3420],\n |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n |          >>> cpu = torch.device(\"cpu\")\n |          >>> linear.to(cpu)\n |          Linear(in_features=2, out_features=2, bias=True)\n |          >>> linear.weight\n |          Parameter containing:\n |          tensor([[ 0.1914, -0.3420],\n |                  [-0.5112, -0.2324]], dtype=torch.float16)\n |  \n |  train(self: ~T, mode: bool = True) -> ~T\n |      Sets the module in training mode.\n |      \n |      This has any effect only on certain modules. See documentations of\n |      particular modules for details of their behaviors in training/evaluation\n |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n |      etc.\n |      \n |      Args:\n |          mode (bool): whether to set training mode (``True``) or evaluation\n |                       mode (``False``). Default: ``True``.\n |      \n |      Returns:\n |          Module: self\n |  \n |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n |      Casts all parameters and buffers to :attr:`dst_type`.\n |      \n |      Arguments:\n |          dst_type (type or string): the desired type\n |      \n |      Returns:\n |          Module: self\n |  \n |  zero_grad(self, set_to_none: bool = False) -> None\n |      Sets gradients of all model parameters to zero. See similar function\n |      under :class:`torch.optim.Optimizer` for more context.\n |      \n |      Arguments:\n |          set_to_none (bool): instead of setting to zero, set the grads to None.\n |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from torch.nn.modules.module.Module:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from torch.nn.modules.module.Module:\n |  \n |  T_destination = ~T_destination\n |  \n |  dump_patches = False\n\n"
     ]
    }
   ],
   "source": [
    "help(torch.nn.BCEWithLogitsLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on class BCELoss in module torch.nn.modules.loss:\n\nclass BCELoss(_WeightedLoss)\n |  BCELoss(weight: Union[torch.Tensor, NoneType] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None\n |  \n |  Creates a criterion that measures the Binary Cross Entropy\n |  between the target and the output:\n |  \n |  The unreduced (i.e. with :attr:`reduction` set to ``'none'``) loss can be described as:\n |  \n |  .. math::\n |      \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n |      l_n = - w_n \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right],\n |  \n |  where :math:`N` is the batch size. If :attr:`reduction` is not ``'none'``\n |  (default ``'mean'``), then\n |  \n |  .. math::\n |      \\ell(x, y) = \\begin{cases}\n |          \\operatorname{mean}(L), & \\text{if reduction} = \\text{'mean';}\\\\\n |          \\operatorname{sum}(L),  & \\text{if reduction} = \\text{'sum'.}\n |      \\end{cases}\n |  \n |  This is used for measuring the error of a reconstruction in for example\n |  an auto-encoder. Note that the targets :math:`y` should be numbers\n |  between 0 and 1.\n |  \n |  Notice that if :math:`x_n` is either 0 or 1, one of the log terms would be\n |  mathematically undefined in the above loss equation. PyTorch chooses to set\n |  :math:`\\log (0) = -\\infty`, since :math:`\\lim_{x\\to 0} \\log (x) = -\\infty`.\n |  However, an infinite term in the loss equation is not desirable for several reasons.\n |  \n |  For one, if either :math:`y_n = 0` or :math:`(1 - y_n) = 0`, then we would be\n |  multiplying 0 with infinity. Secondly, if we have an infinite loss value, then\n |  we would also have an infinite term in our gradient, since\n |  :math:`\\lim_{x\\to 0} \\frac{d}{dx} \\log (x) = \\infty`.\n |  This would make BCELoss's backward method nonlinear with respect to :math:`x_n`,\n |  and using it for things like linear regression would not be straight-forward.\n |  \n |  Our solution is that BCELoss clamps its log function outputs to be greater than\n |  or equal to -100. This way, we can always have a finite loss value and a linear\n |  backward method.\n |  \n |  \n |  Args:\n |      weight (Tensor, optional): a manual rescaling weight given to the loss\n |          of each batch element. If given, has to be a Tensor of size `nbatch`.\n |      size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n |          the losses are averaged over each loss element in the batch. Note that for\n |          some losses, there are multiple elements per sample. If the field :attr:`size_average`\n |          is set to ``False``, the losses are instead summed for each minibatch. Ignored\n |          when reduce is ``False``. Default: ``True``\n |      reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n |          losses are averaged or summed over observations for each minibatch depending\n |          on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n |          batch element instead and ignores :attr:`size_average`. Default: ``True``\n |      reduction (string, optional): Specifies the reduction to apply to the output:\n |          ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n |          ``'mean'``: the sum of the output will be divided by the number of\n |          elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n |          and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n |          specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n |  \n |  Shape:\n |      - Input: :math:`(N, *)` where :math:`*` means, any number of additional\n |        dimensions\n |      - Target: :math:`(N, *)`, same shape as the input\n |      - Output: scalar. If :attr:`reduction` is ``'none'``, then :math:`(N, *)`, same\n |        shape as input.\n |  \n |  Examples::\n |  \n |      >>> m = nn.Sigmoid()\n |      >>> loss = nn.BCELoss()\n |      >>> input = torch.randn(3, requires_grad=True)\n |      >>> target = torch.empty(3).random_(2)\n |      >>> output = loss(m(input), target)\n |      >>> output.backward()\n |  \n |  Method resolution order:\n |      BCELoss\n |      _WeightedLoss\n |      _Loss\n |      torch.nn.modules.module.Module\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __init__(self, weight: Union[torch.Tensor, NoneType] = None, size_average=None, reduce=None, reduction: str = 'mean') -> None\n |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n |  \n |  forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor\n |      Defines the computation performed at every call.\n |      \n |      Should be overridden by all subclasses.\n |      \n |      .. note::\n |          Although the recipe for forward pass needs to be defined within\n |          this function, one should call the :class:`Module` instance afterwards\n |          instead of this since the former takes care of running the\n |          registered hooks while the latter silently ignores them.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  __constants__ = ['reduction']\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from _Loss:\n |  \n |  __annotations__ = {'reduction': <class 'str'>}\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from torch.nn.modules.module.Module:\n |  \n |  __call__ = _call_impl(self, *input, **kwargs)\n |  \n |  __delattr__(self, name)\n |      Implement delattr(self, name).\n |  \n |  __dir__(self)\n |      Default dir() implementation.\n |  \n |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n |  \n |  __repr__(self)\n |      Return repr(self).\n |  \n |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n |      Implement setattr(self, name, value).\n |  \n |  __setstate__(self, state)\n |  \n |  add_module(self, name: str, module: Union[ForwardRef('Module'), NoneType]) -> None\n |      Adds a child module to the current module.\n |      \n |      The module can be accessed as an attribute using the given name.\n |      \n |      Args:\n |          name (string): name of the child module. The child module can be\n |              accessed from this module using the given name\n |          module (Module): child module to be added to the module.\n |  \n |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n |      as well as self. Typical use includes initializing the parameters of a model\n |      (see also :ref:`nn-init-doc`).\n |      \n |      Args:\n |          fn (:class:`Module` -> None): function to be applied to each submodule\n |      \n |      Returns:\n |          Module: self\n |      \n |      Example::\n |      \n |          >>> @torch.no_grad()\n |          >>> def init_weights(m):\n |          >>>     print(m)\n |          >>>     if type(m) == nn.Linear:\n |          >>>         m.weight.fill_(1.0)\n |          >>>         print(m.weight)\n |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n |          >>> net.apply(init_weights)\n |          Linear(in_features=2, out_features=2, bias=True)\n |          Parameter containing:\n |          tensor([[ 1.,  1.],\n |                  [ 1.,  1.]])\n |          Linear(in_features=2, out_features=2, bias=True)\n |          Parameter containing:\n |          tensor([[ 1.,  1.],\n |                  [ 1.,  1.]])\n |          Sequential(\n |            (0): Linear(in_features=2, out_features=2, bias=True)\n |            (1): Linear(in_features=2, out_features=2, bias=True)\n |          )\n |          Sequential(\n |            (0): Linear(in_features=2, out_features=2, bias=True)\n |            (1): Linear(in_features=2, out_features=2, bias=True)\n |          )\n |  \n |  bfloat16(self: ~T) -> ~T\n |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n |      \n |      Returns:\n |          Module: self\n |  \n |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n |      Returns an iterator over module buffers.\n |      \n |      Args:\n |          recurse (bool): if True, then yields buffers of this module\n |              and all submodules. Otherwise, yields only buffers that\n |              are direct members of this module.\n |      \n |      Yields:\n |          torch.Tensor: module buffer\n |      \n |      Example::\n |      \n |          >>> for buf in model.buffers():\n |          >>>     print(type(buf), buf.size())\n |          <class 'torch.Tensor'> (20L,)\n |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n |  \n |  children(self) -> Iterator[ForwardRef('Module')]\n |      Returns an iterator over immediate children modules.\n |      \n |      Yields:\n |          Module: a child module\n |  \n |  cpu(self: ~T) -> ~T\n |      Moves all model parameters and buffers to the CPU.\n |      \n |      Returns:\n |          Module: self\n |  \n |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n |      Moves all model parameters and buffers to the GPU.\n |      \n |      This also makes associated parameters and buffers different objects. So\n |      it should be called before constructing optimizer if the module will\n |      live on GPU while being optimized.\n |      \n |      Arguments:\n |          device (int, optional): if specified, all parameters will be\n |              copied to that device\n |      \n |      Returns:\n |          Module: self\n |  \n |  double(self: ~T) -> ~T\n |      Casts all floating point parameters and buffers to ``double`` datatype.\n |      \n |      Returns:\n |          Module: self\n |  \n |  eval(self: ~T) -> ~T\n |      Sets the module in evaluation mode.\n |      \n |      This has any effect only on certain modules. See documentations of\n |      particular modules for details of their behaviors in training/evaluation\n |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n |      etc.\n |      \n |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n |      \n |      Returns:\n |          Module: self\n |  \n |  extra_repr(self) -> str\n |      Set the extra representation of the module\n |      \n |      To print customized extra information, you should re-implement\n |      this method in your own modules. Both single-line and multi-line\n |      strings are acceptable.\n |  \n |  float(self: ~T) -> ~T\n |      Casts all floating point parameters and buffers to float datatype.\n |      \n |      Returns:\n |          Module: self\n |  \n |  half(self: ~T) -> ~T\n |      Casts all floating point parameters and buffers to ``half`` datatype.\n |      \n |      Returns:\n |          Module: self\n |  \n |  load_state_dict(self, state_dict: Dict[str, torch.Tensor], strict: bool = True)\n |      Copies parameters and buffers from :attr:`state_dict` into\n |      this module and its descendants. If :attr:`strict` is ``True``, then\n |      the keys of :attr:`state_dict` must exactly match the keys returned\n |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n |      \n |      Arguments:\n |          state_dict (dict): a dict containing parameters and\n |              persistent buffers.\n |          strict (bool, optional): whether to strictly enforce that the keys\n |              in :attr:`state_dict` match the keys returned by this module's\n |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n |      \n |      Returns:\n |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n |              * **missing_keys** is a list of str containing the missing keys\n |              * **unexpected_keys** is a list of str containing the unexpected keys\n |  \n |  modules(self) -> Iterator[ForwardRef('Module')]\n |      Returns an iterator over all modules in the network.\n |      \n |      Yields:\n |          Module: a module in the network\n |      \n |      Note:\n |          Duplicate modules are returned only once. In the following\n |          example, ``l`` will be returned only once.\n |      \n |      Example::\n |      \n |          >>> l = nn.Linear(2, 2)\n |          >>> net = nn.Sequential(l, l)\n |          >>> for idx, m in enumerate(net.modules()):\n |                  print(idx, '->', m)\n |      \n |          0 -> Sequential(\n |            (0): Linear(in_features=2, out_features=2, bias=True)\n |            (1): Linear(in_features=2, out_features=2, bias=True)\n |          )\n |          1 -> Linear(in_features=2, out_features=2, bias=True)\n |  \n |  named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n |      Returns an iterator over module buffers, yielding both the\n |      name of the buffer as well as the buffer itself.\n |      \n |      Args:\n |          prefix (str): prefix to prepend to all buffer names.\n |          recurse (bool): if True, then yields buffers of this module\n |              and all submodules. Otherwise, yields only buffers that\n |              are direct members of this module.\n |      \n |      Yields:\n |          (string, torch.Tensor): Tuple containing the name and buffer\n |      \n |      Example::\n |      \n |          >>> for name, buf in self.named_buffers():\n |          >>>    if name in ['running_var']:\n |          >>>        print(buf.size())\n |  \n |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n |      Returns an iterator over immediate children modules, yielding both\n |      the name of the module as well as the module itself.\n |      \n |      Yields:\n |          (string, Module): Tuple containing a name and child module\n |      \n |      Example::\n |      \n |          >>> for name, module in model.named_children():\n |          >>>     if name in ['conv4', 'conv5']:\n |          >>>         print(module)\n |  \n |  named_modules(self, memo: Union[Set[ForwardRef('Module')], NoneType] = None, prefix: str = '')\n |      Returns an iterator over all modules in the network, yielding\n |      both the name of the module as well as the module itself.\n |      \n |      Yields:\n |          (string, Module): Tuple of name and module\n |      \n |      Note:\n |          Duplicate modules are returned only once. In the following\n |          example, ``l`` will be returned only once.\n |      \n |      Example::\n |      \n |          >>> l = nn.Linear(2, 2)\n |          >>> net = nn.Sequential(l, l)\n |          >>> for idx, m in enumerate(net.named_modules()):\n |                  print(idx, '->', m)\n |      \n |          0 -> ('', Sequential(\n |            (0): Linear(in_features=2, out_features=2, bias=True)\n |            (1): Linear(in_features=2, out_features=2, bias=True)\n |          ))\n |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n |  \n |  named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n |      Returns an iterator over module parameters, yielding both the\n |      name of the parameter as well as the parameter itself.\n |      \n |      Args:\n |          prefix (str): prefix to prepend to all parameter names.\n |          recurse (bool): if True, then yields parameters of this module\n |              and all submodules. Otherwise, yields only parameters that\n |              are direct members of this module.\n |      \n |      Yields:\n |          (string, Parameter): Tuple containing the name and parameter\n |      \n |      Example::\n |      \n |          >>> for name, param in self.named_parameters():\n |          >>>    if name in ['bias']:\n |          >>>        print(param.size())\n |  \n |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n |      Returns an iterator over module parameters.\n |      \n |      This is typically passed to an optimizer.\n |      \n |      Args:\n |          recurse (bool): if True, then yields parameters of this module\n |              and all submodules. Otherwise, yields only parameters that\n |              are direct members of this module.\n |      \n |      Yields:\n |          Parameter: module parameter\n |      \n |      Example::\n |      \n |          >>> for param in model.parameters():\n |          >>>     print(type(param), param.size())\n |          <class 'torch.Tensor'> (20L,)\n |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n |  \n |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n |      Registers a backward hook on the module.\n |      \n |      .. warning ::\n |      \n |          The current implementation will not have the presented behavior\n |          for complex :class:`Module` that perform many operations.\n |          In some failure cases, :attr:`grad_input` and :attr:`grad_output` will only\n |          contain the gradients for a subset of the inputs and outputs.\n |          For such :class:`Module`, you should use :func:`torch.Tensor.register_hook`\n |          directly on a specific input or output to get the required gradients.\n |      \n |      The hook will be called every time the gradients with respect to module\n |      inputs are computed. The hook should have the following signature::\n |      \n |          hook(module, grad_input, grad_output) -> Tensor or None\n |      \n |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n |      module has multiple inputs or outputs. The hook should not modify its\n |      arguments, but it can optionally return a new gradient with respect to\n |      input that will be used in place of :attr:`grad_input` in subsequent\n |      computations. :attr:`grad_input` will only correspond to the inputs given\n |      as positional arguments.\n |      \n |      Returns:\n |          :class:`torch.utils.hooks.RemovableHandle`:\n |              a handle that can be used to remove the added hook by calling\n |              ``handle.remove()``\n |  \n |  register_buffer(self, name: str, tensor: Union[torch.Tensor, NoneType], persistent: bool = True) -> None\n |      Adds a buffer to the module.\n |      \n |      This is typically used to register a buffer that should not to be\n |      considered a model parameter. For example, BatchNorm's ``running_mean``\n |      is not a parameter, but is part of the module's state. Buffers, by\n |      default, are persistent and will be saved alongside parameters. This\n |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n |      only difference between a persistent buffer and a non-persistent buffer\n |      is that the latter will not be a part of this module's\n |      :attr:`state_dict`.\n |      \n |      Buffers can be accessed as attributes using given names.\n |      \n |      Args:\n |          name (string): name of the buffer. The buffer can be accessed\n |              from this module using the given name\n |          tensor (Tensor): buffer to be registered.\n |          persistent (bool): whether the buffer is part of this module's\n |              :attr:`state_dict`.\n |      \n |      Example::\n |      \n |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n |  \n |  register_forward_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n |      Registers a forward hook on the module.\n |      \n |      The hook will be called every time after :func:`forward` has computed an output.\n |      It should have the following signature::\n |      \n |          hook(module, input, output) -> None or modified output\n |      \n |      The input contains only the positional arguments given to the module.\n |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n |      The hook can modify the output. It can modify the input inplace but\n |      it will not have effect on forward since this is called after\n |      :func:`forward` is called.\n |      \n |      Returns:\n |          :class:`torch.utils.hooks.RemovableHandle`:\n |              a handle that can be used to remove the added hook by calling\n |              ``handle.remove()``\n |  \n |  register_forward_pre_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n |      Registers a forward pre-hook on the module.\n |      \n |      The hook will be called every time before :func:`forward` is invoked.\n |      It should have the following signature::\n |      \n |          hook(module, input) -> None or modified input\n |      \n |      The input contains only the positional arguments given to the module.\n |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n |      The hook can modify the input. User can either return a tuple or a\n |      single modified value in the hook. We will wrap the value into a tuple\n |      if a single value is returned(unless that value is already a tuple).\n |      \n |      Returns:\n |          :class:`torch.utils.hooks.RemovableHandle`:\n |              a handle that can be used to remove the added hook by calling\n |              ``handle.remove()``\n |  \n |  register_parameter(self, name: str, param: Union[torch.nn.parameter.Parameter, NoneType]) -> None\n |      Adds a parameter to the module.\n |      \n |      The parameter can be accessed as an attribute using given name.\n |      \n |      Args:\n |          name (string): name of the parameter. The parameter can be accessed\n |              from this module using the given name\n |          param (Parameter): parameter to be added to the module.\n |  \n |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n |      Change if autograd should record operations on parameters in this\n |      module.\n |      \n |      This method sets the parameters' :attr:`requires_grad` attributes\n |      in-place.\n |      \n |      This method is helpful for freezing part of the module for finetuning\n |      or training parts of a model individually (e.g., GAN training).\n |      \n |      Args:\n |          requires_grad (bool): whether autograd should record operations on\n |                                parameters in this module. Default: ``True``.\n |      \n |      Returns:\n |          Module: self\n |  \n |  share_memory(self: ~T) -> ~T\n |  \n |  state_dict(self, destination=None, prefix='', keep_vars=False)\n |      Returns a dictionary containing a whole state of the module.\n |      \n |      Both parameters and persistent buffers (e.g. running averages) are\n |      included. Keys are corresponding parameter and buffer names.\n |      \n |      Returns:\n |          dict:\n |              a dictionary containing a whole state of the module\n |      \n |      Example::\n |      \n |          >>> module.state_dict().keys()\n |          ['bias', 'weight']\n |  \n |  to(self, *args, **kwargs)\n |      Moves and/or casts the parameters and buffers.\n |      \n |      This can be called as\n |      \n |      .. function:: to(device=None, dtype=None, non_blocking=False)\n |      \n |      .. function:: to(dtype, non_blocking=False)\n |      \n |      .. function:: to(tensor, non_blocking=False)\n |      \n |      .. function:: to(memory_format=torch.channels_last)\n |      \n |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n |      floating point desired :attr:`dtype` s. In addition, this method will\n |      only cast the floating point parameters and buffers to :attr:`dtype`\n |      (if given). The integral parameters and buffers will be moved\n |      :attr:`device`, if that is given, but with dtypes unchanged. When\n |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n |      with respect to the host if possible, e.g., moving CPU Tensors with\n |      pinned memory to CUDA devices.\n |      \n |      See below for examples.\n |      \n |      .. note::\n |          This method modifies the module in-place.\n |      \n |      Args:\n |          device (:class:`torch.device`): the desired device of the parameters\n |              and buffers in this module\n |          dtype (:class:`torch.dtype`): the desired floating point type of\n |              the floating point parameters and buffers in this module\n |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n |              dtype and device for all parameters and buffers in this module\n |          memory_format (:class:`torch.memory_format`): the desired memory\n |              format for 4D parameters and buffers in this module (keyword\n |              only argument)\n |      \n |      Returns:\n |          Module: self\n |      \n |      Example::\n |      \n |          >>> linear = nn.Linear(2, 2)\n |          >>> linear.weight\n |          Parameter containing:\n |          tensor([[ 0.1913, -0.3420],\n |                  [-0.5113, -0.2325]])\n |          >>> linear.to(torch.double)\n |          Linear(in_features=2, out_features=2, bias=True)\n |          >>> linear.weight\n |          Parameter containing:\n |          tensor([[ 0.1913, -0.3420],\n |                  [-0.5113, -0.2325]], dtype=torch.float64)\n |          >>> gpu1 = torch.device(\"cuda:1\")\n |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n |          Linear(in_features=2, out_features=2, bias=True)\n |          >>> linear.weight\n |          Parameter containing:\n |          tensor([[ 0.1914, -0.3420],\n |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n |          >>> cpu = torch.device(\"cpu\")\n |          >>> linear.to(cpu)\n |          Linear(in_features=2, out_features=2, bias=True)\n |          >>> linear.weight\n |          Parameter containing:\n |          tensor([[ 0.1914, -0.3420],\n |                  [-0.5112, -0.2324]], dtype=torch.float16)\n |  \n |  train(self: ~T, mode: bool = True) -> ~T\n |      Sets the module in training mode.\n |      \n |      This has any effect only on certain modules. See documentations of\n |      particular modules for details of their behaviors in training/evaluation\n |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n |      etc.\n |      \n |      Args:\n |          mode (bool): whether to set training mode (``True``) or evaluation\n |                       mode (``False``). Default: ``True``.\n |      \n |      Returns:\n |          Module: self\n |  \n |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n |      Casts all parameters and buffers to :attr:`dst_type`.\n |      \n |      Arguments:\n |          dst_type (type or string): the desired type\n |      \n |      Returns:\n |          Module: self\n |  \n |  zero_grad(self, set_to_none: bool = False) -> None\n |      Sets gradients of all model parameters to zero. See similar function\n |      under :class:`torch.optim.Optimizer` for more context.\n |      \n |      Arguments:\n |          set_to_none (bool): instead of setting to zero, set the grads to None.\n |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from torch.nn.modules.module.Module:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes inherited from torch.nn.modules.module.Module:\n |  \n |  T_destination = ~T_destination\n |  \n |  dump_patches = False\n\n"
     ]
    }
   ],
   "source": [
    "help(torch.nn.BCELoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on function kaiming_uniform_ in module torch.nn.init:\n\nkaiming_uniform_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu')\n    Fills the input `Tensor` with values according to the method\n    described in `Delving deep into rectifiers: Surpassing human-level\n    performance on ImageNet classification` - He, K. et al. (2015), using a\n    uniform distribution. The resulting tensor will have values sampled from\n    :math:`\\mathcal{U}(-\\text{bound}, \\text{bound})` where\n    \n    .. math::\n        \\text{bound} = \\text{gain} \\times \\sqrt{\\frac{3}{\\text{fan\\_mode}}}\n    \n    Also known as He initialization.\n    \n    Args:\n        tensor: an n-dimensional `torch.Tensor`\n        a: the negative slope of the rectifier used after this layer (only\n            used with ``'leaky_relu'``)\n        mode: either ``'fan_in'`` (default) or ``'fan_out'``. Choosing ``'fan_in'``\n            preserves the magnitude of the variance of the weights in the\n            forward pass. Choosing ``'fan_out'`` preserves the magnitudes in the\n            backwards pass.\n        nonlinearity: the non-linear function (`nn.functional` name),\n            recommended to use only with ``'relu'`` or ``'leaky_relu'`` (default).\n    \n    Examples:\n        >>> w = torch.empty(3, 5)\n        >>> nn.init.kaiming_uniform_(w, mode='fan_in', nonlinearity='relu')\n\n"
     ]
    }
   ],
   "source": [
    "help(nn.init.kaiming_uniform_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.kaggle.com/mlwhiz/attention-pytorch-and-keras \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "        self.supports_masking = True\n",
    "\n",
    "        self.bias = bias\n",
    "        self.feature_dim = feature_dim\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        \n",
    "        weight = torch.zeros(feature_dim, 1)\n",
    "        nn.init.kaiming_uniform_(weight)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        \n",
    "        if bias:\n",
    "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        feature_dim = self.feature_dim \n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = torch.mm(\n",
    "            x.contiguous().view(-1, feature_dim), \n",
    "            self.weight\n",
    "        ).view(-1, step_dim)\n",
    "        \n",
    "        if self.bias:\n",
    "            eij = eij + self.b\n",
    "            \n",
    "        eij = torch.tanh(eij)\n",
    "        a = torch.exp(eij)\n",
    "        \n",
    "        if mask is not None:\n",
    "            a = a * mask\n",
    "\n",
    "        a = a / (torch.sum(a, 1, keepdim=True) + 1e-10)\n",
    "\n",
    "        weighted_input = x * torch.unsqueeze(a, -1)\n",
    "        return torch.sum(weighted_input, 1)\n",
    "\n",
    "class Attention_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention_Net, self).__init__()\n",
    "        drp = 0.1\n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "\n",
    "        self.embedding_dropout = nn.Dropout2d(0.1)\n",
    "        self.lstm = nn.LSTM(embed_size, 128, bidirectional=True, batch_first=True)\n",
    "        self.lstm2 = nn.GRU(128*2, 64, bidirectional=True, batch_first=True)\n",
    "\n",
    "        self.attention_layer = Attention(128, maxlen)\n",
    "        \n",
    "        self.linear = nn.Linear(64*2 , 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_embedding = self.embedding(x)\n",
    "        h_embedding = torch.squeeze(torch.unsqueeze(h_embedding, 0))\n",
    "        h_lstm, _ = self.lstm(h_embedding)\n",
    "        h_lstm, _ = self.lstm2(h_lstm)\n",
    "        h_lstm_atten = self.attention_layer(h_lstm)\n",
    "        conc = self.relu(self.linear(h_lstm_atten))\n",
    "        out = self.out(conc)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}