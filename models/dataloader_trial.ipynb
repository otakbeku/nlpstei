{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('nlpai': conda)",
   "metadata": {
    "interpreter": {
     "hash": "63f661667cfff4a21b9f1172704ab3c7d831d3612a4dc528cd9d3281904853c9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import heapq\n",
    "import pprint\n",
    "\n",
    "from nltk.tokenize import wordpunct_tokenize, blankline_tokenize, line_tokenize, word_tokenize\n",
    "from itertools import combinations\n",
    "from nltk.corpus import stopwords\n",
    "from time import time \n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import multiprocessing\n",
    "\n",
    "# # tensorflow\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pytorch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# stanza\n",
    "import stanza as st\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 534943 entries, 0 to 534942\nData columns (total 4 columns):\n #   Column     Non-Null Count   Dtype \n---  ------     --------------   ----- \n 0   artist     534943 non-null  object\n 1   song_name  534943 non-null  object\n 2   song_id    534943 non-null  int64 \n 3   sent       534943 non-null  object\ndtypes: int64(1), object(3)\nmemory usage: 16.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('sentences_15klyrics.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-02-26 11:12:52 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| depparse  | combined  |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-02-26 11:12:52 INFO: Use device: gpu\n",
      "2021-02-26 11:12:52 INFO: Loading: tokenize\n",
      "2021-02-26 11:12:56 INFO: Loading: pos\n",
      "2021-02-26 11:12:56 INFO: Loading: lemma\n",
      "2021-02-26 11:12:57 INFO: Loading: depparse\n",
      "2021-02-26 11:12:57 INFO: Loading: sentiment\n",
      "2021-02-26 11:12:57 INFO: Loading: ner\n",
      "2021-02-26 11:12:58 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "pos_tagger =  st.Pipeline(lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = data.sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"it's a junkie dream makes you so uptight\""
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "sent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "it [('itself', 0.782857358455658), ('something', 0.7486327886581421), ('everything', 0.7118643522262573), ('them', 0.7043470144271851)]\n",
      "==========\n",
      "'s [(\"'s--the\", 0.6630688309669495), ('was--the', 0.6064021587371826), ('is--the', 0.6045242547988892), ('its', 0.5987124443054199)]\n",
      "==========\n",
      "a [('A', 0.816367506980896), ('-', 0.739240288734436), ('\"', 0.7376177906990051), ('/', 0.7108931541442871)]\n",
      "==========\n",
      "junkie [('junkies', 0.7693454027175903), ('addict', 0.7505453824996948), ('ex-junkie', 0.7027280926704407), ('junky', 0.6767479777336121)]\n",
      "==========\n",
      "dream [('dreams', 0.8512080907821655), ('dreaming', 0.7916011214256287), ('dream-', 0.7445577383041382), ('day-dream', 0.7272703647613525)]\n",
      "==========\n",
      "makes [('make', 0.8064786195755005), ('making', 0.7594941854476929), ('made', 0.6906698942184448), ('finds', 0.6746305227279663)]\n",
      "==========\n",
      "you [('you--you', 0.7711327075958252), ('you-and', 0.7605157494544983), ('you--if', 0.7444275617599487), ('thatyou', 0.7353635430335999)]\n",
      "==========\n",
      "so [('too', 0.7427366971969604), ('but', 0.7313002347946167), ('however', 0.726128339767456), ('anyway', 0.7238963842391968)]\n",
      "==========\n",
      "uptight [('up-tight', 0.7604759931564331), ('strait-laced', 0.7212878465652466), ('uptightness', 0.7143203616142273), ('prudish', 0.709030270576477)]\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "for word in word_tokenize(sent[0]):\n",
    "    print(word, pretrainedwvmodel.wv.similar_by_word(word, topn=4))\n",
    "    print('==========')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = pos_tagger(sent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_ents',\n",
       " '_num_tokens',\n",
       " '_num_words',\n",
       " '_process_sentences',\n",
       " '_sentences',\n",
       " '_text',\n",
       " 'add_property',\n",
       " 'build_ents',\n",
       " 'entities',\n",
       " 'ents',\n",
       " 'from_serialized',\n",
       " 'get',\n",
       " 'get_mwt_expansions',\n",
       " 'iter_tokens',\n",
       " 'iter_words',\n",
       " 'num_tokens',\n",
       " 'num_words',\n",
       " 'sentences',\n",
       " 'set',\n",
       " 'set_mwt_expansions',\n",
       " 'text',\n",
       " 'to_dict',\n",
       " 'to_serialized']"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "dir(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{\n",
       "  \"id\": 1,\n",
       "  \"text\": \"it\",\n",
       "  \"lemma\": \"it\",\n",
       "  \"upos\": \"PRON\",\n",
       "  \"xpos\": \"PRP\",\n",
       "  \"feats\": \"Case=Nom|Gender=Neut|Number=Sing|Person=3|PronType=Prs\",\n",
       "  \"head\": 5,\n",
       "  \"deprel\": \"nsubj\",\n",
       "  \"misc\": \"start_char=0|end_char=2\"\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "doc.sentences[0].words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl = [pretrainedwvmodel.wv.vocab[k.text].index for k in doc.sentences[0].words]\n",
    "yl = [k.xpos for k in doc.sentences[0].words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = pos_tagger('asdasd asdasd arkw mikwe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2class = {\n",
    "    '<PAD>':0,\n",
    "    '<UNK>':404,\n",
    "    'CC':1,\n",
    "'CD':2,\n",
    "'DT':3,\n",
    "'EX':4,\n",
    "'FW':5,\n",
    "'IN':6,\n",
    "'JJ':7,\n",
    "'JJR':8,\n",
    "'JJS':9,\n",
    "'LS':10,\n",
    "'MD':11,\n",
    "'NN':12,\n",
    "'NNS':13,\n",
    "'NNP':14,\n",
    "'NNPS':15,\n",
    "'PDT':16,\n",
    "'POS':17,\n",
    "'PRP':18,\n",
    "'PRP$':19,\n",
    "'RB':20,\n",
    "'RBR':21,\n",
    "'RBS':22,\n",
    "'RP':23,\n",
    "'SYM':24,\n",
    "'TO':25,\n",
    "'UH':26,\n",
    "'VB':27,\n",
    "'VBD':28,\n",
    "'VBG':29,\n",
    "'VBN':30,\n",
    "'VBP':31,\n",
    "'VBZ':32,\n",
    "'WDT':33,\n",
    "'WP':34,\n",
    "'WP$':35,\n",
    "'WRB':36,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "asdasd None True\nasdasd None True\narkw None True\nmikwe None True\n"
     ]
    }
   ],
   "source": [
    "xl = []\n",
    "yl = []\n",
    "len_seq = 20\n",
    "seq = np.zeros(len_seq, dtype=np.int64)\n",
    "# yseq = np.array(['<pad>' for _ in range(len_seq)])\n",
    "yseq = np.zeros(len_seq, dtype=object)\n",
    "for k in doc2.sentences[0].words:\n",
    "    print(k.text, pretrainedwvmodel.wv.vocab.get(k.text), (pretrainedwvmodel.wv.vocab.get(k.text) is None))\n",
    "    if (pretrainedwvmodel.wv.vocab.get(k.text) is None):\n",
    "        xl.append(10001)\n",
    "        yl.append(tag2class.get('<UNK>'))\n",
    "        continue\n",
    "    xl.append(pretrainedwvmodel.wv.vocab.get(k.text).index)\n",
    "    yl.append(tag2class.get(k.xpos))\n",
    "seq[:len(xl)] = xl\n",
    "yseq[:len(yl)] = yl\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[404, 404, 404, 404]"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "yl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([404, 404, 404, 404, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "yseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "asdasd None True\nasdasd None True\narkw None True\nmikwe None True\n"
     ]
    }
   ],
   "source": [
    "xl = []\n",
    "len_seq = 20\n",
    "seq = np.zeros(len_seq, dtype=np.int64)\n",
    "for k in doc2.sentences[0].words:\n",
    "    print(k.text, pretrainedwvmodel.wv.vocab.get(k.text), (pretrainedwvmodel.wv.vocab.get(k.text) is None))\n",
    "    if k == '<pad>':\n",
    "        xl.append(10000)\n",
    "        continue\n",
    "    if (pretrainedwvmodel.wv.vocab.get(k.text) is None):\n",
    "        xl.append(10001)\n",
    "        continue\n",
    "    xl.append(pretrainedwvmodel.wv.vocab.get(k.text).index)\n",
    "seq[:len(xl)] = xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([10001, 10001, 10001, 10001,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([   19,    24,     7, 45314,  3758,   618,    30,    57, 54995,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'index'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-c189ea9e58b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpretrainedwvmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpretrainedwvmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m10000\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'asdklasd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'asdasd'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0myl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpos\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-c189ea9e58b4>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpretrainedwvmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpretrainedwvmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m10000\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'asdklasd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'asdasd'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0myl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpos\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "xl = [pretrainedwvmodel.wv.vocab.get(k).index  for k in ['asdklasd', 'asdasd'] ]\n",
    "yl = [k.xpos for k in doc.sentences[0].words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'asdklasd'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-c34cb52b2fe9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'asdklasd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'asdasd'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpretrainedwvmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpretrainedwvmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'asdklasd'"
     ]
    }
   ],
   "source": [
    "for k in ['asdklasd', 'asdasd']:\n",
    "    pretrainedwvmodel.wv.vocab[k]\n",
    "    if pretrainedwvmodel.wv.vocab[k].index:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "pretrainedwvmodel.wv.vocab['he'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrainedwvmodel.wv.vocab.get('asdawdaw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'clear',\n",
       " 'copy',\n",
       " 'fromkeys',\n",
       " 'get',\n",
       " 'items',\n",
       " 'keys',\n",
       " 'pop',\n",
       " 'popitem',\n",
       " 'setdefault',\n",
       " 'update',\n",
       " 'values']"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "dir(pretrainedwvmodel.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['PRP', 'VBZ', 'DT', 'NN', 'NN', 'VBZ', 'PRP', 'RB', 'JJ']"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "yl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lyrics_pos_tagger = {\n",
    "#     'artist':[],\n",
    "#     'song_name':[],\n",
    "#     'song_id':[],\n",
    "#     'word':[],\n",
    "#     'XPOS':[],\n",
    "#     'UPOS':[],\n",
    "# }\n",
    "\n",
    "# max_length_sent = 0\n",
    "# for song_id, song_info in data.iterrows():\n",
    "#     lines = '. '.join(line_tokenize(song_info.lyric))\n",
    "#     doc = pos_tagger(lines)\n",
    "#     for sent in doc.sentences:\n",
    "#         curr_max_length = 0\n",
    "#         for word in sent.words:\n",
    "#             curr_max_length += 1\n",
    "#             lyrics_pos_tagger['artist'].append(song_info.artist)\n",
    "#             lyrics_pos_tagger['song_name'].append(song_info.song_name)\n",
    "#             lyrics_pos_tagger['song_id'].append(song_id)\n",
    "#             lyrics_pos_tagger['word'].append(word.text)\n",
    "#             lyrics_pos_tagger['XPOS'].append(word.xpos)\n",
    "#             lyrics_pos_tagger['UPOS'].append(word.upos)\n",
    "#         max_length_sent = max(max_length_sent, curr_max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DatasetMaper(Dataset):\n",
    "# \t'''\n",
    "# \tHandles batches of dataset\n",
    "# \t'''\n",
    "  \n",
    "# \tdef __init__(self, x, y):\n",
    "# \t\tself.x = x\n",
    "# \t\tself.y = y\n",
    "\t\t\n",
    "# \tdef __len__(self):\n",
    "# \t\treturn len(self.x)\n",
    "\t\t\n",
    "# \tdef __getitem__(self, idx):\n",
    "# \t\treturn self.x[idx], self.y[idx]\n",
    "\n",
    "# training_set = DatasetMaper(X_train, y_train)\n",
    "# validation_set = DatasetMaper(X_val, y_val)\n",
    "# test_set = DatasetMaper(X_test, y_test)\n",
    "\t\t\n",
    "# loader_training = DataLoader(training_set, batch_size=lstm_args.batch_size)\n",
    "# loader_val = DataLoader(training_set, batch_size=lstm_args.batch_size)\n",
    "# loader_test = DataLoader(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sentence_encoder(text, vocab2index):\n",
    "#     tokens = text.lower().split()\n",
    "#     temp = np.full(len(vocab2index), len(vocab2index)+1)\n",
    "#     sentencoded = np.array([vocab2index.get(word, len(vocab2index)+1) for word in tokens])\n",
    "#     length = len(sentencoded)\n",
    "#     temp[:length] = sentencoded\n",
    "#     return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrained word2vec\n",
    "import gensim.downloader as api\n",
    "corpus = api.load('fasttext-wiki-news-subwords-300', return_path=True)\n",
    "pretrainedwvmodel = KeyedVectors.load_word2vec_format(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrainedwvmodel.wv.similar_by_word(\"its\", topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrainedwvmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embedding_matrix = pretrainedwvmodel.wv.vectors\n",
    "pretrained_embedding_matrix.append(np.zeros((300,))) # Padding\n",
    "padding_index = len(pretrained_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG2CLASS = {\n",
    "    '<PAD>':0,\n",
    "    '<UNK>':404,\n",
    "    'CC':1,\n",
    "'CD':2,\n",
    "'DT':3,\n",
    "'EX':4,\n",
    "'FW':5,\n",
    "'IN':6,\n",
    "'JJ':7,\n",
    "'JJR':8,\n",
    "'JJS':9,\n",
    "'LS':10,\n",
    "'MD':11,\n",
    "'NN':12,\n",
    "'NNS':13,\n",
    "'NNP':14,\n",
    "'NNPS':15,\n",
    "'PDT':16,\n",
    "'POS':17,\n",
    "'PRP':18,\n",
    "'PRP$':19,\n",
    "'RB':20,\n",
    "'RBR':21,\n",
    "'RBS':22,\n",
    "'RP':23,\n",
    "'SYM':24,\n",
    "'TO':25,\n",
    "'UH':26,\n",
    "'VB':27,\n",
    "'VBD':28,\n",
    "'VBG':29,\n",
    "'VBN':30,\n",
    "'VBP':31,\n",
    "'VBZ':32,\n",
    "'WDT':33,\n",
    "'WP':34,\n",
    "'WP$':35,\n",
    "'WRB':36,}\n",
    "\n",
    "class DataMapper(Dataset):\n",
    "    def __init__(self, sentence_lyrics_file, wvmodel, sequence_len):\n",
    "        self.pos_tagger = st.Pipeline(lang='en')\n",
    "        temp = pd.read_csv(sentence_lyrics_file)\n",
    "        self.sents = temp.sent\n",
    "        self.sequence_len=sequence_len\n",
    "        self.model = wvmodel\n",
    "    def __len__(self):\n",
    "        return len(self.sents)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        doc = pos_tagger(self.sents[idx])\n",
    "        xl = []\n",
    "        yl = []\n",
    "        seq = np.zeros(self.sequence_len, dtype=np.int64)\n",
    "        yseq = np.zeros(self.sequence_len, dtype=object)\n",
    "        for k in doc.sentences[0].words:\n",
    "            if (self.model.wv.vocab.get(k.text) is None):\n",
    "                xl.append(10001)\n",
    "                yl.append(TAG2CLASS.get('<UNK>'))\n",
    "                continue\n",
    "            xl.append(self.model.wv.vocab.get(k.text).index)\n",
    "            yl.append(TAG2CLASS.get(k.xpos))\n",
    "        seq[:len(xl)] = xl\n",
    "        yseq[:len(yl)] = yl\n",
    "        return seq, yseq\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-02-26 12:09:40 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| depparse  | combined  |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-02-26 12:09:40 INFO: Use device: gpu\n",
      "2021-02-26 12:09:40 INFO: Loading: tokenize\n",
      "2021-02-26 12:09:40 INFO: Loading: pos\n",
      "2021-02-26 12:09:40 INFO: Loading: lemma\n",
      "2021-02-26 12:09:40 INFO: Loading: depparse\n",
      "2021-02-26 12:09:40 INFO: Loading: sentiment\n",
      "2021-02-26 12:09:41 INFO: Loading: ner\n",
      "2021-02-26 12:09:41 INFO: Done loading processors!\n",
      "[   19    24     7 45314  3758   618    30    57 54995     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "[18 32 3 12 12 32 18 20 7 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "nice = DataMapper('sentences_15klyrics.csv', pretrainedwvmodel, 20)\n",
    "\n",
    "xn, yn = nice[0]\n",
    "print(xn)\n",
    "print(yn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "20471it [00:04, 4693.83it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-222-3af38764492f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdatak\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'sent'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'length'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msong_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msong_info\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mcurr_max_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msong_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mdatak\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sent'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msong_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mdatak\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'length'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_max_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m--> 129\u001b[1;33m     \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m     return [\n\u001b[0;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\nltk\\tokenize\\__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m    106\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tokenizers/punkt/{0}.pickle\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1270\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m         \"\"\"\n\u001b[1;32m-> 1272\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1324\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m         \"\"\"\n\u001b[1;32m-> 1326\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1324\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m         \"\"\"\n\u001b[1;32m-> 1326\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[1;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[0;32m   1314\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m             \u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[1;34m(self, text, slices)\u001b[0m\n\u001b[0;32m   1355\u001b[0m         \"\"\"\n\u001b[0;32m   1356\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1357\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1358\u001b[0m             \u001b[0msl1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1359\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[1;34m(it)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m         \u001b[0mprev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\nltk\\tokenize\\punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"after_tok\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('sentences_15klyrics.csv')\n",
    "from tqdm import tqdm\n",
    "max_length_sent = 20\n",
    "data = pd.read_csv('sentences_15klyrics.csv')\n",
    "datak = {'sent':[], 'length':[]}\n",
    "for song_id, song_info in tqdm(data.iterrows()):\n",
    "    curr_max_length = len(word_tokenize(song_info.sent))\n",
    "    datak['sent'].append(song_info.sent)\n",
    "    datak['length'].append(curr_max_length)\n",
    "    max_length_sent = max(max_length_sent, curr_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdatak = pd.DataFrame(datak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdatak.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdatak.query('length>10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(dfdatak.groupby('length').describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdatak.groupby('length').nunique().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdatak.groupby('length').nunique().query('sent>3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdatak.query('length>20').sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "676",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 676",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-230-43fd6c1d3119>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfdatak\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'length>50'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m676\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 824\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 676"
     ]
    }
   ],
   "source": [
    "dfdatak.query('length>50').sent[676]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "446172",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 446172",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-231-2213fb9e10f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mteku\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfdatak\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'length>500'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m446172\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mteku\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m', '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 824\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    825\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 446172"
     ]
    }
   ],
   "source": [
    "teku = dfdatak.query('length>500').sent[446172]\n",
    "teku.split(', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "count    534943.000000\n",
       "mean          7.480139\n",
       "std           4.730531\n",
       "min           1.000000\n",
       "25%           5.000000\n",
       "50%           7.000000\n",
       "75%           9.000000\n",
       "max         811.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "source": [
    "dfdatak.length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "811"
      ]
     },
     "metadata": {},
     "execution_count": 150
    }
   ],
   "source": [
    "max_length_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "643"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "max_length_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on class tqdm in module tqdm.std:\n\nclass tqdm(tqdm.utils.Comparable)\n |  tqdm(*_, **__)\n |  \n |  Decorate an iterable object, returning an iterator which acts exactly\n |  like the original iterable, but prints a dynamically updating\n |  progressbar every time a value is requested.\n |  \n |  Method resolution order:\n |      tqdm\n |      tqdm.utils.Comparable\n |      builtins.object\n |  \n |  Methods defined here:\n |  \n |  __bool__(self)\n |  \n |  __del__(self)\n |  \n |  __enter__(self)\n |  \n |  __exit__(self, exc_type, exc_value, traceback)\n |  \n |  __hash__(self)\n |      Return hash(self).\n |  \n |  __init__(self, iterable=None, desc=None, total=None, leave=True, file=None, ncols=None, mininterval=0.1, maxinterval=10.0, miniters=None, ascii=None, disable=False, unit='it', unit_scale=False, dynamic_ncols=False, smoothing=0.3, bar_format=None, initial=0, position=None, postfix=None, unit_divisor=1000, write_bytes=None, lock_args=None, nrows=None, colour=None, gui=False, **kwargs)\n |      Parameters\n |      ----------\n |      iterable  : iterable, optional\n |          Iterable to decorate with a progressbar.\n |          Leave blank to manually manage the updates.\n |      desc  : str, optional\n |          Prefix for the progressbar.\n |      total  : int or float, optional\n |          The number of expected iterations. If unspecified,\n |          len(iterable) is used if possible. If float(\"inf\") or as a last\n |          resort, only basic progress statistics are displayed\n |          (no ETA, no progressbar).\n |          If `gui` is True and this parameter needs subsequent updating,\n |          specify an initial arbitrary large positive number,\n |          e.g. 9e9.\n |      leave  : bool, optional\n |          If [default: True], keeps all traces of the progressbar\n |          upon termination of iteration.\n |          If `None`, will leave only if `position` is `0`.\n |      file  : `io.TextIOWrapper` or `io.StringIO`, optional\n |          Specifies where to output the progress messages\n |          (default: sys.stderr). Uses `file.write(str)` and `file.flush()`\n |          methods.  For encoding, see `write_bytes`.\n |      ncols  : int, optional\n |          The width of the entire output message. If specified,\n |          dynamically resizes the progressbar to stay within this bound.\n |          If unspecified, attempts to use environment width. The\n |          fallback is a meter width of 10 and no limit for the counter and\n |          statistics. If 0, will not print any meter (only stats).\n |      mininterval  : float, optional\n |          Minimum progress display update interval [default: 0.1] seconds.\n |      maxinterval  : float, optional\n |          Maximum progress display update interval [default: 10] seconds.\n |          Automatically adjusts `miniters` to correspond to `mininterval`\n |          after long display update lag. Only works if `dynamic_miniters`\n |          or monitor thread is enabled.\n |      miniters  : int or float, optional\n |          Minimum progress display update interval, in iterations.\n |          If 0 and `dynamic_miniters`, will automatically adjust to equal\n |          `mininterval` (more CPU efficient, good for tight loops).\n |          If > 0, will skip display of specified number of iterations.\n |          Tweak this and `mininterval` to get very efficient loops.\n |          If your progress is erratic with both fast and slow iterations\n |          (network, skipping items, etc) you should set miniters=1.\n |      ascii  : bool or str, optional\n |          If unspecified or False, use unicode (smooth blocks) to fill\n |          the meter. The fallback is to use ASCII characters \" 123456789#\".\n |      disable  : bool, optional\n |          Whether to disable the entire progressbar wrapper\n |          [default: False]. If set to None, disable on non-TTY.\n |      unit  : str, optional\n |          String that will be used to define the unit of each iteration\n |          [default: it].\n |      unit_scale  : bool or int or float, optional\n |          If 1 or True, the number of iterations will be reduced/scaled\n |          automatically and a metric prefix following the\n |          International System of Units standard will be added\n |          (kilo, mega, etc.) [default: False]. If any other non-zero\n |          number, will scale `total` and `n`.\n |      dynamic_ncols  : bool, optional\n |          If set, constantly alters `ncols` and `nrows` to the\n |          environment (allowing for window resizes) [default: False].\n |      smoothing  : float, optional\n |          Exponential moving average smoothing factor for speed estimates\n |          (ignored in GUI mode). Ranges from 0 (average speed) to 1\n |          (current/instantaneous speed) [default: 0.3].\n |      bar_format  : str, optional\n |          Specify a custom bar string formatting. May impact performance.\n |          [default: '{l_bar}{bar}{r_bar}'], where\n |          l_bar='{desc}: {percentage:3.0f}%|' and\n |          r_bar='| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, '\n |            '{rate_fmt}{postfix}]'\n |          Possible vars: l_bar, bar, r_bar, n, n_fmt, total, total_fmt,\n |            percentage, elapsed, elapsed_s, ncols, nrows, desc, unit,\n |            rate, rate_fmt, rate_noinv, rate_noinv_fmt,\n |            rate_inv, rate_inv_fmt, postfix, unit_divisor,\n |            remaining, remaining_s, eta.\n |          Note that a trailing \": \" is automatically removed after {desc}\n |          if the latter is empty.\n |      initial  : int or float, optional\n |          The initial counter value. Useful when restarting a progress\n |          bar [default: 0]. If using float, consider specifying `{n:.3f}`\n |          or similar in `bar_format`, or specifying `unit_scale`.\n |      position  : int, optional\n |          Specify the line offset to print this bar (starting from 0)\n |          Automatic if unspecified.\n |          Useful to manage multiple bars at once (eg, from threads).\n |      postfix  : dict or *, optional\n |          Specify additional stats to display at the end of the bar.\n |          Calls `set_postfix(**postfix)` if possible (dict).\n |      unit_divisor  : float, optional\n |          [default: 1000], ignored unless `unit_scale` is True.\n |      write_bytes  : bool, optional\n |          If (default: None) and `file` is unspecified,\n |          bytes will be written in Python 2. If `True` will also write\n |          bytes. In all other cases will default to unicode.\n |      lock_args  : tuple, optional\n |          Passed to `refresh` for intermediate output\n |          (initialisation, iterating, and updating).\n |      nrows  : int, optional\n |          The screen height. If specified, hides nested bars outside this\n |          bound. If unspecified, attempts to use environment height.\n |          The fallback is 20.\n |      colour  : str, optional\n |          Bar colour (e.g. 'green', '#00ff00').\n |      gui  : bool, optional\n |          WARNING: internal parameter - do not use.\n |          Use tqdm.gui.tqdm(...) instead. If set, will attempt to use\n |          matplotlib animations for a graphical output [default: False].\n |      \n |      Returns\n |      -------\n |      out  : decorated iterator.\n |  \n |  __iter__(self)\n |      Backward-compatibility to use: for x in tqdm(iterable)\n |  \n |  __len__(self)\n |  \n |  __nonzero__(self)\n |  \n |  __repr__(self)\n |      Return repr(self).\n |  \n |  clear(self, nolock=False)\n |      Clear current bar display.\n |  \n |  close(self)\n |      Cleanup and (if leave=False) close the progressbar.\n |  \n |  display(self, msg=None, pos=None)\n |      Use `self.sp` to display `msg` in the specified `pos`.\n |      \n |      Consider overloading this function when inheriting to use e.g.:\n |      `self.some_frontend(**self.format_dict)` instead of `self.sp`.\n |      \n |      Parameters\n |      ----------\n |      msg  : str, optional. What to display (default: `repr(self)`).\n |      pos  : int, optional. Position to `moveto`\n |        (default: `abs(self.pos)`).\n |  \n |  moveto(self, n)\n |  \n |  refresh(self, nolock=False, lock_args=None)\n |      Force refresh the display of this bar.\n |      \n |      Parameters\n |      ----------\n |      nolock  : bool, optional\n |          If `True`, does not lock.\n |          If [default: `False`]: calls `acquire()` on internal lock.\n |      lock_args  : tuple, optional\n |          Passed to internal lock's `acquire()`.\n |          If specified, will only `display()` if `acquire()` returns `True`.\n |  \n |  reset(self, total=None)\n |      Resets to 0 iterations for repeated use.\n |      \n |      Consider combining with `leave=True`.\n |      \n |      Parameters\n |      ----------\n |      total  : int or float, optional. Total to use for the new bar.\n |  \n |  set_description(self, desc=None, refresh=True)\n |      Set/modify description of the progress bar.\n |      \n |      Parameters\n |      ----------\n |      desc  : str, optional\n |      refresh  : bool, optional\n |          Forces refresh [default: True].\n |  \n |  set_description_str(self, desc=None, refresh=True)\n |      Set/modify description without ': ' appended.\n |  \n |  set_postfix(self, ordered_dict=None, refresh=True, **kwargs)\n |      Set/modify postfix (additional stats)\n |      with automatic formatting based on datatype.\n |      \n |      Parameters\n |      ----------\n |      ordered_dict  : dict or OrderedDict, optional\n |      refresh  : bool, optional\n |          Forces refresh [default: True].\n |      kwargs  : dict, optional\n |  \n |  set_postfix_str(self, s='', refresh=True)\n |      Postfix without dictionary expansion, similar to prefix handling.\n |  \n |  unpause(self)\n |      Restart tqdm timer from last print time.\n |  \n |  update(self, n=1)\n |      Manually update the progress bar, useful for streams\n |      such as reading files.\n |      E.g.:\n |      >>> t = tqdm(total=filesize) # Initialise\n |      >>> for current_buffer in stream:\n |      ...    ...\n |      ...    t.update(len(current_buffer))\n |      >>> t.close()\n |      The last line is highly recommended, but possibly not necessary if\n |      `t.update()` will be called in such a way that `filesize` will be\n |      exactly reached and printed.\n |      \n |      Parameters\n |      ----------\n |      n  : int or float, optional\n |          Increment to add to the internal counter of iterations\n |          [default: 1]. If using float, consider specifying `{n:.3f}`\n |          or similar in `bar_format`, or specifying `unit_scale`.\n |      \n |      Returns\n |      -------\n |      out  : bool or None\n |          True if a `display()` was triggered.\n |  \n |  ----------------------------------------------------------------------\n |  Class methods defined here:\n |  \n |  external_write_mode(file=None, nolock=False) from builtins.type\n |      Disable tqdm within context and refresh tqdm when exits.\n |      Useful when writing to standard output stream\n |  \n |  get_lock() from builtins.type\n |      Get the global lock. Construct it if it does not exist.\n |  \n |  pandas(**tqdm_kwargs) from builtins.type\n |      Registers the current `tqdm` class with\n |          pandas.core.\n |          ( frame.DataFrame\n |          | series.Series\n |          | groupby.(generic.)DataFrameGroupBy\n |          | groupby.(generic.)SeriesGroupBy\n |          ).progress_apply\n |      \n |      A new instance will be create every time `progress_apply` is called,\n |      and each instance will automatically `close()` upon completion.\n |      \n |      Parameters\n |      ----------\n |      tqdm_kwargs  : arguments for the tqdm instance\n |      \n |      Examples\n |      --------\n |      >>> import pandas as pd\n |      >>> import numpy as np\n |      >>> from tqdm import tqdm\n |      >>> from tqdm.gui import tqdm as tqdm_gui\n |      >>>\n |      >>> df = pd.DataFrame(np.random.randint(0, 100, (100000, 6)))\n |      >>> tqdm.pandas(ncols=50)  # can use tqdm_gui, optional kwargs, etc\n |      >>> # Now you can use `progress_apply` instead of `apply`\n |      >>> df.groupby(0).progress_apply(lambda x: x**2)\n |      \n |      References\n |      ----------\n |      <https://stackoverflow.com/questions/18603270/        progress-indicator-during-pandas-operations-python>\n |  \n |  set_lock(lock) from builtins.type\n |      Set the global lock.\n |  \n |  wrapattr(stream, method, total=None, bytes=True, **tqdm_kwargs) from builtins.type\n |      stream  : file-like object.\n |      method  : str, \"read\" or \"write\". The result of `read()` and\n |          the first argument of `write()` should have a `len()`.\n |      \n |      >>> with tqdm.wrapattr(file_obj, \"read\", total=file_obj.size) as fobj:\n |      ...     while True:\n |      ...         chunk = fobj.read(chunk_size)\n |      ...         if not chunk:\n |      ...             break\n |  \n |  write(s, file=None, end='\\n', nolock=False) from builtins.type\n |      Print a message via tqdm (without overlap with bars).\n |  \n |  ----------------------------------------------------------------------\n |  Static methods defined here:\n |  \n |  __new__(cls, *_, **__)\n |      Create and return a new object.  See help(type) for accurate signature.\n |  \n |  format_interval(t)\n |      Formats a number of seconds as a clock time, [H:]MM:SS\n |      \n |      Parameters\n |      ----------\n |      t  : int\n |          Number of seconds.\n |      \n |      Returns\n |      -------\n |      out  : str\n |          [H:]MM:SS\n |  \n |  format_meter(n, total, elapsed, ncols=None, prefix='', ascii=False, unit='it', unit_scale=False, rate=None, bar_format=None, postfix=None, unit_divisor=1000, initial=0, colour=None, **extra_kwargs)\n |      Return a string-based progress bar given some parameters\n |      \n |      Parameters\n |      ----------\n |      n  : int or float\n |          Number of finished iterations.\n |      total  : int or float\n |          The expected total number of iterations. If meaningless (None),\n |          only basic progress statistics are displayed (no ETA).\n |      elapsed  : float\n |          Number of seconds passed since start.\n |      ncols  : int, optional\n |          The width of the entire output message. If specified,\n |          dynamically resizes `{bar}` to stay within this bound\n |          [default: None]. If `0`, will not print any bar (only stats).\n |          The fallback is `{bar:10}`.\n |      prefix  : str, optional\n |          Prefix message (included in total width) [default: ''].\n |          Use as {desc} in bar_format string.\n |      ascii  : bool, optional or str, optional\n |          If not set, use unicode (smooth blocks) to fill the meter\n |          [default: False]. The fallback is to use ASCII characters\n |          \" 123456789#\".\n |      unit  : str, optional\n |          The iteration unit [default: 'it'].\n |      unit_scale  : bool or int or float, optional\n |          If 1 or True, the number of iterations will be printed with an\n |          appropriate SI metric prefix (k = 10^3, M = 10^6, etc.)\n |          [default: False]. If any other non-zero number, will scale\n |          `total` and `n`.\n |      rate  : float, optional\n |          Manual override for iteration rate.\n |          If [default: None], uses n/elapsed.\n |      bar_format  : str, optional\n |          Specify a custom bar string formatting. May impact performance.\n |          [default: '{l_bar}{bar}{r_bar}'], where\n |          l_bar='{desc}: {percentage:3.0f}%|' and\n |          r_bar='| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, '\n |            '{rate_fmt}{postfix}]'\n |          Possible vars: l_bar, bar, r_bar, n, n_fmt, total, total_fmt,\n |            percentage, elapsed, elapsed_s, ncols, nrows, desc, unit,\n |            rate, rate_fmt, rate_noinv, rate_noinv_fmt,\n |            rate_inv, rate_inv_fmt, postfix, unit_divisor,\n |            remaining, remaining_s, eta.\n |          Note that a trailing \": \" is automatically removed after {desc}\n |          if the latter is empty.\n |      postfix  : *, optional\n |          Similar to `prefix`, but placed at the end\n |          (e.g. for additional stats).\n |          Note: postfix is usually a string (not a dict) for this method,\n |          and will if possible be set to postfix = ', ' + postfix.\n |          However other types are supported (#382).\n |      unit_divisor  : float, optional\n |          [default: 1000], ignored unless `unit_scale` is True.\n |      initial  : int or float, optional\n |          The initial counter value [default: 0].\n |      colour  : str, optional\n |          Bar colour (e.g. 'green', '#00ff00').\n |      \n |      Returns\n |      -------\n |      out  : Formatted meter and stats, ready to display.\n |  \n |  format_num(n)\n |      Intelligent scientific notation (.3g).\n |      \n |      Parameters\n |      ----------\n |      n  : int or float or Numeric\n |          A Number.\n |      \n |      Returns\n |      -------\n |      out  : str\n |          Formatted number.\n |  \n |  format_sizeof(num, suffix='', divisor=1000)\n |      Formats a number (greater than unity) with SI Order of Magnitude\n |      prefixes.\n |      \n |      Parameters\n |      ----------\n |      num  : float\n |          Number ( >= 1) to format.\n |      suffix  : str, optional\n |          Post-postfix [default: ''].\n |      divisor  : float, optional\n |          Divisor between prefixes [default: 1000].\n |      \n |      Returns\n |      -------\n |      out  : str\n |          Number with Order of Magnitude SI unit postfix.\n |  \n |  status_printer(file)\n |      Manage the printing and in-place updating of a line of characters.\n |      Note that if the string is longer than a line, then in-place\n |      updating may not work (it will print a new line at each refresh).\n |  \n |  ----------------------------------------------------------------------\n |  Readonly properties defined here:\n |  \n |  format_dict\n |      Public API for read-only member access.\n |  \n |  ----------------------------------------------------------------------\n |  Data and other attributes defined here:\n |  \n |  monitor = <TMonitor(Thread-4, started daemon 32548)>\n |  \n |  monitor_interval = 10\n |  \n |  ----------------------------------------------------------------------\n |  Methods inherited from tqdm.utils.Comparable:\n |  \n |  __eq__(self, other)\n |      Return self==value.\n |  \n |  __ge__(self, other)\n |      Return self>=value.\n |  \n |  __gt__(self, other)\n |      Return self>value.\n |  \n |  __le__(self, other)\n |      Return self<=value.\n |  \n |  __lt__(self, other)\n |      Return self<value.\n |  \n |  __ne__(self, other)\n |      Return self!=value.\n |  \n |  ----------------------------------------------------------------------\n |  Data descriptors inherited from tqdm.utils.Comparable:\n |  \n |  __dict__\n |      dictionary for instance variables (if defined)\n |  \n |  __weakref__\n |      list of weak references to the object (if defined)\n\n"
     ]
    }
   ],
   "source": [
    "help(tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "artist                                             Trick Daddy\n",
       "song_name                                           Nann Nigga\n",
       "song_id                                                  12385\n",
       "sent         (feat. Trina) [Trina] Hell no I don't wanna ho...\n",
       "Name: 446172, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "song_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Repeat (*)']"
      ]
     },
     "metadata": {},
     "execution_count": 214
    }
   ],
   "source": [
    "line_tokenize(song_info.sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "templ = np.array(word_tokenize(teku), dtype=object)\n",
    "kasd = np.array_split(templ, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "( feat . Trina ) [ Trina ] Hell no I do n't wan na holla at no motherfuckin Trick He all over there smelling like boonk and Hennesey and shit Hell no [ Taterhead ] I 'm saying though What\n"
     ]
    }
   ],
   "source": [
    "for i  in kasd:\n",
    "    print(' '.join(i))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([0., 1., 2.]), array([3., 4., 5.]), array([6., 7., 8.])]"
      ]
     },
     "metadata": {},
     "execution_count": 139
    }
   ],
   "source": [
    "x = np.arange(9.0)\n",
    "np.split(x, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Repeat', '(', '*', ')']"
      ]
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "temp_tk = 'Repeat (*)'\n",
    "word_tokenize(temp_tk)"
   ]
  }
 ]
}