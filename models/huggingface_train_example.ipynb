{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd063f661667cfff4a21b9f1172704ab3c7d831d3612a4dc528cd9d3281904853c9",
   "display_name": "Python 3.8.5 64-bit ('nlpai': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "# paths = [str(x) for x in Path(\".\").glob(\"**/*.txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize training\n",
    "tokenizer.train(files='oscar.eo.txt', vocab_size=52_000, min_frequency=2, special_tokens=[\n",
    "    \"<s>\",\n",
    "    \"<pad>\",\n",
    "    \"</s>\",\n",
    "    \"<unk>\",\n",
    "    \"<mask>\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['.\\\\esperberto-vocab.json', '.\\\\esperberto-merges.txt']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Save files to disk\n",
    "tokenizer.save_model(\".\", \"esperberto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"esperberto-vocab.json\",\n",
    "    \"esperberto-merges.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Encoding(num_tokens=7, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n"
     ]
    }
   ],
   "source": [
    "tokenizer.enable_truncation(max_length=512)\n",
    "\n",
    "print(\n",
    "    tokenizer.encode(\"Mi estas Julien.\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset\n",
    "\n",
    "# class EsperantoDataset(Dataset):\n",
    "#     def __init__(self, evaluate: bool = False):\n",
    "#         tokenizer = ByteLevelBPETokenizer(\n",
    "#             \"esperberto-vocab.json\",\n",
    "#             \"esperberto-merges.txt\",\n",
    "#         )\n",
    "#         tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "#             (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "#             (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    "#         )\n",
    "#         tokenizer.enable_truncation(max_length=512)\n",
    "#         # or use the RobertaTokenizer from `transformers` directly.\n",
    "\n",
    "#         self.examples = []\n",
    "\n",
    "#         src_files = Path(\"./data/\").glob(\"*-eval.txt\") if evaluate else Path(\"./data/\").glob(\"*-train.txt\")\n",
    "#         for src_file in src_files:\n",
    "#             print(\"ðŸ”¥\", src_file)\n",
    "#             lines = src_file.read_text(encoding=\"utf-8\").splitlines()\n",
    "#             self.examples += [x.ids for x in tokenizer.encode_batch(lines)]\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.examples)\n",
    "\n",
    "#     def __getitem__(self, i):\n",
    "#         # Weâ€™ll pad at the batch level.\n",
    "#         return torch.tensor(self.examples[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=52_000,\n",
    "    max_position_embeddings=514,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"julien-c/EsperBERTo-small\", max_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "--2021-04-11 19:33:18--  https://cdn-datasets.huggingface.co/EsperBERTo/data/oscar.eo.txt\n",
      "Resolving cdn-datasets.huggingface.co (cdn-datasets.huggingface.co)... 54.192.147.62, 54.192.147.68, 54.192.147.25, ...\n",
      "Connecting to cdn-datasets.huggingface.co (cdn-datasets.huggingface.co)|54.192.147.62|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 312733741 (298M) [text/plain]\n",
      "Saving to: 'oscar.eo.txt'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0%  113K 45m6s\n",
      "    50K .......... .......... .......... .......... ..........  0%  238K 33m14s\n",
      "   100K .......... .......... .......... .......... ..........  0% 2.52M 22m48s\n",
      "   150K .......... .......... .......... .......... ..........  0%  257K 22m3s\n",
      "   200K .......... .......... .......... .......... ..........  0% 2.46M 18m3s\n",
      "   250K .......... .......... .......... .......... ..........  0%  254K 18m23s\n",
      "   300K .......... .......... .......... .......... ..........  0%  252K 18m38s\n",
      "   350K .......... .......... .......... .......... ..........  0% 2.97M 16m30s\n",
      "   400K .......... .......... .......... .......... ..........  0%  253K 16m54s\n",
      "   450K .......... .......... .......... .......... ..........  0% 2.04M 15m27s\n",
      "   500K .......... .......... .......... .......... ..........  0%  269K 15m46s\n",
      "   550K .......... .......... .......... .......... ..........  0% 2.30M 14m38s\n",
      "   600K .......... .......... .......... .......... ..........  0%  249K 15m4s\n",
      "   650K .......... .......... .......... .......... ..........  0% 2.66M 14m7s\n",
      "   700K .......... .......... .......... .......... ..........  0%  270K 14m26s\n",
      "   750K .......... .......... .......... .......... ..........  0% 2.74M 13m39s\n",
      "   800K .......... .......... .......... .......... ..........  0%  268K 13m57s\n",
      "   850K .......... .......... .......... .......... ..........  0% 2.67M 13m17s\n",
      "   900K .......... .......... .......... .......... ..........  0% 2.75M 12m40s\n",
      "   950K .......... .......... .......... .......... ..........  0%  269K 12m59s\n",
      "  1000K .......... .......... .......... .......... ..........  0% 3.60M 12m26s\n",
      "  1050K .......... .......... .......... .......... ..........  0%  269K 12m43s\n",
      "  1100K .......... .......... .......... .......... ..........  0% 2.74M 12m15s\n",
      "  1150K .......... .......... .......... .......... ..........  0% 2.74M 11m48s\n",
      "  1200K .......... .......... .......... .......... ..........  0%  268K 12m5s\n",
      "  1250K .......... .......... .......... .......... ..........  0% 1.78M 11m44s\n",
      "  1300K .......... .......... .......... .......... ..........  0%  263K 12m0s\n",
      "  1350K .......... .......... .......... .......... ..........  0% 3.05M 11m38s\n",
      "  1400K .......... .......... .......... .......... ..........  0% 2.56M 11m18s\n",
      "  1450K .......... .......... .......... .......... ..........  0%  299K 11m29s\n",
      "  1500K .......... .......... .......... .......... ..........  0% 2.57M 11m10s\n",
      "  1550K .......... .......... .......... .......... ..........  0% 2.44M 10m53s\n",
      "  1600K .......... .......... .......... .......... ..........  0%  277K 11m6s\n",
      "  1650K .......... .......... .......... .......... ..........  0% 2.60M 10m50s\n",
      "  1700K .......... .......... .......... .......... ..........  0% 2.89M 10m34s\n",
      "  1750K .......... .......... .......... .......... ..........  0% 2.53M 10m20s\n",
      "  1800K .......... .......... .......... .......... ..........  0%  296K 10m31s\n",
      "  1850K .......... .......... .......... .......... ..........  0% 2.57M 10m17s\n",
      "  1900K .......... .......... .......... .......... ..........  0% 1.82M 10m5s\n",
      "  1950K .......... .......... .......... .......... ..........  0%  321K 10m14s\n",
      "  2000K .......... .......... .......... .......... ..........  0% 2.39M 10m2s\n",
      "  2050K .......... .......... .......... .......... ..........  0% 2.60M 9m50s\n",
      "  2100K .......... .......... .......... .......... ..........  0%  300K 10m0s\n",
      "  2150K .......... .......... .......... .......... ..........  0% 2.49M 9m49s\n",
      "  2200K .......... .......... .......... .......... ..........  0% 2.47M 9m38s\n",
      "  2250K .......... .......... .......... .......... ..........  0% 2.70M 9m28s\n",
      "  2300K .......... .......... .......... .......... ..........  0%  306K 9m37s\n",
      "  2350K .......... .......... .......... .......... ..........  0% 2.48M 9m27s\n",
      "  2400K .......... .......... .......... .......... ..........  0% 2.97M 9m17s\n",
      "  2450K .......... .......... .......... .......... ..........  0%  323K 9m25s\n",
      "  2500K .......... .......... .......... .......... ..........  0% 2.15M 9m16s\n",
      "  2550K .......... .......... .......... .......... ..........  0% 2.90M 9m8s\n",
      "  2600K .......... .......... .......... .......... ..........  0% 2.50M 8m59s\n",
      "  2650K .......... .......... .......... .......... ..........  0% 2.30M 8m52s\n",
      "  2700K .......... .......... .......... .......... ..........  0%  340K 8m58s\n",
      "  2750K .......... .......... .......... .......... ..........  0% 2.42M 8m51s\n",
      "  2800K .......... .......... .......... .......... ..........  0% 2.63M 8m43s\n",
      "  2850K .......... .......... .......... .......... ..........  0% 2.31M 8m36s\n",
      "  2900K .......... .......... .......... .......... ..........  0%  298K 8m45s\n",
      "  2950K .......... .......... .......... .......... ..........  0% 2.43M 8m38s\n",
      "  3000K .......... .......... .......... .......... ..........  0% 2.78M 8m31s\n",
      "  3050K .......... .......... .......... .......... ..........  1% 4.03M 8m24s\n",
      "  3100K .......... .......... .......... .......... ..........  1%  366K 8m29s\n",
      "  3150K .......... .......... .......... .......... ..........  1% 2.83M 8m23s\n",
      "  3200K .......... .......... .......... .......... ..........  1% 2.16M 8m17s\n",
      "  3250K .......... .......... .......... .......... ..........  1% 3.03M 8m11s\n",
      "  3300K .......... .......... .......... .......... ..........  1% 1.09M 8m7s\n",
      "  3350K .......... .......... .......... .......... ..........  1%  358K 8m12s\n",
      "  3400K .......... .......... .......... .......... ..........  1% 2.65M 8m7s\n",
      "  3450K .......... .......... .......... .......... ..........  1% 2.78M 8m1s\n",
      "  3500K .......... .......... .......... .......... ..........  1% 2.57M 7m56s\n",
      "  3550K .......... .......... .......... .......... ..........  1% 2.79M 7m51s\n",
      "  3600K .......... .......... .......... .......... ..........  1%  379K 7m55s\n",
      "  3650K .......... .......... .......... .......... ..........  1% 7.47M 7m49s\n",
      "  3700K .......... .......... .......... .......... ..........  1% 2.15M 7m45s\n",
      "  3750K .......... .......... .......... .......... ..........  1% 2.88M 7m40s\n",
      "  3800K .......... .......... .......... .......... ..........  1% 2.49M 7m35s\n",
      "  3850K .......... .......... .......... .......... ..........  1%  361K 7m40s\n",
      "  3900K .......... .......... .......... .......... ..........  1% 3.23M 7m35s\n",
      "  3950K .......... .......... .......... .......... ..........  1% 3.25M 7m31s\n",
      "  4000K .......... .......... .......... .......... ..........  1% 2.43M 7m27s\n",
      "  4050K .......... .......... .......... .......... ..........  1% 2.87M 7m22s\n",
      "  4100K .......... .......... .......... .......... ..........  1%  362K 7m27s\n",
      "  4150K .......... .......... .......... .......... ..........  1% 2.17M 7m23s\n",
      "  4200K .......... .......... .......... .......... ..........  1% 2.49M 7m19s\n",
      "  4250K .......... .......... .......... .......... ..........  1% 2.44M 7m16s\n",
      "  4300K .......... .......... .......... .......... ..........  1% 2.82M 7m12s\n",
      "  4350K .......... .......... .......... .......... ..........  1% 2.84M 7m8s\n",
      "  4400K .......... .......... .......... .......... ..........  1%  450K 7m11s\n",
      "  4450K .......... .......... .......... .......... ..........  1% 2.57M 7m7s\n",
      "  4500K .......... .......... .......... .......... ..........  1% 2.25M 7m4s\n",
      "  4550K .......... .......... .......... .......... ..........  1% 2.60M 7m0s\n",
      "  4600K .......... .......... .......... .......... ..........  1% 2.50M 6m57s\n",
      "  4650K .......... .......... .......... .......... ..........  1%  299K 7m3s\n",
      "  4700K .......... .......... .......... .......... ..........  1% 2.44M 7m0s\n",
      "  4750K .......... .......... .......... .......... ..........  1% 2.44M 6m57s\n",
      "  4800K .......... .......... .......... .......... ..........  1% 2.31M 6m54s\n",
      "  4850K .......... .......... .......... .......... ..........  1% 2.73M 6m50s\n",
      "  4900K .......... .......... .......... .......... ..........  1% 2.51M 6m47s\n",
      "  4950K .......... .......... .......... .......... ..........  1%  425K 6m50s\n",
      "  5000K .......... .......... .......... .......... ..........  1% 2.49M 6m47s\n",
      "  5050K .......... .......... .......... .......... ..........  1% 2.47M 6m44s\n",
      "  5100K .......... .......... .......... .......... ..........  1% 1.94M 6m42s\n",
      "  5150K .......... .......... .......... .......... ..........  1% 5.47M 6m38s\n",
      "  5200K .......... .......... .......... .......... ..........  1% 2.14M 6m36s\n",
      "  5250K .......... .......... .......... .......... ..........  1% 3.08M 6m33s\n",
      "  5300K .......... .......... .......... .......... ..........  1%  425K 6m36s\n",
      "  5350K .......... .......... .......... .......... ..........  1% 1.90M 6m34s\n",
      "  5400K .......... .......... .......... .......... ..........  1% 2.78M 6m31s\n",
      "  5450K .......... .......... .......... .......... ..........  1% 2.95M 6m28s\n",
      "  5500K .......... .......... .......... .......... ..........  1% 2.57M 6m26s\n",
      "  5550K .......... .......... .......... .......... ..........  1% 2.66M 6m23s\n",
      "  5600K .......... .......... .......... .......... ..........  1% 2.20M 6m21s\n",
      "  5650K .......... .......... .......... .......... ..........  1%  120K 6m39s\n",
      "  5700K .......... .......... .......... .......... ..........  1% 15.2M 6m36s\n",
      "  5750K .......... .......... .......... .......... ..........  1% 3.19M 6m33s\n",
      "  5800K .......... .......... .......... .......... ..........  1% 2.61M 6m31s\n",
      "  5850K .......... .......... .......... .......... ..........  1% 2.77M 6m28s\n",
      "  5900K .......... .......... .......... .......... ..........  1% 2.10M 6m26s\n",
      "  5950K .......... .......... .......... .......... ..........  1% 2.62M 6m24s\n",
      "  6000K .......... .......... .......... .......... ..........  1% 2.34M 6m22s\n",
      "  6050K .......... .......... .......... .......... ..........  1% 1.64M 6m20s\n",
      "  6100K .......... .......... .......... .......... ..........  2% 2.37M 6m18s\n",
      "  6150K .......... .......... .......... .......... ..........  2% 7.53M 6m15s\n",
      "  6200K .......... .......... .......... .......... ..........  2% 3.12M 6m13s\n",
      "  6250K .......... .......... .......... .......... ..........  2% 1.84M 6m11s\n",
      "  6300K .......... .......... .......... .......... ..........  2% 3.79M 6m9s\n",
      "  6350K .......... .......... .......... .......... ..........  2% 2.45M 6m7s\n",
      "  6400K .......... .......... .......... .......... ..........  2% 2.04M 6m5s\n",
      "  6450K .......... .......... .......... .......... ..........  2% 2.83M 6m3s\n",
      "  6500K .......... .......... .......... .......... ..........  2% 1.47M 6m1s\n",
      "  6550K .......... .......... .......... .......... ..........  2% 5.67M 5m59s\n",
      "  6600K .......... .......... .......... .......... ..........  2% 2.97M 5m57s\n",
      "  6650K .......... .......... .......... .......... ..........  2% 2.50M 5m55s\n",
      "  6700K .......... .......... .......... .......... ..........  2% 2.43M 5m53s\n",
      "  6750K .......... .......... .......... .......... ..........  2% 2.62M 5m51s\n",
      "  6800K .......... .......... .......... .......... ..........  2% 1.59M 5m50s\n",
      "  6850K .......... .......... .......... .......... ..........  2% 4.53M 5m48s\n",
      "  6900K .......... .......... .......... .......... ..........  2% 3.18M 5m46s\n",
      "  6950K .......... .......... .......... .......... ..........  2% 2.75M 5m44s\n",
      "  7000K .......... .......... .......... .......... ..........  2% 2.40M 5m43s\n",
      "  7050K .......... .......... .......... .......... ..........  2% 1.62M 5m41s\n",
      "  7100K .......... .......... .......... .......... ..........  2% 1.66M 5m40s\n",
      "  7150K .......... .......... .......... .......... ..........  2% 1.88M 5m39s\n",
      "  7200K .......... .......... .......... .......... ..........  2% 4.65M 5m37s\n",
      "  7250K .......... .......... .......... .......... ..........  2% 4.13M 5m35s\n",
      "  7300K .......... .......... .......... .......... ..........  2% 2.77M 5m33s\n",
      "  7350K .......... .......... .......... .......... ..........  2% 2.60M 5m32s\n",
      "  7400K .......... .......... .......... .......... ..........  2% 2.49M 5m30s\n",
      "  7450K .......... .......... .......... .......... ..........  2% 2.59M 5m29s\n",
      "  7500K .......... .......... .......... .......... ..........  2% 1.76M 5m28s\n",
      "  7550K .......... .......... .......... .......... ..........  2% 3.09M 5m26s\n",
      "  7600K .......... .......... .......... .......... ..........  2% 1.85M 5m25s\n",
      "  7650K .......... .......... .......... .......... ..........  2% 2.65M 5m24s\n",
      "  7700K .......... .......... .......... .......... ..........  2% 3.24M 5m22s\n",
      "  7750K .......... .......... .......... .......... ..........  2% 2.23M 5m21s\n",
      "  7800K .......... .......... .......... .......... ..........  2% 1.14M 5m20s\n",
      "  7850K .......... .......... .......... .......... ..........  2% 2.34M 5m19s\n",
      "  7900K .......... .......... .......... .......... ..........  2% 3.55M 5m17s\n",
      "  7950K .......... .......... .......... .......... ..........  2% 4.14M 5m16s\n",
      "  8000K .......... .......... .......... .......... ..........  2% 2.38M 5m15s\n",
      "  8050K .......... .......... .......... .......... ..........  2% 1.20M 5m14s\n",
      "  8100K .......... .......... .......... .......... ..........  2% 2.74M 5m13s\n",
      "  8150K .......... .......... .......... .......... ..........  2% 2.12M 5m12s\n",
      "  8200K .......... .......... .......... .......... ..........  2% 2.94M 5m10s\n",
      "  8250K .......... .......... .......... .......... ..........  2% 2.44M 5m9s\n",
      "  8300K .......... .......... .......... .......... ..........  2% 3.02M 5m8s\n",
      "  8350K .......... .......... .......... .......... ..........  2% 2.13M 5m7s\n",
      "  8400K .......... .......... .......... .......... ..........  2% 2.26M 5m6s\n",
      "  8450K .......... .......... .......... .......... ..........  2% 2.50M 5m4s\n",
      "  8500K .......... .......... .......... .......... ..........  2% 1003K 5m4s\n",
      "  8550K .......... .......... .......... .......... ..........  2% 3.24M 5m3s\n",
      "  8600K .......... .......... .......... .......... ..........  2% 2.69M 5m2s\n",
      "  8650K .......... .......... .......... .......... ..........  2% 2.19M 5m1s\n",
      "  8700K .......... .......... .......... .......... ..........  2% 2.36M 5m0s\n",
      "  8750K .......... .......... .......... .......... ..........  2% 2.60M 4m59s\n",
      "  8800K .......... .......... .......... .......... ..........  2% 2.78M 4m57s\n",
      "  8850K .......... .......... .......... .......... ..........  2% 2.37M 4m56s\n",
      "  8900K .......... .......... .......... .......... ..........  2% 2.30M 4m55s\n",
      "  8950K .......... .......... .......... .......... ..........  2% 2.36M 4m54s\n",
      "  9000K .......... .......... .......... .......... ..........  2% 1.21M 4m54s\n"
     ]
    }
   ],
   "source": [
    "# !wget -c https://cdn-datasets.huggingface.co/EsperBERTo/data/oscar.eo.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM\n",
    "\n",
    "model = RobertaForMaskedLM(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\anaconda\\envs\\nlpai\\lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:120: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "Wall time: 5min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import LineByLineTextDataset\n",
    "\n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"oscar.eo.txt\",\n",
    "    block_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "83504416"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "model.num_parameters()\n",
    "# => 84 million parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"EsperBERTo\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_gpu_train_batch_size=8,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "You can only call `wandb.watch` once per model.  Pass a new instance of the model if you need to call wandb.watch again in your code.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m         \u001b[1;31m# Skip the first epochs_trained epochs to get the random state of the dataloader at the right point.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\transformers\\trainer_callback.py\u001b[0m in \u001b[0;36mon_train_begin\u001b[1;34m(self, args, state, control)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[0mcontrol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_training_stop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"on_train_begin\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainerState\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainerControl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\transformers\\trainer_callback.py\u001b[0m in \u001b[0;36mcall_event\u001b[1;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m             result = getattr(callback, event)(\n\u001b[0m\u001b[0;32m    379\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m                 \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\transformers\\integrations.py\u001b[0m in \u001b[0;36mon_train_begin\u001b[1;34m(self, args, state, control, model, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wandb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialized\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 629\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\transformers\\integrations.py\u001b[0m in \u001b[0;36msetup\u001b[1;34m(self, args, state, model, **kwargs)\u001b[0m\n\u001b[0;32m    616\u001b[0m             \u001b[1;31m# keep track of model topology and gradients, unsupported on TPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"WANDB_WATCH\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"false\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m                 self._wandb.watch(\n\u001b[0m\u001b[0;32m    619\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"WANDB_WATCH\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"gradients\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 )\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\wandb\\sdk\\wandb_watch.py\u001b[0m in \u001b[0;36mwatch\u001b[1;34m(models, criterion, log, log_freq, idx)\u001b[0m\n\u001b[0;32m     91\u001b[0m         )\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         graph = wandb.wandb_torch.TorchGraph.hook_torch(\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobal_idx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         )\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\wandb\\wandb_torch.py\u001b[0m in \u001b[0;36mhook_torch\u001b[1;34m(cls, model, criterion, graph_idx)\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhook_torch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTorchGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m         \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhook_torch_modules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgraph_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\envs\\nlpai\\lib\\site-packages\\wandb\\wandb_torch.py\u001b[0m in \u001b[0;36mhook_torch_modules\u001b[1;34m(self, module, criterion, prefix, graph_idx)\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_wandb_watch_called\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wandb_watch_called\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    358\u001b[0m                 \u001b[1;34m\"You can only call `wandb.watch` once per model.  Pass a new instance of the model if you need to call wandb.watch again in your code.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: You can only call `wandb.watch` once per model.  Pass a new instance of the model if you need to call wandb.watch again in your code."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on method train in module transformers.trainer:\n\ntrain(resume_from_checkpoint: Union[str, bool, NoneType] = None, trial: Union[ForwardRef('optuna.Trial'), Dict[str, Any]] = None, **kwargs) method of transformers.trainer.Trainer instance\n    Main training entry point.\n    \n    Args:\n        resume_from_checkpoint (:obj:`str` or :obj:`bool`, `optional`):\n            If a :obj:`str`, local path to a saved checkpoint as saved by a previous instance of\n            :class:`~transformers.Trainer`. If a :obj:`bool` and equals `True`, load the last checkpoint in\n            `args.output_dir` as saved by a previous instance of :class:`~transformers.Trainer`. If present,\n            training will resume from the model/optimizer/scheduler states loaded here.\n        trial (:obj:`optuna.Trial` or :obj:`Dict[str, Any]`, `optional`):\n            The trial run or the hyperparameter dictionary for hyperparameter search.\n        kwargs:\n            Additional keyword arguments used to hide deprecated arguments\n\n"
     ]
    }
   ],
   "source": [
    "help(trainer.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"EsperBERTo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=\"EsperBERTo\",\n",
    "    tokenizer=\"EsperBERTo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sun <mask>.\n",
    "# =>\n",
    "\n",
    "fill_mask(\"La suno <mask>.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_mask(\"Jen la komenco de bela <mask>.\")\n",
    "\n",
    "# This is the beginning of a beautiful <mask>.\n",
    "# =>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}