{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('nlpai': conda)",
   "metadata": {
    "interpreter": {
     "hash": "63f661667cfff4a21b9f1172704ab3c7d831d3612a4dc528cd9d3281904853c9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from time import time \n",
    "from gensim.models import KeyedVectors\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "# Pytorch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# stanza\n",
    "import stanza as st\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pretrained word2vec\n",
    "import gensim.downloader as api\n",
    "corpus = api.load('glove-wiki-gigaword-50', return_path=True)\n",
    "pretrainedwvmodel = KeyedVectors.load_word2vec_format(corpus)\n",
    "embedding_matrix = pretrainedwvmodel.wv.vectors\n",
    "embedding_matrix = np.append(embedding_matrix, np.zeros((1,50)), axis=0) # Padding\n",
    "embedding_matrix = np.append(embedding_matrix, np.zeros((1,50)), axis=0)\n",
    "embedding_matrix = np.append(embedding_matrix, np.zeros((1,50)), axis=0) # Unknown word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-02-28 14:41:26 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| depparse  | combined  |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-02-28 14:41:26 INFO: Use device: gpu\n",
      "2021-02-28 14:41:26 INFO: Loading: tokenize\n",
      "2021-02-28 14:41:31 INFO: Loading: pos\n",
      "2021-02-28 14:41:32 INFO: Loading: lemma\n",
      "2021-02-28 14:41:32 INFO: Loading: depparse\n",
      "2021-02-28 14:41:33 INFO: Loading: sentiment\n",
      "2021-02-28 14:41:33 INFO: Loading: ner\n",
      "2021-02-28 14:41:34 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TAG2CLASS = {\n",
    "    '<PAD>': 0,\n",
    "    'CC': 1,\n",
    "    'CD': 2,\n",
    "    'DT': 3,\n",
    "    'EX': 4,\n",
    "    'FW': 5,\n",
    "    'IN': 6,\n",
    "    'JJ': 7,\n",
    "    'JJR': 8,\n",
    "    'JJS': 9,\n",
    "    'LS': 10,\n",
    "    'MD': 11,\n",
    "    'NN': 12,\n",
    "    'NNS': 13,\n",
    "    'NNP': 14,\n",
    "    'NNPS': 15,\n",
    "    'PDT': 16,\n",
    "    'POS': 17,\n",
    "    'PRP': 18,\n",
    "    'PRP$': 19,\n",
    "    'RB': 20,\n",
    "    'RBR': 21,\n",
    "    'RBS': 22,\n",
    "    'RP': 23,\n",
    "    'SYM': 24,\n",
    "    'TO': 25,\n",
    "    'UH': 26,\n",
    "    'VB': 27,\n",
    "    'VBD': 28,\n",
    "    'VBG': 29,\n",
    "    'VBN': 30,\n",
    "    'VBP': 31,\n",
    "    'VBZ': 32,\n",
    "    'WDT': 33,\n",
    "    'WP': 34,\n",
    "    'WP$': 35,\n",
    "    'WRB': 36,\n",
    "    '-RRB-': 37,\n",
    "    '-LRB-':38,\n",
    "        '<UNK>': 0,\n",
    "    \n",
    "}\n",
    "pos_tagger = st.Pipeline(lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataMapper1(Dataset):\n",
    "    def __init__(self, sentence_lyrics, wvmodel, sequence_len):\n",
    "        self.sents = sentence_lyrics\n",
    "        self.sequence_len = sequence_len\n",
    "        self.model = wvmodel\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sents)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        doc = pos_tagger(self.sents[idx])\n",
    "        xl = []\n",
    "        yl = []\n",
    "        seq = np.zeros(self.sequence_len, dtype=np.int64)\n",
    "        yseq = np.zeros(self.sequence_len, dtype=np.int64)\n",
    "        for k in doc.sentences[0].words:\n",
    "            if (self.model.wv.vocab.get(k.text) is None):\n",
    "                xl.append(400002)\n",
    "                yl.append(TAG2CLASS.get('<UNK>'))\n",
    "                continue\n",
    "            xl.append(self.model.wv.vocab.get(k.text).index)\n",
    "            yl.append(TAG2CLASS.get(k.xpos, 0))\n",
    "        seq[:len(xl)] = xl[:self.sequence_len]\n",
    "        yseq[:len(yl)] = yl[:self.sequence_len]\n",
    "        return seq, yseq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Sentences_15klyrics_mls_20.csv')\n",
    "train_data = data.sent[:8000].to_numpy()\n",
    "val_random = np.random.choice(data[:8000].to_numpy().flatten(), 800)\n",
    "val_data = np.append(val_random, data.sent[10001:10801].to_numpy())\n",
    "test_data = data.sent[8000:10001].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = DataMapper1(train_data, pretrainedwvmodel, 20)\n",
    "val_set = DataMapper1(val_data, pretrainedwvmodel, 20)\n",
    "test_set = DataMapper1(test_data, pretrainedwvmodel, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_training = DataLoader(training_set, batch_size=16)\n",
    "loader_val = DataLoader(training_set, batch_size=16)\n",
    "loader_test = DataLoader(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 557648 entries, 0 to 557647\nData columns (total 4 columns):\n #   Column     Non-Null Count   Dtype \n---  ------     --------------   ----- \n 0   artist     557648 non-null  object\n 1   song_name  557648 non-null  object\n 2   song_id    557648 non-null  int64 \n 3   sent       557646 non-null  object\ndtypes: int64(1), object(3)\nmemory usage: 17.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x tensor([[    20,      9,      7,  37701,   2895,    907,     81,    100,  46215,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0],\n        [  8738,     20,      9,  11999,   4385,      5,    359,    364,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0],\n        [   253,     81,  11229,     23,    253,     20,     13,     24,    392,\n           3825,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0],\n        [   392,  72488,   9085,      0,      0,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0],\n        [    81,    267,      7,   6413,    300,     17,     48,  48271,   1812,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0],\n        [   197,     39,    960,     81,     60,    147,     49,    147,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0],\n        [     5,     61,     81,   2274,     60,     81,    267,    222,      4,\n             30,      7,  16279,      0,      0,      0,      0,      0,      0,\n              0,      0],\n        [   303,      7,   2528,   1749,     38,      9,     36,   7731,      3,\n           1096,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0],\n        [   275,    285,   1916,    192,     79,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0],\n        [    57,   1157, 400002,    769,    332,     30,   1695,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0],\n        [   275,    285,   1916,    192,     79,      0,      0,      0,      0,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0],\n        [    81,    388,    135,      4,    662,     22,    167,   2691,    328,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0],\n        [   111,     81,    390,     30,   4478,    120,      4,   3927,    204,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0],\n        [   541,     20,     13,    816,    197,      4,   1916,    392,    300,\n              0,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0],\n        [   127,    117,  79100,      9,   1500,      7,  12704,      6,    392,\n            823,      0,      0,      0,      0,      0,      0,      0,      0,\n              0,      0],\n        [    81,    439,    580,    392,   6075,     67,      9,     66,    862,\n             10,     81,      0,      0,      0,      0,      0,      0,      0,\n              0,      0]])\ny tensor([[18, 32,  3, 12, 12, 32, 18, 20,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0],\n        [26, 18, 32, 12, 12,  1,  3, 12,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0],\n        [27, 18, 12, 38, 27, 18,  6, 37, 19, 12,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0],\n        [19, 12, 12,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0],\n        [18, 31,  3, 12, 12,  6,  2, 12, 12,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0],\n        [36, 18, 31, 18, 23, 12,  6, 12,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0],\n        [ 1, 36, 18, 31, 23, 18, 31, 29, 25, 27,  3, 12,  0,  0,  0,  0,  0,  0,\n          0,  0],\n        [27,  3,  7, 12, 34, 32, 20,  7,  6, 12,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0],\n        [27, 18, 27, 19, 12,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0],\n        [ 0,  6,  0, 11, 20, 27,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0],\n        [27, 18, 27, 19, 12,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0],\n        [18, 28, 20, 25, 27,  6,  7, 14, 12,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0],\n        [36, 18, 11, 27,  7, 20, 25, 27, 23,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0],\n        [30, 18,  6, 12, 36, 25, 27, 19, 12,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0],\n        [20,  6, 14, 17, 12,  3, 12,  6, 19, 12,  0,  0,  0,  0,  0,  0,  0,  0,\n          0,  0],\n        [18, 21, 27, 19, 12, 18, 32, 20, 29,  6, 18,  0,  0,  0,  0,  0,  0,  0,\n          0,  0]])\n"
     ]
    }
   ],
   "source": [
    "for x, y in loader_training:\n",
    "    print('x', x)\n",
    "    print('y', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple_Sequence_LSTM(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(Simple_Sequence_LSTM, self).__init__()\n",
    "\n",
    "        # Hyperparameters\n",
    "        # self.batch_size = args.batch_size\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.LSTM_layers = args.lstm_layers\n",
    "        # self.input_size = args.input_size\n",
    "        self.embedding_matrix = args.embedding_matrix.cuda()\n",
    "        self.target_size = args.target_size\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        # self.embedding = nn.Embedding(self.input_size, self.hidden_dim, padding_idx=0)\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            self.embedding_matrix, padding_idx=args.padding_idx, freeze=True)\n",
    "        self.lstm = nn.LSTM(input_size=self.hidden_dim, hidden_size=self.hidden_dim,\n",
    "                            num_layers=self.LSTM_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(in_features=self.hidden_dim,\n",
    "                             out_features=self.hidden_dim*2)\n",
    "        self.fc2 = nn.Linear(self.hidden_dim*2, self.target_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Hidden and cell state definion\n",
    "        h = torch.zeros((self.LSTM_layers, x.size(0), self.hidden_dim)).cuda()\n",
    "        c = torch.zeros((self.LSTM_layers, x.size(0), self.hidden_dim)).cuda()\n",
    "\n",
    "        # Initialization fo hidden and cell states\n",
    "        torch.nn.init.xavier_normal_(h)\n",
    "        torch.nn.init.xavier_normal_(c)\n",
    "\n",
    "        # Each sequence \"x\" is passed through an embedding layer\n",
    "        out = self.embedding(x)\n",
    "        # Feed LSTMs\n",
    "        out, (hidden, cell) = self.lstm(out, (h, c))\n",
    "        out = self.dropout(out)\n",
    "        # The last hidden state is taken\n",
    "        out = torch.relu_(self.fc1(out[:, -1, :]))\n",
    "        out = self.dropout(out)\n",
    "        out = torch.sigmoid(self.fc2(out))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple_Sequence_LSTMver2(nn.Module):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(Simple_Sequence_LSTMver2, self).__init__()\n",
    "        # Hyperparameters\n",
    "        self.hidden_dim = args.hidden_dim\n",
    "        self.LSTM_layers = args.lstm_layers\n",
    "        self.embedding_matrix = args.embedding_matrix.cuda()\n",
    "        self.target_size = args.target_size\n",
    "        self.tag_class_size = args.class_number\n",
    "\n",
    "        self.word_embeddings = nn.Embedding.from_pretrained(\n",
    "            self.embedding_matrix, padding_idx=args.padding_idx, freeze=True)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(self.hidden_dim, self.hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(self.hidden_dim, self.tag_class_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        # # Hidden and cell state definion\n",
    "        # h = torch.zeros((self.LSTM_layers, x.size(0), self.hidden_dim)).cuda()\n",
    "        # c = torch.zeros((self.LSTM_layers, x.size(0), self.hidden_dim)).cuda()\n",
    "\n",
    "        # # Initialization fo hidden and cell states\n",
    "        # torch.nn.init.xavier_normal_(h)\n",
    "        # torch.nn.init.xavier_normal_(c)\n",
    "\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        # lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1),(h, c))\n",
    "        # print(embeds.view(len(sentence), 1, -1).shape)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        tag_space = self.hidden2tag(lstm_out)\n",
    "        # print(lstm_out.view(len(sentence), -1).shape)\n",
    "        # tag_space = tag_space.view(len(sentence), self.tag_class_size)\n",
    "        tag_scores = torch.sigmoid_(tag_space)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = torch.FloatTensor(embedding_matrix)\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "lstm_dict = {\n",
    "    # 'batch_size':8,\n",
    "    'hidden_dim': embedding_matrix.shape[1],\n",
    "    'lstm_layers':3,\n",
    "    # 'input_size':embedding_matrix.shape[0],\n",
    "    'padding_idx': 400001,\n",
    "    'target_size': 20,\n",
    "    'class_number': 40,\n",
    "    'embedding_matrix': embedding_matrix\n",
    "}\n",
    "lstm_args = namedtuple('lstm_args', lstm_dict.keys())(**lstm_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Simple_Sequence_LSTM(lstm_args).cuda()\n",
    "model = Simple_Sequence_LSTMver2(lstm_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Simple_Sequence_LSTMver2(\n",
       "  (word_embeddings): Embedding(400003, 50, padding_idx=400001)\n",
       "  (lstm): LSTM(50, 50)\n",
       "  (hidden2tag): Linear(in_features=50, out_features=40, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y, tag_pad_idx=0):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements]).cuda()\n",
    "    return correct.sum() / torch.FloatTensor([y[non_pad_elements].shape[0]]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01,momentum=0.9,weight_decay=0.0001)\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    sum_loss = 0.0\n",
    "    total = 0\n",
    "    epoch_acc = 0\n",
    "    for x, y in loader_training:\n",
    "        x = torch.tensor(x).to(torch.long).cuda()\n",
    "        y_pred = model(x)\n",
    "        y = torch.tensor(y).to(torch.long).cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred_2 = y_pred.view(-1, y_pred.shape[-1])\n",
    "        y_2 = y.view(-1)\n",
    "        loss = loss_function(y_pred_2, y_2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "        total += y.shape[0]\n",
    "        acc = categorical_accuracy(y_pred_2, y_2)\n",
    "        # print(acc.item())\n",
    "        epoch_acc += acc.item()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_metrics (model, valid_dl):\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    acc_total = 0.0\n",
    "    for x, y in valid_dl:\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        y_hat = model(x)\n",
    "        y_pred_2 = y_pred.view(-1, y_hat.shape[-1])\n",
    "        y_2 = y.view(-1)\n",
    "        loss = loss_function(y_hy_pred_2at, y_2)\n",
    "        pred = torch.max(y_hat, 0)[1]\n",
    "        correct += (pred == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "        acc = categorical_accuracy(y_pred_2, y_2)\n",
    "        acc_total = acc.item()\n",
    "#     torch.cuda.empty_cache()\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_metrics(model, loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function Tensor.type>"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "y_pred.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([16, 20])"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_x = model.word_embeddings(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([16, 20, 50])"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "temp_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 1000])"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "temp_x.view(len(x), 1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([16, 20])"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([16, 20, 40])"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([16, 20, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "source": [
    "torch.argmax(y_pred, dim=2, keepdims=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_preds = y_pred_2.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "non_pad_elements = (y_2 != 0).nonzero()\n",
    "correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-c9fd25e5404e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0my_2\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "(y_2 != 0).nonzero().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-6afcdfdb4e70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmax_preds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnon_pad_elements\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnon_pad_elements\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([320, 40])"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "source": [
    "y_pred.view(-1, y_pred.shape[-1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([320])"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "y.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(160.4284, device='cuda:0', grad_fn=<MseLossBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[18., 32.,  3., 12., 12., 32., 18., 20.,  7.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [26., 18., 32., 12., 12.,  1.,  3., 12.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [27., 18., 12., 38., 27., 18.,  6., 37., 19., 12.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [19., 12., 12.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [18., 31.,  3., 12., 12.,  6.,  2., 12., 12.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [36., 18., 31., 18., 23., 12.,  6., 12.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1., 36., 18., 31., 23., 18., 31., 29., 25., 27.,  3., 12.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [27.,  3.,  7., 12., 34., 32., 20.,  7.,  6., 12.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [27., 18., 27., 19., 12.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  6.,  0., 11., 20., 27.,  7.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [27., 18., 27., 19., 12.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [18., 28., 20., 25., 27.,  6.,  7., 14., 12.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [36., 18., 11., 27.,  7., 20., 25., 27., 23.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [30., 18.,  6., 12., 36., 25., 27., 19., 12.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [20.,  6., 14., 17., 12.,  3., 12.,  6., 19., 12.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [18., 21., 27., 19., 12., 18., 32., 20., 29.,  6., 18.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.4804, 0.5022, 0.5154, 0.5029, 0.4657, 0.4731, 0.5068, 0.4814, 0.5173,\n",
       "         0.5142, 0.4733, 0.5253, 0.4865, 0.5115, 0.5093, 0.5199, 0.5114, 0.5046,\n",
       "         0.4833, 0.5047],\n",
       "        [0.4905, 0.4938, 0.5104, 0.4779, 0.4656, 0.4833, 0.5162, 0.4951, 0.5312,\n",
       "         0.5081, 0.4711, 0.5254, 0.4972, 0.4989, 0.5116, 0.5252, 0.5231, 0.5059,\n",
       "         0.4760, 0.5167],\n",
       "        [0.4889, 0.4954, 0.4981, 0.4817, 0.4880, 0.4883, 0.5224, 0.4950, 0.5327,\n",
       "         0.5132, 0.4697, 0.5099, 0.4923, 0.4962, 0.5004, 0.5179, 0.5053, 0.5226,\n",
       "         0.5011, 0.5132],\n",
       "        [0.4924, 0.4848, 0.5028, 0.4912, 0.4702, 0.4852, 0.4890, 0.4843, 0.5231,\n",
       "         0.5249, 0.4748, 0.5362, 0.5151, 0.5018, 0.5238, 0.5253, 0.5218, 0.5103,\n",
       "         0.4878, 0.5152],\n",
       "        [0.5097, 0.4828, 0.4946, 0.4645, 0.4819, 0.4738, 0.5039, 0.4654, 0.5052,\n",
       "         0.5198, 0.4682, 0.5340, 0.5118, 0.4906, 0.5061, 0.5169, 0.5201, 0.5156,\n",
       "         0.4672, 0.5013],\n",
       "        [0.4909, 0.4949, 0.4876, 0.4803, 0.4870, 0.4810, 0.4948, 0.4811, 0.5178,\n",
       "         0.5084, 0.4559, 0.5116, 0.5180, 0.5103, 0.5001, 0.5067, 0.5188, 0.5167,\n",
       "         0.4676, 0.4936],\n",
       "        [0.4847, 0.4863, 0.5056, 0.4929, 0.4539, 0.4940, 0.4926, 0.5047, 0.5209,\n",
       "         0.5031, 0.4633, 0.5116, 0.4978, 0.5240, 0.5014, 0.5243, 0.5222, 0.4904,\n",
       "         0.4864, 0.5022],\n",
       "        [0.4963, 0.4940, 0.5088, 0.4912, 0.4805, 0.4728, 0.5092, 0.4940, 0.5120,\n",
       "         0.5110, 0.4867, 0.5238, 0.4974, 0.5116, 0.4993, 0.5216, 0.5014, 0.4968,\n",
       "         0.4768, 0.5095],\n",
       "        [0.4957, 0.4974, 0.4915, 0.4887, 0.4741, 0.4815, 0.5104, 0.4966, 0.5196,\n",
       "         0.5026, 0.4657, 0.5220, 0.5107, 0.5032, 0.5063, 0.5304, 0.5038, 0.5154,\n",
       "         0.4897, 0.5181],\n",
       "        [0.4901, 0.5121, 0.4950, 0.4948, 0.4598, 0.4790, 0.5003, 0.4921, 0.5135,\n",
       "         0.5044, 0.4582, 0.5181, 0.5094, 0.5093, 0.4973, 0.5187, 0.5203, 0.4985,\n",
       "         0.4834, 0.5103],\n",
       "        [0.4955, 0.4918, 0.4889, 0.4742, 0.4796, 0.4731, 0.4838, 0.4800, 0.5239,\n",
       "         0.5164, 0.4621, 0.5095, 0.5227, 0.4943, 0.5076, 0.5298, 0.5088, 0.5109,\n",
       "         0.4642, 0.5100],\n",
       "        [0.4850, 0.4937, 0.5009, 0.5058, 0.4758, 0.4788, 0.5086, 0.5079, 0.5235,\n",
       "         0.5163, 0.4683, 0.5212, 0.4909, 0.5076, 0.5023, 0.5333, 0.5159, 0.5078,\n",
       "         0.5068, 0.5196],\n",
       "        [0.4948, 0.4937, 0.5017, 0.4870, 0.4771, 0.4684, 0.4975, 0.4816, 0.5079,\n",
       "         0.4991, 0.4831, 0.5111, 0.4977, 0.4934, 0.4953, 0.5240, 0.5106, 0.5115,\n",
       "         0.4739, 0.4998],\n",
       "        [0.4880, 0.4909, 0.4978, 0.4969, 0.4780, 0.4884, 0.4863, 0.4838, 0.5196,\n",
       "         0.5162, 0.4527, 0.5041, 0.5065, 0.5146, 0.4992, 0.5105, 0.5127, 0.4996,\n",
       "         0.4507, 0.5116],\n",
       "        [0.4990, 0.4872, 0.4986, 0.4854, 0.4925, 0.4894, 0.5156, 0.4959, 0.5229,\n",
       "         0.5118, 0.4794, 0.4999, 0.4987, 0.4995, 0.4896, 0.5217, 0.5129, 0.5208,\n",
       "         0.4913, 0.5060],\n",
       "        [0.4797, 0.4829, 0.4952, 0.4757, 0.4814, 0.4774, 0.5001, 0.4873, 0.5223,\n",
       "         0.5152, 0.4577, 0.4969, 0.5116, 0.5042, 0.5140, 0.5018, 0.5106, 0.5258,\n",
       "         0.4757, 0.5084]], device='cuda:0', grad_fn=<SigmoidBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Linear(in_features=100, out_features=20, bias=True)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "model.fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Linear(in_features=50, out_features=100, bias=True)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "model.fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor(3.6673, device='cuda:0', grad_fn=<NllLossBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}