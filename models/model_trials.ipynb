{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "63f661667cfff4a21b9f1172704ab3c7d831d3612a4dc528cd9d3281904853c9"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import heapq\n",
    "import pprint\n",
    "\n",
    "from nltk.tokenize import wordpunct_tokenize, blankline_tokenize, line_tokenize, word_tokenize\n",
    "from itertools import combinations\n",
    "from nltk.corpus import stopwords\n",
    "from time import time \n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import multiprocessing\n",
    "from collections import namedtuple\n",
    "\n",
    "# # tensorflow\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pytorch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# stanza\n",
    "import stanza as st\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lyrics_dataloader import DataMapper\n",
    "from models import Simple_Sequence_LSTM\n",
    "# Pretrained word2vec\n",
    "import gensim.downloader as api\n",
    "corpus = api.load('fasttext-wiki-news-subwords-300', return_path=True)\n",
    "pretrainedwvmodel = KeyedVectors.load_word2vec_format(corpus)\n",
    "embedding_matrix = pretrainedwvmodel.wv.vectors\n",
    "embedding_matrix = np.append(embedding_matrix, np.zeros((1,300)), axis=0) # Padding\n",
    "embedding_matrix = np.append(embedding_matrix, np.zeros((1,300)), axis=0) # Unknown word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-02-26 17:22:44 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| depparse  | combined  |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-02-26 17:22:44 INFO: Use device: gpu\n",
      "2021-02-26 17:22:44 INFO: Loading: tokenize\n",
      "2021-02-26 17:22:48 INFO: Loading: pos\n",
      "2021-02-26 17:22:49 INFO: Loading: lemma\n",
      "2021-02-26 17:22:49 INFO: Loading: depparse\n",
      "2021-02-26 17:22:49 INFO: Loading: sentiment\n",
      "2021-02-26 17:22:50 INFO: Loading: ner\n",
      "2021-02-26 17:22:51 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# Max length known from 15K lyrics = 811\n",
    "# Splitted into 20 lengthed sentences\n",
    "# Training : Test == 8 : 2\n",
    "# Training : Val == 8 : 2\n",
    "data = pd.read_csv('sentences_15klyrics_mls_20.csv')\n",
    "train_data = data.sent[:8000].to_numpy\n",
    "val_random = np.random.choice(data[:8000].to_numpy().flatten(), 800)\n",
    "val_data = np.append(val_random, data.sent[10001:10801].to_numpy())\n",
    "test_data = data.sent[8000:10001].to_numpy()\n",
    "\n",
    "training_set = DataMapper(train_data, pretrainedwvmodel, 20)\n",
    "val_set = DataMapper(val_data, pretrainedwvmodel, 20)\n",
    "test_set = DataMapper(test_data, pretrainedwvmodel, 20)\n",
    "\n",
    "loader_training = DataLoader(training_set, batch_size=8)\n",
    "loader_val = DataLoader(training_set, batch_size=8)\n",
    "loader_test = DataLoader(test_set)\n",
    "\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "lstm_dict = {\n",
    "    # 'batch_size':8,\n",
    "    'hidden_dim': embedding_matrix.shape[1],\n",
    "    'lstm_layers':3,\n",
    "    # 'input_size':embedding_matrix.shape[0],\n",
    "    'padding_idx': 1000001,\n",
    "    'target_size': 20,\n",
    "    'embedding_matrix': embedding_matrix\n",
    "}\n",
    "lstm_args = namedtuple('lstm_args', lstm_dict.keys())(**lstm_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 557648 entries, 0 to 557647\nData columns (total 4 columns):\n #   Column     Non-Null Count   Dtype \n---  ------     --------------   ----- \n 0   artist     557648 non-null  object\n 1   song_name  557648 non-null  object\n 2   song_id    557648 non-null  int64 \n 3   sent       557646 non-null  object\ndtypes: int64(1), object(3)\nmemory usage: 17.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([\"it's a junkie dream makes you so uptight\",\n",
       "       \"yeah it's halloween tonight and every night\",\n",
       "       'see you scratch (see it on) your skin', 'your sandpaper throat',\n",
       "       \"you're a symphony man with one fucking note\",\n",
       "       'how they beat you up week after week',\n",
       "       \"and when you grow up you're going to be a freak\",\n",
       "       \"want a violent girl who's not scared of anything\",\n",
       "       'help me kill my time', \"'cause I'll never be fine\"], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "data.sent[:10].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "len(\"it's a junkie dream makes you so uptight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = np.append(np.random.choice(data[:8000].to_numpy().flatten(), 800), data.sent[10001:10801].to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1600,)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([   19,    24,     7, 45314,  3758,   618,    30,    57, 54995,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0], dtype=int64),\n",
       " array([18, 32, 3, 12, 12, 32, 18, 20, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       dtype=object))"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "Training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Simple_Sequence_LSTM(lstm_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_metrics (model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    sum_rmse = 0.0\n",
    "    for x, y in valid_dl:\n",
    "        x = x.cuda()\n",
    "        y_hat = model(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = torch.max(y_hat, 1)[1]\n",
    "        correct += (pred == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "        sum_rmse += np.sqrt(mean_squared_error(pred, y.unsqueeze(-1)))*y.shape[0]\n",
    "    torch.cuda.empty_cache()\n",
    "    return sum_loss/total, correct/total, sum_rmse/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr =lr,momentum=0.9,weight_decay=0.0001)\n",
    "loss_function = nn.NLLLoss()\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    sum_loss = 0.0\n",
    "    total = 0\n",
    "    for x, y in loader_training:\n",
    "        x = torch.tensor(x).to(torch.long).cuda()\n",
    "        y_pred = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "        total += y.shape[0]\n",
    "    val_loss, val_acc, val_rmse = validation_metrics(model, loader_val)\n",
    "    torch.cuda.empty_cache()\n",
    "    if i % 5 == 1:\n",
    "        print(\"train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (sum_loss/total, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "        print(sentence_in)\n",
    "        print('targets: ', targets)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "        print('predicted: ',torch.argmax(tag_scores, 1))\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  }
 ]
}