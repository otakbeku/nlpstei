{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd063f661667cfff4a21b9f1172704ab3c7d831d3612a4dc528cd9d3281904853c9",
   "display_name": "Python 3.8.5 64-bit ('nlpai': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "     AutoTokenizer,\n",
    "     AutoModelForSeq2SeqLM,\n",
    "     LogitsProcessorList,\n",
    "     MinLengthLogitsProcessor,\n",
    "     TopKLogitsWarper,\n",
    "     TemperatureLogitsWarper,\n",
    "     BeamSearchScorer,\n",
    " )\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = pipeline(\"zero-shot-classification\", device=0)\n",
    "df = pd.read_csv(\n",
    "    'sample_100_15k.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   artist                      song_name closest_genre  \\\n",
       "0               Sam Cooke        Meet Me At Mary's Place         Blues   \n",
       "1         Curtis Mayfield  Give Me Your Love (Love Song)         Blues   \n",
       "2               Sam Cooke         Another Saturday Night         Blues   \n",
       "3  Sonny Boy Williamson I       Something Going On Wrong         Blues   \n",
       "4             Carole King                 Where You Lead         Blues   \n",
       "\n",
       "                                               lyric  length_lyric  \n",
       "0  A friend of mine told me one early mornin'\\n(O...           290  \n",
       "1  SO IN LOVE\\nSO IN LOVE, YOU DO SO MANY THINGS ...           218  \n",
       "2  Let me tell you 'bout a place\\nSomewhere up-a ...           220  \n",
       "3  (Together) We will go our way\\n(Together) We w...           364  \n",
       "4  Wanting you the way I do\\nI only wanna be with...           166  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>artist</th>\n      <th>song_name</th>\n      <th>closest_genre</th>\n      <th>lyric</th>\n      <th>length_lyric</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sam Cooke</td>\n      <td>Meet Me At Mary's Place</td>\n      <td>Blues</td>\n      <td>A friend of mine told me one early mornin'\\n(O...</td>\n      <td>290</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Curtis Mayfield</td>\n      <td>Give Me Your Love (Love Song)</td>\n      <td>Blues</td>\n      <td>SO IN LOVE\\nSO IN LOVE, YOU DO SO MANY THINGS ...</td>\n      <td>218</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sam Cooke</td>\n      <td>Another Saturday Night</td>\n      <td>Blues</td>\n      <td>Let me tell you 'bout a place\\nSomewhere up-a ...</td>\n      <td>220</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sonny Boy Williamson I</td>\n      <td>Something Going On Wrong</td>\n      <td>Blues</td>\n      <td>(Together) We will go our way\\n(Together) We w...</td>\n      <td>364</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Carole King</td>\n      <td>Where You Lead</td>\n      <td>Blues</td>\n      <td>Wanting you the way I do\\nI only wanna be with...</td>\n      <td>166</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "len(df.lyric[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 1.20k/1.20k [00:00<00:00, 600kB/s]\n",
      "Downloading: 100%|██████████| 792k/792k [00:01<00:00, 527kB/s]\n",
      "Downloading: 100%|██████████| 1.39M/1.39M [00:02<00:00, 677kB/s] \n",
      "Downloading: 100%|██████████| 892M/892M [06:56<00:00, 2.14MB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('t5-base')\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = (\n",
    " \"at least two people were killed in a suspected bomb attack on a passenger bus \"\n",
    " \"in the strife-torn southern philippines on monday , the military said.\"\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(document, return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " outputs = model.generate(input_ids=input_ids, num_beams=5, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generated: ['at least two people were killed in a suspected bomb attack on a passenger bus in the', 'at least two people were killed in a suspected bomb attack on a passenger bus.', 'at least two people were killed in a suspected bomb attack on a passenger bus on mon']\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated:\", tokenizer.batch_decode(outputs, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence = 'I love this music'\n",
    "# candidate_labels = ['negative', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on method from_pretrained in module transformers.models.auto.tokenization_auto:\n\nfrom_pretrained(pretrained_model_name_or_path, *inputs, **kwargs) method of builtins.type instance\n    Instantiate one of the tokenizer classes of the library from a pretrained model vocabulary.\n    \n    The tokenizer class to instantiate is selected based on the :obj:`model_type` property of the config object\n    (either passed as an argument or loaded from :obj:`pretrained_model_name_or_path` if possible), or when it's\n    missing, by falling back to using pattern matching on :obj:`pretrained_model_name_or_path`:\n    \n        - **albert** -- :class:`~transformers.AlbertTokenizer` (ALBERT model)\n        - **bart** -- :class:`~transformers.BartTokenizer` (BART model)\n        - **bert** -- :class:`~transformers.BertTokenizer` (BERT model)\n        - **bert-generation** -- :class:`~transformers.BertGenerationTokenizer` (Bert Generation model)\n        - **big_bird** -- :class:`~transformers.BigBirdTokenizer` (BigBird model)\n        - **blenderbot** -- :class:`~transformers.BlenderbotTokenizer` (Blenderbot model)\n        - **blenderbot-small** -- :class:`~transformers.BlenderbotSmallTokenizer` (BlenderbotSmall model)\n        - **camembert** -- :class:`~transformers.CamembertTokenizer` (CamemBERT model)\n        - **convbert** -- :class:`~transformers.ConvBertTokenizer` (ConvBERT model)\n        - **ctrl** -- :class:`~transformers.CTRLTokenizer` (CTRL model)\n        - **deberta** -- :class:`~transformers.DebertaTokenizer` (DeBERTa model)\n        - **deberta-v2** -- :class:`~transformers.DebertaV2Tokenizer` (DeBERTa-v2 model)\n        - **distilbert** -- :class:`~transformers.DistilBertTokenizer` (DistilBERT model)\n        - **dpr** -- :class:`~transformers.DPRQuestionEncoderTokenizer` (DPR model)\n        - **electra** -- :class:`~transformers.ElectraTokenizer` (ELECTRA model)\n        - **flaubert** -- :class:`~transformers.FlaubertTokenizer` (FlauBERT model)\n        - **fsmt** -- :class:`~transformers.FSMTTokenizer` (FairSeq Machine-Translation model)\n        - **funnel** -- :class:`~transformers.FunnelTokenizer` (Funnel Transformer model)\n        - **gpt2** -- :class:`~transformers.GPT2Tokenizer` (OpenAI GPT-2 model)\n        - **gpt_neo** -- :class:`~transformers.GPT2Tokenizer` (GPT Neo model)\n        - **ibert** -- :class:`~transformers.RobertaTokenizer` (I-BERT model)\n        - **layoutlm** -- :class:`~transformers.LayoutLMTokenizer` (LayoutLM model)\n        - **led** -- :class:`~transformers.LEDTokenizer` (LED model)\n        - **longformer** -- :class:`~transformers.LongformerTokenizer` (Longformer model)\n        - **lxmert** -- :class:`~transformers.LxmertTokenizer` (LXMERT model)\n        - **m2m_100** -- :class:`~transformers.M2M100Tokenizer` (M2M100 model)\n        - **marian** -- :class:`~transformers.MarianTokenizer` (Marian model)\n        - **mbart** -- :class:`~transformers.MBartTokenizer` (mBART model)\n        - **mobilebert** -- :class:`~transformers.MobileBertTokenizer` (MobileBERT model)\n        - **mpnet** -- :class:`~transformers.MPNetTokenizer` (MPNet model)\n        - **mt5** -- :class:`~transformers.T5Tokenizer` (mT5 model)\n        - **openai-gpt** -- :class:`~transformers.OpenAIGPTTokenizer` (OpenAI GPT model)\n        - **pegasus** -- :class:`~transformers.PegasusTokenizer` (Pegasus model)\n        - **prophetnet** -- :class:`~transformers.ProphetNetTokenizer` (ProphetNet model)\n        - **rag** -- :class:`~transformers.RagTokenizer` (RAG model)\n        - **reformer** -- :class:`~transformers.ReformerTokenizer` (Reformer model)\n        - **retribert** -- :class:`~transformers.RetriBertTokenizer` (RetriBERT model)\n        - **roberta** -- :class:`~transformers.RobertaTokenizer` (RoBERTa model)\n        - **speech_to_text** -- :class:`~transformers.Speech2TextTokenizer` (Speech2Text model)\n        - **squeezebert** -- :class:`~transformers.SqueezeBertTokenizer` (SqueezeBERT model)\n        - **t5** -- :class:`~transformers.T5Tokenizer` (T5 model)\n        - **tapas** -- :class:`~transformers.TapasTokenizer` (TAPAS model)\n        - **transfo-xl** -- :class:`~transformers.TransfoXLTokenizer` (Transformer-XL model)\n        - **wav2vec2** -- :class:`~transformers.Wav2Vec2CTCTokenizer` (Wav2Vec2 model)\n        - **xlm** -- :class:`~transformers.XLMTokenizer` (XLM model)\n        - **xlm-prophetnet** -- :class:`~transformers.XLMProphetNetTokenizer` (XLMProphetNet model)\n        - **xlm-roberta** -- :class:`~transformers.XLMRobertaTokenizer` (XLM-RoBERTa model)\n        - **xlnet** -- :class:`~transformers.XLNetTokenizer` (XLNet model)\n    \n    Params:\n        pretrained_model_name_or_path (:obj:`str` or :obj:`os.PathLike`):\n            Can be either:\n    \n                - A string, the `model id` of a predefined tokenizer hosted inside a model repo on huggingface.co.\n                  Valid model ids can be located at the root-level, like ``bert-base-uncased``, or namespaced under\n                  a user or organization name, like ``dbmdz/bert-base-german-cased``.\n                - A path to a `directory` containing vocabulary files required by the tokenizer, for instance saved\n                  using the :func:`~transformers.PreTrainedTokenizer.save_pretrained` method, e.g.,\n                  ``./my_model_directory/``.\n                - A path or url to a single saved vocabulary file if and only if the tokenizer only requires a\n                  single vocabulary file (like Bert or XLNet), e.g.: ``./my_model_directory/vocab.txt``. (Not\n                  applicable to all derived classes)\n        inputs (additional positional arguments, `optional`):\n            Will be passed along to the Tokenizer ``__init__()`` method.\n        config (:class:`~transformers.PreTrainedConfig`, `optional`)\n            The configuration object used to dertermine the tokenizer class to instantiate.\n        cache_dir (:obj:`str` or :obj:`os.PathLike`, `optional`):\n            Path to a directory in which a downloaded pretrained model configuration should be cached if the\n            standard cache should not be used.\n        force_download (:obj:`bool`, `optional`, defaults to :obj:`False`):\n            Whether or not to force the (re-)download the model weights and configuration files and override the\n            cached versions if they exist.\n        resume_download (:obj:`bool`, `optional`, defaults to :obj:`False`):\n            Whether or not to delete incompletely received files. Will attempt to resume the download if such a\n            file exists.\n        proxies (:obj:`Dict[str, str]`, `optional`):\n            A dictionary of proxy servers to use by protocol or endpoint, e.g., :obj:`{'http': 'foo.bar:3128',\n            'http://hostname': 'foo.bar:4012'}`. The proxies are used on each request.\n        revision(:obj:`str`, `optional`, defaults to :obj:`\"main\"`):\n            The specific model version to use. It can be a branch name, a tag name, or a commit id, since we use a\n            git-based system for storing models and other artifacts on huggingface.co, so ``revision`` can be any\n            identifier allowed by git.\n        subfolder (:obj:`str`, `optional`):\n            In case the relevant files are located inside a subfolder of the model repo on huggingface.co (e.g. for\n            facebook/rag-token-base), specify it here.\n        use_fast (:obj:`bool`, `optional`, defaults to :obj:`True`):\n            Whether or not to try to load the fast version of the tokenizer.\n        kwargs (additional keyword arguments, `optional`):\n            Will be passed to the Tokenizer ``__init__()`` method. Can be used to set special tokens like\n            ``bos_token``, ``eos_token``, ``unk_token``, ``sep_token``, ``pad_token``, ``cls_token``,\n            ``mask_token``, ``additional_special_tokens``. See parameters in the ``__init__()`` for more details.\n    \n    Examples::\n    \n        >>> from transformers import AutoTokenizer\n    \n        >>> # Download vocabulary from huggingface.co and cache.\n        >>> tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n    \n        >>> # Download vocabulary from huggingface.co (user-uploaded) and cache.\n        >>> tokenizer = AutoTokenizer.from_pretrained('dbmdz/bert-base-german-cased')\n    \n        >>> # If vocabulary files are in a directory (e.g. tokenizer was saved using `save_pretrained('./test/saved_model/')`)\n        >>> tokenizer = AutoTokenizer.from_pretrained('./test/bert_saved_model/')\n\n"
     ]
    }
   ],
   "source": [
    "help(AutoTokenizer.from_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}